<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>朝花夕拾</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2025-10-24T21:20:54.873Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>fangbin</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>解决方案：消息表解决分布式事务</title>
    <link href="http://example.com/2022/12/11/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%E6%B6%88%E6%81%AF%E8%A1%A8%E8%A7%A3%E5%86%B3%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://example.com/2022/12/11/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%E6%B6%88%E6%81%AF%E8%A1%A8%E8%A7%A3%E5%86%B3%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</id>
    <published>2022-12-11T10:30:00.000Z</published>
    <updated>2025-10-24T21:20:54.873Z</updated>
    
    <content type="html"><![CDATA[<p>在内存里面合并一个队列，异步线程轮询这个队列，此时所有用户线程处于挂起状态，如果异步线程挂掉了，对于上游客户端来说超时了，此时有两种情况，异步线程可能执行成功，也可能执行失败，上游不知道库存有没有扣减成功，上游的订单状态变成已扣减库存还是没有扣减库存都有问题，本质上是一个分布式事务的问题。<br><a name="RPyq3"></a></p><h4 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h4><p>事务从狭义上来讲就是 ACID（原子性，一致性，隔离性，持久性）的特性，广义上的事务，尤其是在分布式的环境下更多强调它的原子性。<br />在没有网络隔离的本地事务由内存总线和数据库的连接来保证本地事务的原子性，但是在分布式环境下由于网络隔离的不可靠性，没办法统一协调、同步各个节点成功失败的状态。需要在多进程环境下引入一个协调器，同步多个节点的状态和统一多个节点的行为，要么一起成功，要么一起失败，注意同时并不是严格意义上的同时，是有先后关系的，这也是弱一致性的由来。<br><a name="Ampsw"></a></p><h4 id="节点同步"><a href="#节点同步" class="headerlink" title="节点同步"></a>节点同步</h4><p>节点的同步类型分为两种：阻塞式和非阻塞式，区别在于一致性的时间开销和资源消耗的对比，互联网的业务场景下对性能的要求往往比对一致性的要求要高，所以一般采用的是弱一致的解决方案，尽量避免某一个节点因为网络不稳定导致其他节点的资源都被锁定的情况，这种情况会导致性能急剧降低。<br />对于多节点行为上的同步，要么全成功，要么全失败，协调多个节点执行本地事务，其中一个节点失败，是把之前的事务都回滚还是让后面的事务不断地重试？<br />需要根据具体的业务进行选择，比如下单的链路，包含订单的更新和库存的扣减，先更新订单状态，再去扣减库存，库存扣减失败了，不断地重试意义不大，因为可能就是没有库存了，再怎么重试都是没有库存的，只会增加系统的开销，这种情况一般采用回退的机制，把订单状态回滚回去相比于不断地扣减已经不存在的库存，回滚成功的概率会更高一些。比如物流服务，发完货了之后要更新订单的状态，发货已经执行成功了，更新订单因为网络原因超时了，这样可以不断地重试，因为更新状态是没有资源争抢的，这种业务适合不断地重试来达到最终一致的状态。<br />遇到非业务上的错误，比如网络超时，可以参考一下 seata，每一个节点有一个本地事务提交表，这个流水表里面记录了每一次事务提交的唯一标识，根据这个标识不管是回退还是重试，本地有没有成功执行事务，都根据流水表进行判断。有一种极端的情况，比如本地的机器 FullGC，此时还没有写入流水表，上游的回退或重试消息已经过来了，认为本地没有执行成功，消息就会被忽略。<br><a name="LNYKT"></a></p><h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><p>回退和不断重试都可以采用 MQ，MQ 的好处：解耦，异步，有一定的堆积能力，支持重试，但是重试是有上限的，超过了一定上限会放到死信队列里面，对于这种死信队列一般都是业务上有逻辑性的问题导致一直重试不成功，这种就需要人工介入了。<br />本地事务加消息表的形式发 MQ 有一种极端场景：本地事务已经执行成功了，此时还没有发消息，机器挂掉了，此时也会造成不一致。可以用本地事务保证，写入一张消息表，再用定时任务不断轮询消息表，不停重试，重试达到一定上限之后会发出告警，通知哪一个消息失败了，用页面展示消息表，在列表上每一条消息后面加一个按钮用来手工的重试，因为有些就是业务上的 bug 导致重试一直不成功，此时等 bug 修完之后只要人工再点一下就能够重试成功了，经常说的分布式事务最后一步人工兜底就是这么做的。<br />分布式事务没有完美的解决方案，尽量在做服务拆分的时候把原子性的操作放在单进程，单数据库里面去执行，由本地事务来保证 ACID。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在内存里面合并一个队列，异步线程轮询这个队列，此时所有用户线程处于挂起状态，如果异步线程挂掉了，对于上游客户端来说超时了，此时有两种情况，异步线程可能执行成功，也可能执行失败，上游不知道库存有没有扣减成功，上游的订单状态变成已扣减库存还是没有扣减库存都有问题，本质上是一个分</summary>
      
    
    
    
    <category term="项目实战" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="解决方案" scheme="http://example.com/tags/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    
  </entry>
  
  <entry>
    <title>解决方案：合并队列秒杀</title>
    <link href="http://example.com/2022/12/11/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%E5%90%88%E5%B9%B6%E9%98%9F%E5%88%97%E7%A7%92%E6%9D%80/"/>
    <id>http://example.com/2022/12/11/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%E5%90%88%E5%B9%B6%E9%98%9F%E5%88%97%E7%A7%92%E6%9D%80/</id>
    <published>2022-12-11T10:20:00.000Z</published>
    <updated>2025-10-24T21:20:54.873Z</updated>
    
    <content type="html"><![CDATA[<p><a name="l6pBN"></a></p><h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><p>电商的大促活动，推一些爆品，爆品在秒杀的时候 rt（response time）非常高，并发量上不来。<br><a name="RXHHO"></a></p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>每个商品在数据库里都是一行记录，字段包括商品 id，库存数量等，每次用户下单就进行 update 操作，对这一行的库存进行扣减。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680585450302-551c9939-403d-43b6-8580-d3c429d7750a.png#averageHue=%23eeeeee&clientId=u03d45f88-a5d7-4&from=paste&height=78&id=u1a85832d&name=image.png&originHeight=145&originWidth=784&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=15002&status=done&style=none&taskId=u48c2045b-8fd9-45a6-87d7-a9a65f04c66&title=&width=424.20001220703125"><br />如何防止超卖？<br />多个线程去查都有库存然后扣减，肯定会有超卖现象的发生，所以进行扣减都是用 update 判断库存够不够然后对库存进行扣减，这样本质上就持有了行锁。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680586027093-3afc4e67-4bc5-4391-91b9-18eea0d4fd37.png#averageHue=%23f7b4b4&clientId=u03d45f88-a5d7-4&from=paste&height=62&id=u956c1196&name=image.png&originHeight=88&originWidth=842&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=79029&status=done&style=none&taskId=u06fd70f9-3532-433e-8233-d165083bcb4&title=&width=593.6000366210938"><br />多个用户争抢一个商品，行锁底层是串行执行的，所以 rt 会飙高，tps（transaction per second）上不去。<br />为什么不直接把库存放到 Redis 里面去进行扣减？<br />在业务场景中，在扣减库存的同时还要去写一张库存的流水表，这两个操作是在一个事务当中的，如果把库存写在 Redis 里面，扣减库存和写库存的流水表怎么去保证原子性是一个棘手的问题。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680589939901-e34f7677-1e46-4f5e-bde0-d211801f4185.png#averageHue=%23f6f5f5&clientId=u03d45f88-a5d7-4&from=paste&height=206&id=u9239d924&name=image.png&originHeight=435&originWidth=709&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=45445&status=done&style=none&taskId=u7eff871a-bcb8-4fae-89aa-9e1fcc38086&title=&width=336.20001220703125"><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680590316512-226164a3-6472-4ea0-8cba-b1dd3a698331.png#averageHue=%23f1f0ef&clientId=u03d45f88-a5d7-4&from=paste&height=165&id=u9f776773&name=image.png&originHeight=380&originWidth=870&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=103103&status=done&style=none&taskId=ud5a02977-dd3b-4e74-a772-870983c3233&title=&width=378"><br><a name="ghX8s"></a></p><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><p>针对并发资源的争抢，提升并发度，主要是降低锁的粒度，降低锁的持有时间。<br><a name="ILtMH"></a></p><h5 id="降低锁粒度"><a href="#降低锁粒度" class="headerlink" title="降低锁粒度"></a>降低锁粒度</h5><p>可以采用分库分表的方式，但是分库分表本身可能会涉及到数据的迁移，改造的成本比较大。只有少量的爆品会有这个并发的问题，如果为了这么少的商品去做整个数据库模型层面的改动，成本会比较高。<br><a name="w7JWv"></a></p><h5 id="降低锁持有时间"><a href="#降低锁持有时间" class="headerlink" title="降低锁持有时间"></a>降低锁持有时间</h5><p><a name="XdCxH"></a></p><h6 id="合并队列"><a href="#合并队列" class="headerlink" title="合并队列"></a>合并队列</h6><p>在高并发的情况下，很多用户都来同时抢一个商品，可以将多个用户合并成一个队列，这个队列批量的进行一次数据库的 io 去批量的进行扣减。在内存里面设计一个队列，队列在非常少的一个时间段比如200ms，这 200ms 所有商品的请求都放在队列里面，然后再起一个异步线程把这 200ms 里面所有这个商品的库存扣减一并进行扣减，这样就把 tps 从 500 拉到 2000 以上。<br />200ms 是怎么确定下来的？异步线程，用户是不是还在同步的等待？<br />对用户来说的确是在同步等待，不过一个用户运气最差的话，可能会等待 200ms，但是基于业务场景这个完全是能够容忍的。<br />是否生成队列也是根据当前的并发数，在内存里面有一个计数器，用来记录当前商品的并发请求。每个请求过来就会给它计数，如果当前商品的并发超过了 3，就会创建队列，并不是说每个商品都会去走合并队列的逻辑。<br />这个方案确实降低了 IO 的次数，但还有其他的问题。</p><ul><li>异步合并的线程报错了，对上游来说等待超时了，上游会认为库存没有扣减成功，对于实际的库存模块来说有两种可能，有可能扣减成功也有可能没有扣减成功，因为报错可能是在提交事务之前，也可能是在提交事务之后，如果是在库存事务提交之后报错的，上游的订单状态还是没有扣减库存成功，但是库存却扣减完了，这就会产生数据不一致的问题。此时上游会发出一个消息，消息里面会带着订单号，通过消息和库存的流水号进行库存的回滚，监听到消息，判断订单有没有扣减库存，如果扣减了库存，就会进行回滚，如果没有查到库存流水记录，就不会回滚，这样就达到了上下游的数据一致性，类似于 seata 的解决方案；</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680593171767-f2d75aa9-e31c-4e98-bc7d-e9aec52fe5a4.png#averageHue=%23e6e3e3&clientId=u03d45f88-a5d7-4&from=paste&height=159&id=ub82d9988&name=image.png&originHeight=336&originWidth=930&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=96556&status=done&style=none&taskId=ua19e7fce-934e-44de-b14e-ab002798aca&title=&width=439"><br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680593385438-e9c232a0-dd5d-4967-a0fb-c55d6937dd56.png#averageHue=%23ebe9e8&clientId=u03d45f88-a5d7-4&from=paste&height=207&id=u2ffda3dc&name=image.png&originHeight=378&originWidth=806&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=86880&status=done&style=none&taskId=u50b5b67d-a77d-4408-a6f8-458a5b4e2d9&title=&width=440.8000183105469"></p><ul><li>商品库存只有 1 件了，内存合并之后需要扣 3 件，比如合并了两个用户，一个用户要买 2 件，另外一个用户要买 1 件，异步线程合并扣减可能是扣减不成功的。针对这种极端情况，会退化成一个循环，每个用户购买的数量从大到小去进行扣减，先去尝试扣减两个，扣减失败再去扣减一个，尽量保证买的多的用户先扣减成功。<br><a name="SFjc5"></a></li></ul><h6 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h6><p>事务里先进行一个 update，再进行一个 insert，update 要放到第二条语句执行。如果先 update 再 insert，在insert 的时间也在持有 update 的行锁。先 insert 再 update，insert 的时间没有持有 update 的行锁，降低了锁的持有时间。库存流水表本身特别大，虽然针对流水表做了冷热分离，数据量还是很大，随着时间的增加，insert 语句插入去构建索引耗时会越来越多。<br />最开始先 update 再 insert，改成先 insert 再 update，tps 从 3000 拉到 5000。在高并发的情况下，很小的优化提升了很高的并发度。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680594871787-c0176d5a-5f80-40f2-b2b6-846e1f365b15.png#averageHue=%23faf8f8&clientId=u03d45f88-a5d7-4&from=paste&height=230&id=ua3f13752&name=image.png&originHeight=376&originWidth=683&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=56754&status=done&style=none&taskId=u11fe039e-1841-4283-8f2b-5b605c924fb&title=&width=418.3999938964844"><br><a name="uucE1"></a></p><h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>库存也有缓存，比如商品列表，商品详情页都要去查库存的数据，查询都是放在 Redis 上的。<br />如何保证数据库和 Redis 的一致性？<br />最开始用的是 cache aside，每次更新数据库之后，都会去删一下缓存，这里面有两个问题。</p><ul><li>在高并发的情况下，删缓存也是同步的过程，客户端还是要等待，虽然 Redis 的操作是毫秒级别，针对这种性能极高的接口，这个时间也是想干掉的；</li><li>缓存的命中率非常低，库存更新之后上游并没有查多少次又会更新成另外一个数据，频繁刷新成新的值。</li></ul><p>基于业务场景，系统只要保证不超卖就行了，页面上看到的库存实时性要求不高，所以采用了监听 binlog 的方式，用 binlog 去监听数据库的变更，异步地去刷新 Redis。通过这种方法改造之后，代码完全不用关心缓存，直接用另外一个模块监听 binlog 进行刷新。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680598953979-1bf4f44b-40c8-4b7d-9e27-a070bb0cee7d.png#averageHue=%23efefef&clientId=u0765a597-e8f3-4&from=paste&height=244&id=uaa6e6e67&name=image.png&originHeight=395&originWidth=606&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=86239&status=done&style=none&taskId=u15cdc9b2-c677-4bf6-b12e-f77b8366c6e&title=&width=373.8000183105469"><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680599168407-463494d2-eb44-4777-be66-1597a02560a7.png#averageHue=%23f4f4f3&clientId=u0765a597-e8f3-4&from=paste&height=251&id=ua03801a8&name=image.png&originHeight=384&originWidth=551&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=59659&status=done&style=none&taskId=u553e266d-7ab5-4730-b586-2f7ccbcbe39&title=&width=360.8000183105469"><br />针对缓存命中率不高的问题，监听 binlog 模块，设计了一个时间窗口，比如一个商品在 5 秒钟之内有更新，只在 5 秒钟结束的时候去刷新 Redis。这样就避免在高并发的情况下缓存频繁覆盖 Redis 的值。<br />这样还有一个问题，binlog 可能是并行过来的，后面的 binlog 可能先被监听到，这样会有消息乱序的问题。解决方案是在表里面加了一个版本号，每次库存更新就给版本号加 1。监听 binlog 的时候，首先判断 Redis 里面的版本号，如果大于版本号，才会更新，这样就能避免老的 binlog 把最新的库存值覆盖掉，能够保证数据库的数据只是有延迟，但一定能达到最终一致。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680600710749-17d047eb-c0cc-4af1-a627-e82bd1634b60.png#averageHue=%23eeeceb&clientId=u0765a597-e8f3-4&from=paste&height=248&id=u11d8b622&name=image.png&originHeight=341&originWidth=849&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=104931&status=done&style=none&taskId=uf471b448-0f3b-4bad-89b0-abb6370e601&title=&width=617.2000122070312"><br />还有一个业务上的考虑，对于上游来说库存有没有比库存有多少的敏感度要高很多，因为一旦库存没有，前端的页面会直接置灰。采用了异步刷新之后，真实的库存跟页面上看到的库存肯定是有延迟的，比如页面上看到的库存可能是 10，9，8，7 在减少的过程，但是实际上看到的库存可能已经变成 0 了。一旦扣库存失败，库存没有了之后，直接把缓存里的数据同步更新为 0。<br />binlog 过来之后 0 已经是最新的值了，binlog 会不会把最新的值覆盖掉？<br />通过版本号的对比，不会去进行覆盖。异步的 binlog 过来之后，会判断 0 已经是最新的版本了，会直接把旧的 binlog 丢弃掉。</p><blockquote><p>时间窗口如何设计？如何实现？<br>多个线程都判断版本是老的，会不会都去覆盖？<br>判断版本是不是要加分布式锁？</p></blockquote><p><a name="mEPQP"></a></p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>内存队列很难横向的进行扩容，因为合并完全是在内存的层面，单机的内存，cpu都是有上限的， 肯定要采取集群的模式，加了机器之后每台机器合并的效果就会变差，打到数据库上的线程也会变多，所以服务的横向扩容弹性不是很好。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680601918202-7f1e8400-6253-400c-944e-357d73172c02.png#averageHue=%23eeecec&clientId=u0765a597-e8f3-4&from=paste&height=185&id=u42816c4f&name=image.png&originHeight=243&originWidth=595&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=95022&status=done&style=none&taskId=u880897d6-94cd-4fe4-b2e3-8cf8640b5a3&title=&width=454"><br />优化：把扣减库存的接口单独拎出来，放到一个集群里面，专门拿几台机器做这个事情，避免跟其他一些比如报表，查询的接口共享，争抢资源，尽量压榨单机最好的性能。<br />因为集群很难横向扩容，所以有很多调优的过程，比如等待 200ms，线程池设置的大小，并发的数量，多大创建队列，这些参数都是产生在逐步调优的过程。<br><a name="NdGVo"></a></p><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p>淘宝的核心链路的库存，也是采用排队的机制，只是在 MySQL 这一层用中间件的方式进行集中的排队，而不是在应用机器的内存里面，所以没有横向扩容的问题，但是没有开源。<br />内存合并的解决方案参考了 MySQL 每次更新并不会去刷磁盘，而是在内存里面有 ChangeBuffer 这么一个缓存队列。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1680603054748-83262d1a-e4f3-4d11-8763-933eb2e039a2.png#averageHue=%234e3cd1&clientId=u0765a597-e8f3-4&from=paste&height=338&id=ub5a859b6&name=image.png&originHeight=468&originWidth=932&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=268509&status=done&style=none&taskId=ue6e29a23-63ff-4ed4-83e5-0b0fa30e422&title=&width=674"><br />好的思想都是相互借鉴的，在学八股文的时候，不仅要知道它们是什么样子，而且项目中如果遇到一些挑战，能够灵活的应用这些知识。内存合并虽然用到了八股文的一些技术，但也针对实际的业务场景做了很多妥协，最后的解决方案并不完美，但也能满足业务的需要，这就要求达到两个点：</p><ul><li>对业务场景理解的比较深刻；</li><li>对常见的架构模式和技术的解决方案比较熟悉。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;l6pBN&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;场景&quot;&gt;&lt;a href=&quot;#场景&quot; class=&quot;headerlink&quot; title=&quot;场景&quot;&gt;&lt;/a&gt;场景&lt;/h4&gt;&lt;p&gt;电商的大促活动，推一些爆品，爆品在秒杀的时候 rt（response time）非常</summary>
      
    
    
    
    <category term="项目实战" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="解决方案" scheme="http://example.com/tags/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    
  </entry>
  
  <entry>
    <title>解决方案：事务回调编程</title>
    <link href="http://example.com/2022/12/11/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%E4%BA%8B%E5%8A%A1%E5%9B%9E%E8%B0%83%E7%BC%96%E7%A8%8B/"/>
    <id>http://example.com/2022/12/11/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%E4%BA%8B%E5%8A%A1%E5%9B%9E%E8%B0%83%E7%BC%96%E7%A8%8B/</id>
    <published>2022-12-11T10:10:00.000Z</published>
    <updated>2025-10-24T21:20:54.873Z</updated>
    
    <content type="html"><![CDATA[<p><a name="RNQK9"></a></p><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>业务中很多时候需要本地事务 + RPC 或 MQ 尽量保证原子性。<br><a name="HXuNu"></a></p><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><p>应尽量避免在事务中嵌套 RPC 或 MQ 等耗时 IO 操作。因为可能会拉大事务的执行时间，导致连接池的吞吐量降低。<br />考虑到本地事务往往是可控 -&gt; 回滚 OR 提交，但是 RPC 与 MQ 往往没有回滚操作，所以大部分场景采用本地事务执行成功后再发起 RPC。<br />这个时候代码需要调整结构，考虑到 @Transactional 注解方法无法代理，只能把 RPC 等后置操作调用提到外层来发起。<br /><img src="https://cdn.nlark.com/yuque/0/2023/webp/25368844/1682579270439-c46d1eeb-3dcf-4338-abbc-8422f1df506f.webp#averageHue=%23f8f8f8&clientId=ue11ee2e4-5268-4&from=paste&height=280&id=u41f50f29&originHeight=686&originWidth=794&originalType=binary&ratio=1.25&rotation=0&showTitle=true&size=9070&status=done&style=none&taskId=ufee43438-ca1d-4d7d-8db4-40796895305&title=AOP%20bean%20Proxy&width=324.20001220703125" alt="AOP bean Proxy" title="AOP bean Proxy"><br />但这样增加代码结构的复杂性，是否存在一种既满足代码编写的自由，静态上实现内嵌在声明事务，在当前事务执行成功后实际执行。<br><a name="D5Lbf"></a></p><h4 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h4><p>Spring 提供这样的SPI扩展。TransactionSynchronization是事务执行回调接口。<br /><img src="https://cdn.nlark.com/yuque/0/2023/webp/25368844/1682579395468-e4590dd7-dc8f-4e65-8d65-3181d3514349.webp#averageHue=%233c4335&clientId=ue11ee2e4-5268-4&from=paste&height=276&id=ud09de001&originHeight=486&originWidth=942&originalType=binary&ratio=1.25&rotation=0&showTitle=true&size=40608&status=done&style=none&taskId=u113f109d-6527-4cd9-96c3-a4c41fae5f8&title=Spring%20TX%20SPI&width=535" alt="Spring TX SPI" title="Spring TX SPI"><br />提供了事务执行的多个扩展点。<br /><img src="https://cdn.nlark.com/yuque/0/2023/webp/25368844/1682579442167-60eefc1b-18cd-4827-8936-ac13a3f537f3.webp#averageHue=%23464b54&clientId=ue11ee2e4-5268-4&from=paste&height=276&id=u5b7e04c9&originHeight=498&originWidth=596&originalType=binary&ratio=1.25&rotation=0&showTitle=true&size=26014&status=done&style=none&taskId=uf2ee9b69-add2-49c8-9966-8d10f1fcefc&title=TX%20status&width=329.8000183105469" alt="TX status" title="TX status"><br />其中 afterCompletion 的结果会提供事务执行结果状态（成功 OR 回滚），根据事务执行结果进行后置预期的处理即可。<br /><img src="https://cdn.nlark.com/yuque/0/2023/webp/25368844/1682579508504-41ab8760-3603-4814-90c2-b164065a3c5e.webp#averageHue=%23404737&clientId=ue11ee2e4-5268-4&from=paste&height=277&id=u54beb6db&originHeight=480&originWidth=942&originalType=binary&ratio=1.25&rotation=0&showTitle=true&size=39634&status=done&style=none&taskId=u0a99ea8d-c284-4eb8-b81b-a8d7a5e941e&title=TX%20Callback&width=543" alt="TX Callback" title="TX Callback"><br />另外，这都建立在当前上下文存在事务，如何判断，Spring也提供了静态方法。<br><a name="riW0r"></a></p><h4 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TransactionUtils</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 事务后置处理，可以优化大事务提升连接池性能，尽量保证分布式事务一致性</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> runnable</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">doAfterTransaction</span><span class="params">(Runnable runnable)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (TransactionSynchronizationManager.isActualTransactionActive()) &#123;</span><br><span class="line">            TransactionSynchronizationManager.registerSynchronization(<span class="keyword">new</span> <span class="title class_">DoTransactionCompletion</span>(runnable));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 事务完成后置回调函数定义</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DoTransactionCompletion</span> <span class="keyword">implements</span> <span class="title class_">TransactionSynchronization</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Runnable runnable;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">DoTransactionCompletion</span><span class="params">(Runnable runnable)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.runnable = runnable;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">afterCompletion</span><span class="params">(<span class="type">int</span> status)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (status == TransactionSynchronization.STATUS_COMMITTED) &#123;</span><br><span class="line">            <span class="built_in">this</span>.runnable.run();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * demo</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Transactional</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">doTx</span><span class="params">()</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;start tx&quot;</span>);</span><br><span class="line">    TransactionUtils.doAfterTransaction(() -&gt; &#123;</span><br><span class="line">       System.out.println(<span class="string">&quot;after commit do..&quot;</span>);</span><br><span class="line">    &#125;);</span><br><span class="line">    System.out.println(<span class="string">&quot;tx do end&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start tx</span><br><span class="line">tx do end</span><br><span class="line">after commit do..</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;RNQK9&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h4&gt;&lt;p&gt;业务中很多时候需要本地事务 + RPC 或 MQ 尽量保证原子性。&lt;br&gt;&lt;a na</summary>
      
    
    
    
    <category term="项目实战" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="解决方案" scheme="http://example.com/tags/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    
  </entry>
  
  <entry>
    <title>解决方案：Spring 异步线程池</title>
    <link href="http://example.com/2022/12/11/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9ASpring%20%E5%BC%82%E6%AD%A5%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    <id>http://example.com/2022/12/11/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9ASpring%20%E5%BC%82%E6%AD%A5%E7%BA%BF%E7%A8%8B%E6%B1%A0/</id>
    <published>2022-12-11T10:00:00.000Z</published>
    <updated>2025-10-24T21:20:54.873Z</updated>
    
    <content type="html"><![CDATA[<p><a name="HjKiX"></a></p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>在 spring 中使用 @async 异步调用的情况下，被调用的异步子线程获取不到父线程的 request 信息，不方便处理相关逻辑，即子线程无法获取父线程的上下文数据。<br><a name="sNRwW"></a></p><h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p>在自定义的异步线程池 ThreadPoolTaskExecutor 中，初始化线程池时有 TaskDecorator 这样一个任务装饰器，类似 aop，可对线程执行方法的始末进行增强。<br />TaskDecorator 是一个执行回调方法的装饰器，父要应用于传递上下文，或者提供任务的监控&#x2F;统计信息。<br />基本使用：自定义装饰器实现 TaskDecorator ，重写 decorate 方法，自定义线程池，并设置自定义装饰器。<br />注意：线程池中有的线程是一直存在一直被复用的，所以线程执行完成后需要在 TaskDecorator 的 finally 方法中移除传递的上下文对象，否则就存在内存泄漏的问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ContextDecorator</span> <span class="keyword">implements</span> <span class="title class_">TaskDecorator</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Runnable <span class="title function_">decorate</span><span class="params">(Runnable runnable)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 获取父线程的context</span></span><br><span class="line">            <span class="type">RequestAttributes</span> <span class="variable">context</span> <span class="operator">=</span> RequestContextHolder.currentRequestAttributes();</span><br><span class="line">            <span class="keyword">return</span> () -&gt; &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 将父线程的context设置进子线程里</span></span><br><span class="line">                    RequestContextHolder.setRequestAttributes(context);</span><br><span class="line">                    <span class="comment">// 子线程方法执行</span></span><br><span class="line">                    runnable.run();</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    <span class="comment">// 清除父线程context</span></span><br><span class="line">                    RequestContextHolder.resetRequestAttributes();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IllegalStateException e) &#123;</span><br><span class="line">            <span class="keyword">return</span> runnable;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean(&quot;taskExecutor&quot;)</span> <span class="comment">// bean的名称，默认为首字母小写的方法名</span></span><br><span class="line"><span class="keyword">public</span> Executor <span class="title function_">taskExecutor</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="type">ThreadPoolTaskExecutor</span> <span class="variable">executor</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolTaskExecutor</span>();</span><br><span class="line">    <span class="comment">// 设置核心线程数</span></span><br><span class="line">    executor.setCorePoolSize(<span class="number">20</span>);</span><br><span class="line">    <span class="comment">// 设置最大线程数</span></span><br><span class="line">    executor.setMaxPoolSize(<span class="number">30</span>);</span><br><span class="line">    <span class="comment">// 设置队列容量</span></span><br><span class="line">    executor.setQueueCapacity(<span class="number">1000</span>);</span><br><span class="line">    <span class="comment">// 设置线程活跃时间（秒）</span></span><br><span class="line">    executor.setKeepAliveSeconds(<span class="number">60</span>);</span><br><span class="line">    <span class="comment">// 设置默认线程名称</span></span><br><span class="line">    executor.setThreadNamePrefix(<span class="string">&quot;job-&quot;</span>);</span><br><span class="line">    <span class="comment">// 设置拒绝策略</span></span><br><span class="line">    executor.setRejectedExecutionHandler(<span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>.CallerRunsPolicy());</span><br><span class="line">    <span class="comment">// 等待所有任务结束后再关闭线程池，全局线程池不能关闭</span></span><br><span class="line">    executor.setWaitForTasksToCompleteOnShutdown(<span class="literal">true</span>);</span><br><span class="line">    <span class="comment">// 设置自定义的Decorator</span></span><br><span class="line">    executor.setTaskDecorator(<span class="keyword">new</span> <span class="title class_">ContextDecorator</span>());</span><br><span class="line">    <span class="keyword">return</span> executor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a name="yNyeI"></a></p><h4 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h4><p>从父线程取出的 RequestContextHolder 对象，此为持有线程上下文的 request 容器，将其设置到子线程中，按道理只要对象还存在强引用，就不会被销毁，但由于 RequestContextHolder 的特殊性，在父线程销毁的时候，会触发里面的 resetRequestAttributes 方法（即清除 threadLocal 里面的信息，request 中的信息会被清除），此时即使 RequestContextHolder 这个对象还是存在，子线程也无法继续使用它获取 request 中的数据了。<br><a name="Nu1Hm"></a></p><h4 id="完善思路"><a href="#完善思路" class="headerlink" title="完善思路"></a>完善思路</h4><p>既然是因为 RequestContextHolder 的特殊性，那就绕过销毁清除，思路不变，还是继续使用 threadLocal 来传递需要使用到的变量，在父线程装饰前将所需变量取出来，然后在子线程中设置到 threadLocal，业务使用的时候从 threadLocal 中取即可。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ThreadLocalData</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;String&gt; threadLocal = <span class="keyword">new</span> <span class="title class_">ThreadLocal</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">getUa</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> threadLocal.get();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">setUa</span><span class="params">(String ua)</span>&#123;</span><br><span class="line">        threadLocal.set(ua);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">remove</span><span class="params">()</span>&#123;</span><br><span class="line">        threadLocal.remove();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ContextDecorator</span> <span class="keyword">implements</span> <span class="title class_">TaskDecorator</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Runnable <span class="title function_">decorate</span><span class="params">(Runnable runnable)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 获取父线程的request的user-agent(示例)</span></span><br><span class="line">           <span class="type">HttpServletRequest</span> <span class="variable">request</span> <span class="operator">=</span> ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest();</span><br><span class="line">            <span class="type">String</span> <span class="variable">ua</span> <span class="operator">=</span> request.getHeader(<span class="string">&quot;user-agent&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> () -&gt; &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// 将父线程的ua设置进子线程里</span></span><br><span class="line">                    ThreadLocalData.setUa(ua);</span><br><span class="line">                    <span class="comment">// 子线程方法执行</span></span><br><span class="line">                    runnable.run();</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    <span class="comment">// 清除父线程threadLocal的值</span></span><br><span class="line">                    ThreadLocalData.remove();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IllegalStateException e) &#123;</span><br><span class="line">            <span class="keyword">return</span> runnable;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a name="kcB06"></a></p><h4 id="ThreadLocal，InheritableThreadLocal，TransmittableThreadLocal-区别和使用"><a href="#ThreadLocal，InheritableThreadLocal，TransmittableThreadLocal-区别和使用" class="headerlink" title="ThreadLocal，InheritableThreadLocal，TransmittableThreadLocal 区别和使用"></a>ThreadLocal，InheritableThreadLocal，TransmittableThreadLocal 区别和使用</h4><p>TransmittableThreadLocal：通过继承 InheritableThreadLocal 实现，阿里的，推荐。</p><ul><li>父线程使用 ThreadLocal，子线程创建时不会拥有父类的 threadLocal 信息；</li><li>父线程使用 InheritableThreadLocal，子线程创建时默认 init 方法会拿到父类的 InheritableThreadLocal 信息，这种在线程池&#x2F;线程复用的情况下，由于 init 方法只会在初始化时获取父线程的数据，复用的时候也没法再从父线程那里新的 InheritableThreadLocal 的数据，此种情况下继续使用，很容易出 bug。（InheritableThreadLocal 适用于非线程池和复用线程，单独创建销毁子线程执行的情况）；</li><li>父线程使用 TransmittableThreadLocal，子线程创建时拥有父类的 TransmittableThreadLocal 信息，在线程池&#x2F;线程复用的情况下不会出现读取到脏数据的情况。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;HjKiX&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h4&gt;&lt;p&gt;在 spring 中使用 @async 异步调用的情况下，被调用的异步子线程获取不到</summary>
      
    
    
    
    <category term="项目实战" scheme="http://example.com/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
    
    
    <category term="解决方案" scheme="http://example.com/tags/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    
  </entry>
  
  <entry>
    <title>场景设计：设计一个可以动态缓存热点数据的缓存策略</title>
    <link href="http://example.com/2022/12/10/%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1%EF%BC%9A%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E5%8A%A8%E6%80%81%E7%BC%93%E5%AD%98%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%E7%9A%84%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5/"/>
    <id>http://example.com/2022/12/10/%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1%EF%BC%9A%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BB%A5%E5%8A%A8%E6%80%81%E7%BC%93%E5%AD%98%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%E7%9A%84%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5/</id>
    <published>2022-12-10T10:40:00.000Z</published>
    <updated>2025-10-24T21:20:54.870Z</updated>
    
    <content type="html"><![CDATA[<p>由于数据存储受限系统并不是将所有数据都需要存放到缓存中的，而只是将其中一部分热点数据缓存起来，所以要设计一个热点数据动态缓存的策略。<br />热点数据动态缓存的策略总体思路：通过数据最新访问时间来做排名并过滤掉不常访问的数据，只留下经常访问的数据。<br />以电商平台场景为例，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：</p><ul><li>先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间来更新队列信息，越是最近访问的商品排名越靠前；</li><li>同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；</li><li>这样当请求每次到达时会先从队列中获取商品 ID，如果命中就根据 ID 再从另一个缓存数据结构中读取实际的商品信息并返回。</li></ul><p>在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;由于数据存储受限系统并不是将所有数据都需要存放到缓存中的，而只是将其中一部分热点数据缓存起来，所以要设计一个热点数据动态缓存的策略。&lt;br /&gt;热点数据动态缓存的策略总体思路：通过数据最新访问时间来做排名并过滤掉不常访问的数据，只留下经常访问的数据。&lt;br /&gt;以电商平台场</summary>
      
    
    
    
    <category term="系统设计" scheme="http://example.com/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="场景设计" scheme="http://example.com/tags/%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>场景设计：如何保证数据库和缓存一致性？</title>
    <link href="http://example.com/2022/12/10/%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F/"/>
    <id>http://example.com/2022/12/10/%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9F/</id>
    <published>2022-12-10T10:30:00.000Z</published>
    <updated>2025-10-24T21:20:54.870Z</updated>
    
    <content type="html"><![CDATA[<p>在客户端请求数据时如果能在缓存中命中数据就查询缓存，不能再去查询数据库从而减轻数据库的压力，提高服务器的性能。<br><a name="gpA3f"></a></p><h4 id="先更新数据库还是先更新缓存？"><a href="#先更新数据库还是先更新缓存？" class="headerlink" title="先更新数据库还是先更新缓存？"></a>先更新数据库还是先更新缓存？</h4><p>由于引入了缓存，在数据更新时不仅要更新数据库，而且要更新缓存，这两个更新操作存在前后的问题：</p><ul><li>先更新数据库再更新缓存；</li><li>先更新缓存再更新数据库。<br><a name="krejn"></a></li></ul><h5 id="先更新数据库再更新缓存"><a href="#先更新数据库再更新缓存" class="headerlink" title="先更新数据库再更新缓存"></a>先更新数据库再更新缓存</h5><p>举个例子比如「请求 A 」和「请求 B 」两个请求同时更新「同一条」数据可能出现这样的顺序：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686363063889-f11597de-f28f-4eeb-8850-72d684d45d6a.png#averageHue=%23faf7f1&clientId=u4bf596ea-1a46-4&from=paste&height=356&id=u4948bfb0&originHeight=768&originWidth=1153&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=203387&status=done&style=none&taskId=ub01cc87e-8f46-45ad-b6d4-883d0c241c0&title=&width=534.2000122070312"><br />A 请求先将数据库的数据更新为 1，然后在更新缓存前请求 B 将数据库的数据更新为 2，紧接着也把缓存更新为 2，然后 A 请求更新缓存为 1。<br />此时数据库中的数据是 2 而缓存中的数据却是 1，出现了缓存和数据库中的数据不一致的现象。<br><a name="J3SLC"></a></p><h5 id="先更新缓存再更新数据库"><a href="#先更新缓存再更新数据库" class="headerlink" title="先更新缓存再更新数据库"></a>先更新缓存再更新数据库</h5><p>举个例子比如「请求 A 」和「请求 B 」两个请求同时更新「同一条」数据可能出现这样的顺序：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686363289907-f9c2aa4a-ab1f-4b64-a84e-c0d5fe05a356.png#averageHue=%23f9f5ee&clientId=u4bf596ea-1a46-4&from=paste&height=321&id=u01deda54&originHeight=623&originWidth=1122&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=190933&status=done&style=none&taskId=u4c3a2486-7d1c-4a93-8780-e8713e7ac0f&title=&width=578.2000122070312"><br />A 请求先将缓存的数据更新为 1，然后在更新数据库前 B 请求来了将缓存的数据更新为 2，紧接着把数据库更新为 2，然后 A 请求将数据库的数据更新为 1。<br />此时数据库中的数据是 1 而缓存中的数据却是 2，出现了缓存和数据库中的数据不一致的现象。<br />所以无论是「先更新数据库再更新缓存」还是「先更新缓存再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据时可能会出现缓存和数据库中的数据不一致的现象。<br><a name="ohwZl"></a></p><h4 id="先更新数据库还是先删除缓存？"><a href="#先更新数据库还是先删除缓存？" class="headerlink" title="先更新数据库还是先删除缓存？"></a>先更新数据库还是先删除缓存？</h4><p>在更新数据时不更新缓存而是删除缓存中的数据。到读取数据时，发现缓存中没了数据之后再从数据库中读取数据更新到缓存中。<br />这个策略叫 Cache Aside 策略，中文是叫旁路缓存策略。<br />该策略又可以细分为「读策略」和「写策略」。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686363751293-9e9789fa-a472-42a0-990e-96f2715c8fbf.png#averageHue=%23f8f6f0&clientId=u4bf596ea-1a46-4&from=paste&height=388&id=u278bde2a&originHeight=923&originWidth=1121&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=293699&status=done&style=none&taskId=ude71ac3a-b787-4eb4-90d3-19c93c0f448&title=&width=471.20001220703125"><br />写策略的步骤：</p><ul><li>更新数据库中的数据；</li><li>删除缓存中的数据。</li></ul><p>读策略的步骤：</p><ul><li>如果读取的数据命中了缓存就直接返回数据；</li><li>如果读取的数据没有命中缓存就从数据库中读取数据，然后将数据写入到缓存并返回给用户。<br><a name="YTwH8"></a></li></ul><h5 id="先删除缓存再更新数据库"><a href="#先删除缓存再更新数据库" class="headerlink" title="先删除缓存再更新数据库"></a>先删除缓存再更新数据库</h5><p>假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后会从数据库中读取到年龄为 20 并且写入到缓存中，然后请求 A 继续更改数据库将用户的年龄更新为 21。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686364137296-b0646496-0959-4411-9854-de31af3152b2.png#averageHue=%23f9f5ef&clientId=u4bf596ea-1a46-4&from=paste&height=366&id=u3796715b&originHeight=762&originWidth=1119&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=225547&status=done&style=none&taskId=u0771f48e-4522-4f2f-82d0-1a798c3d960&title=&width=538.2000122070312"><br />最终该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。<br />先删除缓存再更新数据库在「读 + 写」并发的时候还是会出现缓存和数据库的数据不一致的问题。<br><a name="Axc3J"></a></p><h5 id="先更新数据库再删除缓存"><a href="#先更新数据库再删除缓存" class="headerlink" title="先更新数据库再删除缓存"></a>先更新数据库再删除缓存</h5><p>继续用「读 + 写」请求的并发的场景来分析。<br />假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据，更新数据库中的年龄为 21 并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686367005876-081c52b0-2da5-4c5e-8729-a65aeddfa996.png#averageHue=%23faf6ef&clientId=u8d7edf4a-f486-4&from=paste&height=365&id=u7560b0ab&originHeight=767&originWidth=1136&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=227220&status=done&style=none&taskId=u1a8f5f26-40b1-4c9f-967d-6fd1451193a&title=&width=541.2000122070312"><br />最终该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。<br />从上面的理论上分析先更新数据库再删除缓存也是会出现数据不一致性的问题，但是在实际中这个问题出现的概率并不高。<br />因为缓存的写入通常要远远快于数据库的写入，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。<br />而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。<br />所以「先更新数据库再删除缓存」的方案是可以保证数据一致性的。<br />为了确保万无一失还可以给缓存数据加上「过期时间」，这样就算在这期间存在缓存数据不一致，有过期时间来兜底也能达到最终一致。<br />「先更新数据库再删除缓存」其实是两个操作，前面的所有分析都是建立在这两个操作都能同时执行成功，如果在删除缓存（第二个操作）的时候失败了会导致缓存中的数据是旧值。<br />好在给缓存加上了过期时间，所以会出现过一段时间才更新生效的现象，如果没有过期时间的兜底，那后续的请求读到的就会一直是缓存中的旧数据，这样问题就大了。<br><a name="T5FsD"></a></p><h5 id="为什么是删除缓存而不是更新缓存？"><a href="#为什么是删除缓存而不是更新缓存？" class="headerlink" title="为什么是删除缓存而不是更新缓存？"></a>为什么是删除缓存而不是更新缓存？</h5><p>删除一个数据相比更新一个数据更加轻量级，出问题的概率更小。在实际业务中缓存的数据可能不是直接来自数据库表，也许来自多张底层数据表的聚合。<br />比如商品详情信息，在底层可能会关联商品表、价格表、库存表等，如果更新一个价格字段，那么就要更新整个数据库，还要关联的去查询和汇总各个周边业务系统的数据，这个操作会非常耗时。从另外一个角度不是所有的缓存数据都是频繁访问的，更新后的缓存可能会长时间不被访问，所以从计算资源和整体性能的考虑更新的时候删除缓存，等到下次查询命中再填充缓存是一个更好的方案。<br />系统设计中有一个思想叫 Lazy Loading，适用于那些加载代价大的操作，删除缓存而不是更新缓存就是懒加载思想的一个应用。<br><a name="EexR7"></a></p><h5 id="如何保证两个操作都能执行成功？"><a href="#如何保证两个操作都能执行成功？" class="headerlink" title="如何保证两个操作都能执行成功？"></a>如何保证两个操作都能执行成功？</h5><p>因为在删除缓存（第二个操作）的时候失败了导致缓存还是旧值，而数据库是最新值造成数据库和缓存数据不一致的问题，会对敏感业务造成影响。<br />举个例子应用要把数据 X 的值从 1 更新为 2，先成功更新了数据库，然后在 Redis 缓存中删除 X 的缓存，但是这个操作却失败了，这个时候数据库中 X 的新值为 2，Redis 中的 X 的缓存值为 1，出现了数据库和缓存数据不一致的问题。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686371760154-fca9ac46-269d-4e03-a92a-4f1693200969.png#averageHue=%23faf8f4&clientId=u8d7edf4a-f486-4&from=paste&height=430&id=u29be8737&originHeight=537&originWidth=1112&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=153843&status=done&style=none&taskId=u03e865e3-a62a-4579-b717-095a4f0bee4&title=&width=889.6"><br />后续有访问数据 X 的请求会先在 Redis 中查询，因为缓存并没有被删除，所以会命中缓存，但是读到的却是旧值 1。<br />不管是先操作数据库还是先操作缓存，只要第二个操作失败都会出现数据一致的问题。<br />解决有两种方法：</p><ul><li>重试机制；</li><li>订阅 MySQL binlog 再操作缓存。<br><a name="KK0wC"></a></li></ul><h6 id="重试机制"><a href="#重试机制" class="headerlink" title="重试机制"></a>重试机制</h6><p>可以引入消息队列将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。</p><ul><li>如果应用删除缓存失败可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。如果重试超过的一定次数还是没有成功就需要向业务层发送报错信息了；</li><li>如果删除缓存成功就要把数据从消息队列中移除来避免重复操作，否则就继续重试。</li></ul><p>重试机制的过程：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686372255545-73802305-083c-428c-9ea2-e06122bc8951.png#averageHue=%23fbfaf9&clientId=u8d7edf4a-f486-4&from=paste&height=390&id=uc5b9d413&originHeight=488&originWidth=1140&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=124014&status=done&style=none&taskId=u44220c1c-69e3-455b-964b-f51f019de87&title=&width=912"><br><a name="o2CKN"></a></p><h6 id="订阅-MySQL-binlog-再操作缓存"><a href="#订阅-MySQL-binlog-再操作缓存" class="headerlink" title="订阅 MySQL binlog 再操作缓存"></a>订阅 MySQL binlog 再操作缓存</h6><p>「先更新数据库再删缓存」的策略的第一步是更新数据库，更新数据库成功就会产生一条变更日志记录在 binlog 里。<br />可以通过订阅 binlog 日志拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。<br />Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点向 MySQL 主节点发送 dump 请求，MySQL 收到请求后就会开始推送 binlog 给 Canal，Canal 解析 binlog 字节流之后转换为便于读取的结构化数据，供下游程序订阅使用。<br />Canal 的工作原理：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686372517380-fbbbafb4-d215-4b5e-ad78-2183c2320f78.png#averageHue=%23f8f7f5&clientId=u8d7edf4a-f486-4&from=paste&height=313&id=u5b05019f&originHeight=493&originWidth=1103&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=76269&status=done&style=none&taskId=u06170eb8-b94b-48cb-ae54-59bb00bc8c7&title=&width=699.2000122070312"><br />如果要想保证「先更新数据库再删缓存」策略第二个操作能执行成功，可以「使用消息队列来重试缓存的删除」或者「订阅 MySQL binlog 再操作缓存」，这两种方法有一个共同的特点都是采用异步操作缓存。<br><a name="OmZ2G"></a></p><h4 id="其他方案"><a href="#其他方案" class="headerlink" title="其他方案"></a>其他方案</h4><p>「先更新数据库再删除缓存」的方案虽然保证了数据库与缓存的数据一致性，但是每次更新数据的时候缓存的数据都会被删除，这样会对缓存的命中率带来影响。<br />如果业务对缓存命中率有很高的要求可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况。<br />这个方案前面也分析过，在两个更新请求并发执行的时候会出现数据不一致的问题，因为更新数据库和更新缓存这两个操作是独立的又没有对操作做任何并发控制，所以当两个线程并发更新时就会因为写入顺序的不同造成数据的不一致。<br />所以得增加一些手段来解决这个问题，这里提供两种做法：</p><ul><li>在更新缓存前先加个分布式锁保证同一时间只运行一个请求更新缓存就不会产生并发问题了，当然引入锁对于写入的性能就会带来影响；</li><li>在更新缓存时给缓存加上较短的过期时间，这样即使出现缓存不一致的情况缓存的数据也会很快过期，对业务还是能接受的。</li></ul><p>针对「先删除缓存再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「延迟双删」。<br />延迟双删实现的伪代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#删除缓存</span><br><span class="line">redis.delKey(X)</span><br><span class="line">#更新数据库</span><br><span class="line">db.update(X)</span><br><span class="line">#睡眠</span><br><span class="line">Thread.sleep(N)</span><br><span class="line">#再删除缓存</span><br><span class="line">redis.delKey(X)</span><br></pre></td></tr></table></figure><p>加了个睡眠时间主要是为了确保在请求 A 睡眠的时候，请求 B 能够在这一段时间完成「从数据库读取数据再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完再删除缓存。<br />所以请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。<br />但是具体睡眠多久很难评估出来，所以这个方案也只是尽可能保证一致性而已，极端情况下依然会出现缓存不一致的现象。<br />因此还是比较建议用「先更新数据库再删除缓存」的方案。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在客户端请求数据时如果能在缓存中命中数据就查询缓存，不能再去查询数据库从而减轻数据库的压力，提高服务器的性能。&lt;br&gt;&lt;a name=&quot;gpA3f&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;先更新数据库还是先更新缓存？&quot;&gt;&lt;a href=&quot;#先更新数据库还是先更新缓存？&quot; cla</summary>
      
    
    
    
    <category term="系统设计" scheme="http://example.com/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="场景设计" scheme="http://example.com/tags/%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>场景设计：如何设计访问频率控制？</title>
    <link href="http://example.com/2022/12/10/%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1%EF%BC%9A%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E8%AE%BF%E9%97%AE%E9%A2%91%E7%8E%87%E6%8E%A7%E5%88%B6%EF%BC%9F/"/>
    <id>http://example.com/2022/12/10/%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1%EF%BC%9A%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E8%AE%BF%E9%97%AE%E9%A2%91%E7%8E%87%E6%8E%A7%E5%88%B6%EF%BC%9F/</id>
    <published>2022-12-10T10:20:00.000Z</published>
    <updated>2025-10-24T21:20:54.870Z</updated>
    
    <content type="html"><![CDATA[<p><a name="hZ2LI"></a></p><h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><ul><li>软件获取手机的登录验证码，一分钟只能发送一次；</li><li>贴吧发帖 10 秒钟只能发送一次；</li><li>在 b 站上看直播 5 秒钟之内只能发送一条弹幕。<br><a name="bKJJI"></a></li></ul><h4 id="存储方案系统设计"><a href="#存储方案系统设计" class="headerlink" title="存储方案系统设计"></a>存储方案系统设计</h4><p><a name="NnTs1"></a></p><h5 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h5><p>这种方案是不可行的：</p><ul><li>性能问题：如果是类似于弹幕的高频访问，性能可能扛不住；</li><li>冗余数据问题：过了某个时间段数据就没有作用了，无需持久化存储。<br><a name="KYF35"></a></li></ul><h5 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h5><p>这种方案有两个好处：</p><ul><li>访问速度快：因为 Redis 本身是基于内存的，访问速度特别快；</li><li>自带过期时间，可以方便的对过期数据进行清理。<br><a name="alAEt"></a></li></ul><h6 id="计数型"><a href="#计数型" class="headerlink" title="计数型"></a>计数型</h6><p>直接简单粗暴的进行 count，比如验证码只允许一分钟访问一次，如果一分钟内超过一次，则返回拒绝错误。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1677885620253-96980385-bdb6-41cb-b27a-1e8bc6da425a.png#averageHue=%23f8f7f6&clientId=ud28d9d18-f435-4&from=paste&height=334&id=u39bfb6d5&originHeight=405&originWidth=386&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=31055&status=done&style=none&taskId=u8ee186d0-7118-490d-8461-37c17788d8a&title=&width=318.8000183105469"><br />流程：首先请求到来之后根据用户的 ip 或用户信息判断用户获取验证码的次数。判断有没有，如果有的话直接 +1。然后再根据业务配置场景来判断是否超过了阈值。如果超过了阈值直接拒绝访问，如果没有超过则继续请求下面的业务。<br />设计：利用 Redis 中的 String 或 Hash 等等。</p><ul><li>key：用户的 id &#x2F; ip；</li><li>value：访问的次数；</li><li>过期时间：业务的过期时间。</li></ul><p>第一次访问之后 value 设置为 1，后续每访问一次 +1。请求到达之后先判断是否达到了访问限制，如果没有直接用 INCRBY 加 1，如果超过了阈值直接拒绝返回。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1677887037082-55ddbc77-c83e-44d4-bb0d-7bac8138ae60.png#averageHue=%23f9f9f9&clientId=ud28d9d18-f435-4&from=paste&height=152&id=ub9db6fcd&originHeight=184&originWidth=779&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=24072&status=done&style=none&taskId=u7fa0eaad-be7f-4856-bd29-ae51bedd402&title=&width=644.2000122070312"><br />问题：无法很好的做到频率控制而且容易在某个短时间突增流量。<br />例如一分钟只能发送 5 个帖子，用户在第一个一分钟的 1 秒发送一次，59 秒连续发送 4 次，然后在第二个一分钟的 1 秒连续发送 5 次，这样就会在短短的 3 秒钟时间内发送了 9 次帖子，造成短期的流量突增。<br><a name="kmmy2"></a></p><h6 id="Sorted-Set"><a href="#Sorted-Set" class="headerlink" title="Sorted Set"></a>Sorted Set</h6><p><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1677887666135-f2fca0e5-84bd-46de-a17f-bbc6bbe7fd06.png#averageHue=%23f5f3f2&clientId=ud28d9d18-f435-4&from=paste&height=156&id=uee547cb1&originHeight=194&originWidth=805&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=26746&status=done&style=none&taskId=u8ffb9144-caf5-4e1e-ae5c-088b15c5206&title=&width=647"><br />滑动窗口解决流量突增的问题：滑动窗口用于判断动态的一分钟或动态的一个时间段范围内是否超过了限制。类似于 TCP 协议中的滑动窗口，窗口一直向右递增，获取时只需要判断最近一分钟之内访问次数是否达到限制即可，这样会很好的防止流量突增的问题。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1677887845885-fd67bc70-e9c8-42c7-b13d-4f87ea4abb3d.png#averageHue=%23f6f6f6&clientId=ud28d9d18-f435-4&from=paste&height=341&id=u228039ae&originHeight=414&originWidth=254&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=21216&status=done&style=none&taskId=uce12b97a-ce55-48ba-b6ef-f8f36cf332d&title=&width=209.1999969482422"><br />流程：首先用用户的 ip 或 id 获取当前的时间戳，然后再根据当前的时间戳倒推最近一段时间内的访问的次数。如果大于阈值直接拒绝访问，否则继续其他业务。<br />设计：Sorted Set 天然带有有序性。</p><ul><li>key：用户的 id &#x2F; ip；</li><li>score：当前时间戳；</li><li>member：当前时间戳。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZADD &#123;user_id&#125; &#123;current_time&#125; &#123;current_time&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ZCOUNT &#123;user_id&#125; &#123;current_time-&#123;1分钟毫秒数&#125;&#125; &#123;current_time&#125;</span><br></pre></td></tr></table></figure>问题：由于 Sorted Set 只能对整个 key 设置过期时间，如果不及时清理数据，日积月累 Redis 会产生大量的大 key。因此需要用定时任务定期清理一分钟以前的数据，将数据不断地清洗。清洗的过程可以做成异步式的，不需要影响业务。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;hZ2LI&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;场景&quot;&gt;&lt;a href=&quot;#场景&quot; class=&quot;headerlink&quot; title=&quot;场景&quot;&gt;&lt;/a&gt;场景&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;软件获取手机的登录验证码，一分钟只能发送一次；&lt;/li&gt;
&lt;li&gt;贴吧发</summary>
      
    
    
    
    <category term="系统设计" scheme="http://example.com/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="场景设计" scheme="http://example.com/tags/%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>系统设计基础：缓存雪崩、击穿、穿透</title>
    <link href="http://example.com/2022/12/10/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%EF%BC%9A%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F/"/>
    <id>http://example.com/2022/12/10/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%EF%BC%9A%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F/</id>
    <published>2022-12-10T10:10:00.000Z</published>
    <updated>2025-10-24T21:20:54.872Z</updated>
    
    <content type="html"><![CDATA[<p>用户的数据一般都是存储于数据库，数据库的数据是落在磁盘上的，磁盘的读写速度是计算机里最慢的了。<br />如果用户的请求都访问数据库，请求数量一上来数据库很容易就奔溃了，所以为了避免用户直接访问数据库会用 Redis 作为缓存层。<br />因为 Redis 是内存数据库，可以将数据库的数据缓存在 Redis 里，相当于数据缓存在内存，内存的读写速度比硬盘快好几个数量级，这样大大提高了系统性能。<br />引入了缓存层，就会有缓存异常的三个问题，分别是缓存雪崩、缓存击穿、缓存穿透。<br />不光要清楚地知道它们是怎么发生，还需要知道如何解决它们。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686362433431-b0c4f536-189d-4ac6-b9ee-4fb89aebfee4.png#averageHue=%23ede1be&clientId=ufb56288c-e884-4&from=paste&height=526&id=ufedce3e3&originHeight=658&originWidth=1138&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=482373&status=done&style=none&taskId=ub2f59821-9e7f-4516-8092-d84bf71ac80&title=&width=910.4"><br><a name="X3I4t"></a></p><h4 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h4><p>通常为了保证缓存中的数据与数据库中的数据一致性会给 Redis 里的数据设置过期时间，当缓存数据过期后用户访问的数据如果不在缓存里业务系统需要重新生成缓存，因此就会访问数据库并将数据更新到 Redis 里，这样后续请求都可以直接命中缓存。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686327565370-aa9e6384-1c1b-4a3a-95dc-42a02e547ac8.png#averageHue=%23f5f3f2&clientId=u011d7340-1722-4&from=paste&height=346&id=u97184825&originHeight=669&originWidth=1078&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=145157&status=done&style=none&taskId=ub8d1e37c-e290-46a0-a3fd-0ee6d3e2b28&title=&width=558.2000122070312"><br />当大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求，那么都无法在 Redis 中处理，于是全部请求都直接访问数据库从而导致数据库的压力骤增，严重的会造成数据库宕机从而形成一系列连锁反应造成整个系统崩溃，这就是缓存雪崩的问题。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686327745234-387f24af-903c-4bda-aa89-1948f56481bd.png#averageHue=%23faf2e8&clientId=u011d7340-1722-4&from=paste&height=370&id=u49165277&originHeight=644&originWidth=1130&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=306888&status=done&style=none&taskId=u3a70c043-fb62-487c-99a6-2594e2269e4&title=&width=649.2000122070312"><br />发生缓存雪崩有两个原因：</p><ul><li>大量数据同时过期；</li><li>Redis 故障宕机。</li></ul><p>不同的诱因应对的策略也会不同。<br><a name="MxZVC"></a></p><h5 id="大量数据同时过期"><a href="#大量数据同时过期" class="headerlink" title="大量数据同时过期"></a>大量数据同时过期</h5><p><a name="C2uOI"></a></p><h6 id="均匀设置过期时间"><a href="#均匀设置过期时间" class="headerlink" title="均匀设置过期时间"></a>均匀设置过期时间</h6><p>如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。可以在对缓存数据设置过期时间时给这些数据的过期时间加上一个随机数，这样就保证数据不会在同一时间过期。<br><a name="mz7Mp"></a></p><h6 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h6><p>当业务线程在处理用户请求时，如果发现访问的数据不在 Redis 里就加个互斥锁，保证同一时间内只有一个请求来构建缓存（从数据库读取数据再将数据更新到 Redis 里），当缓存构建完成后再释放锁。未能获取互斥锁的请求要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。<br />实现互斥锁时最好设置超时时间，不然第一个请求拿到了锁后发生了某种意外而一直阻塞一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。<br><a name="dXJBo"></a></p><h6 id="后台更新缓存"><a href="#后台更新缓存" class="headerlink" title="后台更新缓存"></a>后台更新缓存</h6><p>业务线程不再负责更新缓存，缓存也不设置有效期而是让缓存”永久有效“并将更新缓存的工作交由后台线程定时更新。<br />缓存数据不设置有效期并不是意味着数据一直能在内存里，因为当系统内存紧张时有些缓存数据会被“淘汰”，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。<br />解决上面的问题的方式有两种：<br />第一种方式，后台线程不仅负责定时更新缓存，而且也负责频繁地检测缓存是否有效，检测到缓存失效原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据并更新到缓存。<br />这种方式的检测时间间隔不能太长，太长会导致用户获取的数据是一个空值而不是真正的数据，所以检测的间隔最好是毫秒级的，但是总归是有个间隔时间，用户体验一般。<br />第二种方式，在业务线程发现缓存数据失效后（缓存数据被淘汰）通过消息队列发送一条消息通知后台线程更新缓存，后台线程收到消息后在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。<br />在业务刚上线的时候最好提前把数据缓起来而不是等待用户访问才来触发缓存构建，这就是所谓的缓存预热，后台更新缓存的机制刚好也适合干这个事情。<br><a name="Zgyrk"></a></p><h5 id="Redis-故障宕机"><a href="#Redis-故障宕机" class="headerlink" title="Redis 故障宕机"></a>Redis 故障宕机</h5><p><a name="ENgqw"></a></p><h6 id="服务熔断或请求限流机制"><a href="#服务熔断或请求限流机制" class="headerlink" title="服务熔断或请求限流机制"></a>服务熔断或请求限流机制</h6><p>因为 Redis 故障宕机而导致缓存雪崩问题时可以启动服务熔断机制暂停业务应用对缓存服务的访问，直接返回错误，不用再继续访问数据库从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后再允许业务应用访问缓存服务。<br />服务熔断机制是保护数据库的正常允许，但是暂停了业务应用访问缓存系统，全部业务都无法正常工作<br />为了减少对业务的影响可以启用请求限流机制，只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到 Redis 恢复正常并把缓存预热完后再解除请求限流的机制。<br><a name="wPpSQ"></a></p><h6 id="构建-Redis-缓存高可靠集群"><a href="#构建-Redis-缓存高可靠集群" class="headerlink" title="构建 Redis 缓存高可靠集群"></a>构建 Redis 缓存高可靠集群</h6><p>服务熔断或请求限流机制是缓存雪崩发生后的应对方案，最好通过主从节点的方式构建 Redis 缓存高可靠集群。<br />如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。<br><a name="WxLw7"></a></p><h4 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h4><p>业务通常会有几个数据会被频繁地访问，比如秒杀活动，这类被频地访问的数据被称为热点数据。<br />如果缓存中的某个热点数据过期了，此时大量的请求访问该热点数据就无法从缓存中读取，会直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686330018839-0e34552e-7866-4c20-a3fb-cfe70c9b88af.png#averageHue=%23f9f2e6&clientId=ufb56288c-e884-4&from=paste&height=416&id=u976ccfbd&originHeight=939&originWidth=838&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=264284&status=done&style=none&taskId=ud26298b1-b9e3-4cf9-8466-a7264382085&title=&width=371.3999938964844"><br />缓存击穿跟缓存雪崩很相似，可以认为缓存击穿是缓存雪崩的一个子集。<br />应对缓存击穿可以采取前面说到两种方案：</p><ul><li>互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求要么等待锁释放后重新读取缓存，要么就返回空值或者默认值；</li><li>不给热点数据设置过期时间，由后台异步更新缓存或者在热点数据要过期前提前通知后台线程更新缓存以及重新设置过期时间。<br><a name="mRGSJ"></a></li></ul><h4 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h4><p>当发生缓存雪崩或击穿时数据库中还是保存了应用要访问的数据，缓存恢复相对应的数据就可以减轻数据库的压力，而缓存穿透就不一样了。<br />当用户访问的数据既不在缓存中，也不在数据库中，导致请求在访问缓存时发现缓存缺失，再去访问数据库时发现数据库中也没有要访问的数据，没办法构建缓存数据来服务后续的请求。当有大量这样的请求到来时数据库的压力骤增，这就是缓存穿透的问题。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686343607163-4283b194-ae68-4fe0-984a-809de3e2afac.png#averageHue=%23faf3ea&clientId=ufb56288c-e884-4&from=paste&height=394&id=u14f3f41d&originHeight=933&originWidth=863&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=245121&status=done&style=none&taskId=u6592e643-50e9-461b-9416-7a4ae3cf883&title=&width=364.3999938964844"><br />缓存穿透的发生一般有这两种情况：</p><ul><li>业务误操作，缓存中的数据和数据库中的数据都被误删除导致缓存和数据库中都没有数据；</li><li>黑客恶意攻击，故意大量访问某些读取不存在数据的业务。</li></ul><p>应对缓存穿透的方案，常见的方案有三种：</p><ul><li>第一种方案，非法请求的限制；</li><li>第二种方案，缓存空值或者默认值；</li><li>第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。<br><a name="ckSwY"></a></li></ul><h5 id="非法请求的限制"><a href="#非法请求的限制" class="headerlink" title="非法请求的限制"></a>非法请求的限制</h5><p>当有大量恶意请求访问不存在的数据时也会发生缓存穿透，因此在 API 入口处要判断请求参数是否合理、请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。<br><a name="GUChA"></a></p><h5 id="缓存空值或者默认值"><a href="#缓存空值或者默认值" class="headerlink" title="缓存空值或者默认值"></a>缓存空值或者默认值</h5><p>当线上业务发现缓存穿透的现象时可以针对查询的数据在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值返回给应用而不会继续查询数据库。<br><a name="B21IX"></a></p><h5 id="使用布隆过滤器快速判断数据是否存在"><a href="#使用布隆过滤器快速判断数据是否存在" class="headerlink" title="使用布隆过滤器快速判断数据是否存在"></a>使用布隆过滤器快速判断数据是否存在</h5><p>可以在写入数据库数据时使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后可以通过查询布隆过滤器快速判断数据是否存在，如果不存在就不用通过查询数据库来判断数据是否存在。<br />即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。<br />布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当写入数据库数据时在布隆过滤器里做个标记，这样下次查询数据是否在数据库时只需要查询布隆过滤器，如果查询到数据没有被标记则说明不在数据库中。<br />布隆过滤器会通过 3 个操作完成标记：</p><ul><li>第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；</li><li>第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置；</li><li>第三步，将每个哈希值在位图数组的对应位置的值设置为 1。</li></ul><p>举个例子假设有一个位图数组长度为 8，哈希函数 3 个的布隆过滤器。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686361853842-215f7ba3-3809-42b8-96c5-91d15a4e3ed4.png#averageHue=%23f6f3ef&clientId=ufb56288c-e884-4&from=paste&height=294&id=u0b70176e&originHeight=368&originWidth=1137&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=134568&status=done&style=none&taskId=u358451e9-0127-434a-a1b0-948a2e9bf51&title=&width=909.6"><br />在数据库写入数据 x 后，把数据 x 标记在布隆过滤器时数据 x 会被 3 个哈希函数分别计算出 3 个哈希值，然后再对这 3 个哈希值对 8 取模，假设取模的结果为 1、4、6 就把位图数组的第 1、4、6 位置的值设置为 1。应用要查询数据 x 是否在数据库时只需通过布隆过滤器查找位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0 就认为数据 x 不在数据库中。<br />布隆过滤器是基于哈希函数来实现查找的，高效查找的同时存在哈希冲突的可能性，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上可能数据库中并不存在数据 y，存在误判的情况。<br />所以查询布隆过滤器说数据存在并不一定证明数据库中存在这个数据，但是查询到数据不存在数据库中一定就不存在这个数据。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;用户的数据一般都是存储于数据库，数据库的数据是落在磁盘上的，磁盘的读写速度是计算机里最慢的了。&lt;br /&gt;如果用户的请求都访问数据库，请求数量一上来数据库很容易就奔溃了，所以为了避免用户直接访问数据库会用 Redis 作为缓存层。&lt;br /&gt;因为 Redis 是内存数据库，</summary>
      
    
    
    
    <category term="系统设计" scheme="http://example.com/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="系统设计基础" scheme="http://example.com/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>系统设计基础：一致性哈希算法</title>
    <link href="http://example.com/2022/12/10/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2022/12/10/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</id>
    <published>2022-12-10T10:00:00.000Z</published>
    <updated>2025-10-24T21:20:54.871Z</updated>
    
    <content type="html"><![CDATA[<p><a name="jM6su"></a></p><h4 id="如何分配请求？"><a href="#如何分配请求？" class="headerlink" title="如何分配请求？"></a>如何分配请求？</h4><p>大多数网站背后肯定不是只有一台服务器提供服务，因为单机的并发量和数据量都是有限的，所以都会用多台服务器构成集群来对外提供服务。那么多个节点要如何分配客户端的请求呢？<br />其实这个问题就是「负载均衡问题」。解决负载均衡问题的算法很多，不同的负载均衡算法对应不同的分配策略，适应的业务场景也不同。<br />最简单的方式是引入一个中间的负载均衡层，让它将外界的请求「轮流」的转发给内部的集群。比如集群有 3 个节点，外界请求有 3 个，那么每个节点都会处理 1 个请求，达到分配请求的目的。<br />考虑到每个节点的硬件配置有所区别，可以引入权重值，将硬件配置更好的节点的权重值设高，然后根据各个节点的权重值，按照一定比重分配在不同的节点上，让硬件配置更好的节点承担更多的请求，这种算法叫做加权轮询。<br />加权轮询算法使用场景是建立在每个节点存储的数据都是相同的前提下，所以每次读数据的请求访问任意一个节点都能得到结果。但是加权轮询算法是无法应对「分布式系统（数据分片的系统）」的，因为分布式系统中每个节点存储的数据是不同的。<br />当想提高系统的容量，就会将数据水平切分到不同的节点来存储，也就是将数据分布到了不同的节点。比如一个分布式 KV(key-value) 缓存系统，某个 key 应该到哪个或者哪些节点上获得应该是确定的，不是说任意访问一个节点都可以得到缓存结果的。<br />因此需要一个能应对分布式系统的负载均衡算法。<br><a name="r5ipU"></a></p><h4 id="使用哈希算法有什么问题？"><a href="#使用哈希算法有什么问题？" class="headerlink" title="使用哈希算法有什么问题？"></a>使用哈希算法有什么问题？</h4><p>哈希算法对同一个关键字进行哈希计算每次计算都是相同的值，这样就可以将某个 key 确定到一个节点上了，可以满足分布式系统的负载均衡需求。<br />哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 hash(key) % 3 公式对数据进行映射。如果客户端要获取指定 key 的数据，通过公式可以定位节点。如果经过公式计算后得到的值是 0，就说明该 key 需要去第一个节点获取。<br />但是这有一个很致命的问题，如果节点数量发生了变化，也就是在对系统做扩容或者缩容时必须迁移改变了映射关系的数据，否则会出现查询不到数据的问题。<br />举个例子，假设有一个由 A、B、C 三个节点组成分布式 KV 缓存系统，基于计算公式 hash(key) % 3 将数据进行了映射，每个节点存储了不同的数据：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685796774217-cf99480d-c049-4666-826c-88c5b7666914.png#averageHue=%23f3f4f1&clientId=u1d97360c-2f40-4&from=paste&height=205&id=u336ce573&originHeight=256&originWidth=1131&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=72120&status=done&style=none&taskId=u2c425a35-2e0a-4f93-afd0-b963c9537db&title=&width=904.8"><br />现在有 3 个查询 key 的请求，分别查询 key-01，key-02，key-03 的数据，这三个 key 分别经过 hash() 函数计算后的值为 hash( key-01) &#x3D; 6、hash( key-02) &#x3D; 7、hash(key-03) &#x3D; 8，然后再对这些值进行取模运算。通过这样的哈希算法，每个 key 都可以定位到对应的节点。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685797127132-15af18a0-5ebe-431e-b135-a513e9466d3c.png#averageHue=%23f9f8f3&clientId=u1d97360c-2f40-4&from=paste&height=351&id=uf6015610&originHeight=914&originWidth=1336&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=233330&status=done&style=none&taskId=ufd8e44a8-a357-4240-bbb7-b4dbdc4115e&title=&width=513.2000122070312"><br />当 3 个节点不能满足业务需求了，这时增加了一个节点，节点的数量从 3 变化为 4，意味着取模哈希函数中基数的变化，这样会导致大部分映射关系改变，如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685797201167-cde8306c-66d7-428b-a99b-2aef2ea828ba.png#averageHue=%23faf4ef&clientId=u1d97360c-2f40-4&from=paste&height=357&id=u8a43a767&originHeight=574&originWidth=1116&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=171033&status=done&style=none&taskId=u0feaf604-e6f5-4cab-b25a-3c2aca87697&title=&width=694.2000122070312"><br />比如之前的 hash(key-01) % 3 &#x3D; 0，就变成了 hash(key-01) % 4 &#x3D; 2，查询 key-01 数据时寻址到了节点 C，而 key-01 的数据是存储在节点 A 上的，不在节点 C 上，所以会查询不到数据。<br />同样的道理，如果对分布式系统进行缩容，比如移除一个节点，也会因为取模哈希函数中基数的变化，可能出现查询不到数据的问题。<br />要解决这个问题就需要迁移数据，比如节点的数量从 3 变化为 4 时，要基于新的计算公式 hash(key) % 4 ，重新对数据和节点做映射。<br />假设总数据条数为 M，哈希算法在面对节点数量变化时最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(M)，这样数据的迁移成本太高了。<br />所以需要一个新的算法，来避免分布式系统在扩容或者缩容时发生过多的数据迁移。<br><a name="twHqd"></a></p><h4 id="使用一致性哈希算法有什么问题？"><a href="#使用一致性哈希算法有什么问题？" class="headerlink" title="使用一致性哈希算法有什么问题？"></a>使用一致性哈希算法有什么问题？</h4><p>一致性哈希算法很好地解决了分布式系统在扩容或者缩容时发生过多的数据迁移的问题。<br />一致性哈希算法也用了取模运算，但与哈希算法不同的是哈希算法是对节点的数量进行取模运算，而一致性哈希算法是对 232 进行取模运算，是一个固定的值。<br />可以把一致性哈希算法是对 232 进行取模运算的结果值组织成一个圆环，这个圆环被称为哈希环，如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685798005601-32c87e36-8553-4e65-aa30-2b545ae7a6a8.png#averageHue=%23f5f5f5&clientId=u1d97360c-2f40-4&from=paste&height=247&id=ue8c7f576&originHeight=825&originWidth=683&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=81432&status=done&style=none&taskId=uf85cdd97-3e28-4a2f-ba92-35c3c0351cc&title=&width=204.39999389648438"><br />一致性哈希要进行两步哈希：</p><ul><li>第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；</li><li>第二步：当对数据进行存储或访问时对数据进行哈希映射。</li></ul><p>所以一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。<br />对「数据」进行哈希映射得到的结果值往顺时针的方向找到的第一个节点就是存储该数据的节点。<br />举个例子，有 3 个节点经过哈希计算，映射到了如下图的位置：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685799456049-b12acf2b-7ead-4530-ad80-bef4845020bc.png#averageHue=%23f6f4f1&clientId=u1d97360c-2f40-4&from=paste&height=286&id=u0939d04e&originHeight=849&originWidth=870&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=181194&status=done&style=none&taskId=u10a7fccb-9a88-42b1-9399-06fe6115adf&title=&width=293"><br />接着对要查询的 key-1 进行哈希计算，确定此 key-1 映射在哈希环的位置，然后从这个位置往顺时针的方向找到的第一个节点 A，就是存储该 key-1 数据的节点。<br />所以当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：</p><ul><li>首先对 key 进行哈希计算，确定此 key 在环上的位置；</li><li>然后从这个位置沿着顺时针方向走，遇到的第一个节点就是存储 key 的节点。</li></ul><p>一致性哈希如果增加一个节点或者减少一个节点会发生大量的数据迁移吗？<br />假设节点数量从 3 增加到 4，新的节点 D 经过哈希计算后映射到了下图中的位置：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685801286443-55e3af4c-4108-44af-a07f-48656f9475d6.png#averageHue=%23f7f4f1&clientId=u1d97360c-2f40-4&from=paste&height=288&id=u876bef58&originHeight=856&originWidth=905&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=194862&status=done&style=none&taskId=ud14444bf-0e24-4b32-8b41-ce16bdd04e5&title=&width=304"><br />可以看到 key-1、key-3 都不受影响，只有 key-2 需要被迁移到节点 D。<br />假设节点数量从 3 减少到 2，比如将节点 A 移除：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685801568683-07b72d95-f277-43c4-97c1-f2158730fe33.png#averageHue=%23f6f4f2&clientId=u1d97360c-2f40-4&from=paste&height=278&id=uff7de821&originHeight=851&originWidth=899&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=174476&status=done&style=none&taskId=uc5e10761-44e8-4330-81e5-56c7c1a8792&title=&width=293.20001220703125"><br />可以看到 key-2 和 key-3 不会受到影响，只有 key-1 需要被迁移到节点 B。<br />因此在一致性哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。<br />上面这些图中 3 个节点映射在哈希环还是比较分散的，所以看起来请求都会「均衡」到每个节点。但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，会有大量的请求集中在一个节点上。<br />比如下图中 3 个节点的映射位置都在哈希环的右半边：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685801728067-039b6881-2d2d-4b04-a221-8e9ca3ceca99.png#averageHue=%23f6f3f0&clientId=u1d97360c-2f40-4&from=paste&height=268&id=u9e794cb3&originHeight=825&originWidth=855&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=219020&status=done&style=none&taskId=ud2c53cfa-1205-4299-8425-61c3ee0bedc&title=&width=278"><br />这时有一半以上的数据的寻址都会找节点 A，也就是访问请求主要集中在节点 A 上，负载不均衡。另外在这种节点分布不均匀的情况下进行容灾与扩容时，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应。<br />比如上图中如果节点 A 被移除了，当节点 A 宕机后根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上，这样节点 B 的数据量、访问量都会迅速增加很多倍，一旦新增的压力超过了节点 B 的处理能力上限就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。<br />所以一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题。<br><a name="oHG1E"></a></p><h4 id="如何通过虚拟节点提高均衡度？"><a href="#如何通过虚拟节点提高均衡度？" class="headerlink" title="如何通过虚拟节点提高均衡度？"></a>如何通过虚拟节点提高均衡度？</h4><p>要想解决节点在哈希环上分配不均匀的问题就要有大量的节点，节点数越多哈希环上的节点分布的就越均匀。<br />但问题是实际上没有那么多节点，所以此时就加入虚拟节点，也就是对一个真实节点做多个副本。具体做法：不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。<br />比如对每个节点分别设置 3 个虚拟节点：</p><ul><li>对节点 A 加上编号来作为虚拟节点：A-01、A-02、A-03；</li><li>对节点 B 加上编号来作为虚拟节点：B-01、B-02、B-03；</li><li>对节点 C 加上编号来作为虚拟节点：C-01、C-02、C-03。</li></ul><p>引入虚拟节点后原本哈希环上只有 3 个节点的情况就会变成有 9 个虚拟节点映射到哈希环上，哈希环上的节点数量多了 3 倍。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685803135703-a635662b-3d63-4cb7-9abe-72d0ef986dc9.png#averageHue=%23f9f4f0&clientId=u1d97360c-2f40-4&from=paste&height=346&id=u88a47dd1&originHeight=834&originWidth=842&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=235983&status=done&style=none&taskId=u63cda9a5-3baa-4168-856c-d8117d9cf7e&title=&width=349.6000061035156"><br />可以看到节点数量多了后，节点在哈希环上的分布就相对均匀了。此时如果有访问请求寻址到「A-01」这个虚拟节点，接着再通过「A-01」虚拟节点找到真实节点 A，这样请求就能访问到真实节点 A 了。<br />上面为了方便理解，每个真实节点仅包含 3 个虚拟节点，这样能起到的均衡效果其实很有限。而在实际的工程中虚拟节点的数量会大很多，比如 Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有160 个虚拟节点。<br />另外虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。当节点变化时会有不同的节点共同分担系统的变化，因此稳定性更高。<br />比如当某个节点被移除时，对应该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点可能会对应不同的真实节点，即这些不同的真实节点共同分担了节点变化导致的压力。而且有了虚拟节点后还可以为硬件配置更好的节点增加权重，比如对权重更高的节点增加更多的虚拟机节点即可。<br />因此带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;jM6su&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;如何分配请求？&quot;&gt;&lt;a href=&quot;#如何分配请求？&quot; class=&quot;headerlink&quot; title=&quot;如何分配请求？&quot;&gt;&lt;/a&gt;如何分配请求？&lt;/h4&gt;&lt;p&gt;大多数网站背后肯定不是只有一台服务器提供服务</summary>
      
    
    
    
    <category term="系统设计" scheme="http://example.com/categories/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
    
    <category term="系统设计基础" scheme="http://example.com/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>算法：排序算法</title>
    <link href="http://example.com/2022/12/09/%E7%AE%97%E6%B3%95%EF%BC%9A%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
    <id>http://example.com/2022/12/09/%E7%AE%97%E6%B3%95%EF%BC%9A%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</id>
    <published>2022-12-09T12:20:00.000Z</published>
    <updated>2025-10-24T21:20:54.871Z</updated>
    
    <content type="html"><![CDATA[<p>排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因为排序的数据很大，不能一次容纳全部的排序记录，在排序过程中需要访问外存。常见的内部排序算法有：冒泡排序、选择排序、插入排序、归并排序、快速排序、堆排序等。用一张图概括：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1683902017307-d492ce86-8150-4622-bb70-ca382011a469.png#averageHue=%23e5ded6&clientId=uf2ec17e9-e2ce-4&from=paste&height=321&id=u8af5afc9&originHeight=401&originWidth=1036&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=179061&status=done&style=none&taskId=u02fccf99-0587-48ca-9826-db957cc42a1&title=&width=828.8"><br />名词解释：</p><ul><li>n：数据规模；</li><li>In-place：占用常数内存，不占用额外内存；</li><li>Out-place：占用额外内存；</li><li>稳定性：排序后 2 个相等键值的顺序和排序之前的顺序相同。</li></ul><p>稳定的排序算法：冒泡排序、插入排序、归并排序。<br />不稳定的排序算法：选择排序、快速排序、堆排序。<br><a name="Or8Oa"></a></p><h4 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h4><p>这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数组的顶端。<br />算法步骤：</p><ol><li>比较相邻的元素，如果第一个比第二个大，就交换它们两个；</li><li>对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后最后的元素会是最大的数；</li><li>针对所有的元素重复以上的步骤，除了最后一个；</li><li>持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; T[] sort(T[] array) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>, size = array.length; i &lt; size; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; size - i; ++j) &#123;</span><br><span class="line">            <span class="keyword">if</span> (SortUtils.greater(array[j], array[j + <span class="number">1</span>])) &#123;</span><br><span class="line">                SortUtils.swap(array, j, j + <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> array;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>优化目的：数组有可能在中间某一过程就已经有序，无需再进行后面操作。<br />优化思路：增加一个标记（swapped），每次发生交换就进行标记，如果某次循环完没有标记，则说明已经完成排序，数组有序，剩下的几趟排序就不需要再去执行了，可以提前结束排序。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; T[] sort(T[] array) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">1</span>, size = array.length; i &lt; size; ++i) &#123;</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">swapped</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>; j &lt; size - i; ++j) &#123;</span><br><span class="line">            <span class="keyword">if</span> (SortUtils.greater(array[j], array[j + <span class="number">1</span>])) &#123;</span><br><span class="line">                SortUtils.swap(array, j, j + <span class="number">1</span>);</span><br><span class="line">                swapped = <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!swapped) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> array;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a name="zlykp"></a></li></ol><h4 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h4><p>算法步骤：</p><ol><li>首先在未排序数组中找到最小元素，存放到排序数组的起始位置；</li><li>再从剩余未排序元素中继续寻找最小元素，然后放到已排序数组的末尾；</li><li>重复第二步，直到所有元素均排序完毕。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; T[] sort(T[] array) &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> array.length;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; size - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">minIndex</span> <span class="operator">=</span> i;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i + <span class="number">1</span>; j &lt; size; ++j) &#123;</span><br><span class="line">            <span class="keyword">if</span>(SortUtils.greater(array[minIndex], array[j])) &#123;</span><br><span class="line">                minIndex = j;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        SortUtils.swap(array, minIndex, i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> array;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a name="CmZwM"></a></li></ol><h4 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h4><p>插入排序的原理是最容易理解的了，只要打过扑克牌的人就能够秒懂。<br />算法步骤：</p><ol><li>将第一待排序数组第一个元素看做一个有序数组，把第二个元素到最后一个元素当成是未排序数组；</li><li>从头到尾依次扫描未排序数组，将扫描到的每个元素插入有序数组的适当位置。（如果待插入的元素与有序数组中的某个元素相等，则将待插入元素插入到相等元素的后面。）<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; T[] sort(T[] array) &#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>, size = array.length; i &lt; size; ++i) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i; j &gt; <span class="number">0</span> &amp;&amp; SortUtils.less(array[j], array[j - <span class="number">1</span>]); --j) &#123;</span><br><span class="line">            SortUtils.swap(array, j, j-<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> array;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a name="zuiZX"></a></li></ol><h4 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h4><p>归并排序是分治法的一个非常典型的应用，始终都是 O(nlogn) 的时间复杂度，代价是需要额外的内存空间。<br />算法步骤：</p><ol><li>申请空间，其大小为待排序数组的长度，该空间用来存放待排序数组的复制；</li><li>设定两个指针，最初位置分别为两个已排序数组的起始位置；</li><li>比较两个指针所指向的元素，选择相对小的元素放入到合并空间并移动指针到下一位置；</li><li>重复步骤 3 直到某一指针达到数组尾；</li><li>将另一数组剩下的所有元素直接复制到合并数组尾。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Comparable[] aux;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; T[] sort(T[] array) &#123;</span><br><span class="line">    aux = <span class="keyword">new</span> <span class="title class_">Comparable</span>[array.length];</span><br><span class="line">    doSort(array, <span class="number">0</span>, array.length - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> array;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; <span class="keyword">void</span> <span class="title function_">doSort</span><span class="params">(T[] array, <span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(left &lt; right) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">mid</span> <span class="operator">=</span> (left + right) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        doSort(array, left, mid);</span><br><span class="line">        doSort(array, mid + <span class="number">1</span>, right);</span><br><span class="line">        merge(array, left, mid, right);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*合并两个有序队列*/</span></span><br><span class="line"><span class="keyword">private</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; <span class="keyword">void</span> <span class="title function_">merge</span><span class="params">(T[] array, <span class="type">int</span> left, <span class="type">int</span> mid, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">    System.arraycopy(array, left, aux, left, right + <span class="number">1</span> - left);</span><br><span class="line">    <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> left, j = mid + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">k</span> <span class="operator">=</span> left; k &lt;= right; k++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (i &gt; mid) &#123;</span><br><span class="line">            array[k] = (T) aux[j++];</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (j &gt; right) &#123;</span><br><span class="line">            array[k] = (T) aux[i++];</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (SortUtils.less(aux[i], aux[j])) &#123;</span><br><span class="line">            array[k] = (T) aux[i++];</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            array[k] = (T) aux[j++];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a name="E7wpR"></a></li></ol><h4 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h4><p>快速排序是处理大数据最快的排序算法之一，因为它的平均时间复杂度是 O(nlogn) 且 O(nlogn) 中隐含的常数因子很小。<br />算法步骤：</p><ol><li>从数组中挑出一个元素，称为 “基准”（pivot）（挑选基准值时要随机挑选，避免遇到基本有序数组时间复杂度退化到 O(n²)）；</li><li>重新排序数组，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。这个称为分区（partition）操作，在分区之后该基准就处于排序后的位置；</li><li>递归地（recursive）把小于基准值元素的子数组和大于基准值元素的子数组排序。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; T[] sort(T[] array) &#123;</span><br><span class="line">    doSort(array, <span class="number">0</span>, array.length - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> array;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; <span class="keyword">void</span> <span class="title function_">doSort</span><span class="params">(T[] array, <span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span>(left &lt; right) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">pivot</span> <span class="operator">=</span> randomPartition(array, left, right);</span><br><span class="line">        doSort(array, left, pivot - <span class="number">1</span>);</span><br><span class="line">        doSort(array, pivot + <span class="number">1</span>, right);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*随机化数组以避免基本有序的数组*/</span></span><br><span class="line"><span class="keyword">private</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; <span class="type">int</span> <span class="title function_">randomPartition</span><span class="params">(T[] array, <span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">randomIndex</span> <span class="operator">=</span> left + (<span class="type">int</span>) (Math.random() * (right - left + <span class="number">1</span>));</span><br><span class="line">    SortUtils.swap(array, randomIndex, left);</span><br><span class="line">    <span class="keyword">return</span> partition(array, left, right);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; <span class="type">int</span> <span class="title function_">partition</span><span class="params">(T[] array, <span class="type">int</span> left, <span class="type">int</span> right)</span> &#123;</span><br><span class="line">    <span class="type">T</span> <span class="variable">pivot</span> <span class="operator">=</span> array[left];<span class="comment">// 选择最左面的元素作为分界点</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> left + <span class="number">1</span>;<span class="comment">// 跳过分界点</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> right;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(i &lt;= j) &#123;</span><br><span class="line">        <span class="comment">// 从左到右找到第一个大于等于分界点的元素</span></span><br><span class="line">        <span class="keyword">while</span>(i &lt;= right &amp;&amp; SortUtils.less(array[i], pivot)) &#123;</span><br><span class="line">            ++i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 从右到左找到第一个小于等于分界点的元素</span></span><br><span class="line">        <span class="keyword">while</span>(j &gt;= left + <span class="number">1</span> &amp;&amp; SortUtils.less(pivot, array[j])) &#123;</span><br><span class="line">            --j;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(i &lt;= j) &#123;</span><br><span class="line">            SortUtils.swap(array, i, j);</span><br><span class="line">            ++i;</span><br><span class="line">            --j;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    SortUtils.swap(array, left, j);<span class="comment">// 将分界点放到正确的位置上</span></span><br><span class="line">    <span class="keyword">return</span> j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a name="eIEl8"></a></li></ol><h4 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h4><p>堆的性质：子结点的键值总是小于（或者大于）它的父节点。</p><ol><li>创建一个大根堆 H[0……n-1]；</li><li>把堆首（最大值）和堆尾互换；</li><li>把堆的尺寸缩小 1，并调用 shiftDown(1)，目的是下沉根节点，维护大根堆；</li><li>重复步骤 2，直到堆的尺寸为 1。<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; T[] sort(T[] array) &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">n</span> <span class="operator">=</span> array.length;</span><br><span class="line">    heapify(array, n);</span><br><span class="line">    <span class="comment">// 大根堆转换成递增数组，不开辟额外空间</span></span><br><span class="line">    <span class="keyword">while</span> (n &gt; <span class="number">1</span>) &#123;</span><br><span class="line">        swap(array, <span class="number">1</span>, n--);</span><br><span class="line">        siftDown(array, <span class="number">1</span>, n);<span class="comment">// 根节点下沉，维护大根堆</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> array;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*构造大根堆*/</span></span><br><span class="line"><span class="keyword">private</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; <span class="keyword">void</span> <span class="title function_">heapify</span><span class="params">(T[] array, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="comment">// 由底向上遍历非叶子节点元素</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">k</span> <span class="operator">=</span> n / <span class="number">2</span>; k &gt;= <span class="number">1</span>; k--) &#123;</span><br><span class="line">        siftDown(array, k, n);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*堆节点下沉*/</span></span><br><span class="line"><span class="keyword">private</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; <span class="keyword">void</span> <span class="title function_">siftDown</span><span class="params">(T[] array, <span class="type">int</span> k, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="comment">// k节点有左孩子节点</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="number">2</span> * k &lt;= n) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">2</span> * k;</span><br><span class="line">        <span class="comment">// k节点有右孩子节点且右孩子节点比左孩子节点大</span></span><br><span class="line">        <span class="keyword">if</span> (j &lt; n &amp;&amp; less(array, j, j + <span class="number">1</span>)) &#123;</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!less(array, k, j)) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        swap(array, k, j);</span><br><span class="line">        k = j;<span class="comment">// 为了继续下沉</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> &lt;T&gt; <span class="keyword">void</span> <span class="title function_">swap</span><span class="params">(T[] array, <span class="type">int</span> i, <span class="type">int</span> j)</span> &#123;</span><br><span class="line">    <span class="type">T</span> <span class="variable">swap</span> <span class="operator">=</span> array[i - <span class="number">1</span>];</span><br><span class="line">    array[i - <span class="number">1</span>] = array[j - <span class="number">1</span>];</span><br><span class="line">    array[j - <span class="number">1</span>] = swap;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> &lt;T <span class="keyword">extends</span> <span class="title class_">Comparable</span>&lt;T&gt;&gt; <span class="type">boolean</span> <span class="title function_">less</span><span class="params">(T[] array, <span class="type">int</span> firstElement, <span class="type">int</span> secondElement)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> array[firstElement - <span class="number">1</span>].compareTo(array[secondElement - <span class="number">1</span>]) &lt; <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;排序算法可以分为内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因为排序的数据很大，不能一次容纳全部的排序记录，在排序过程中需要访问外存。常见的内部排序算法有：冒泡排序、选择排序、插入排序、归并排序、快速排序、堆排序等。用一张图概括：&lt;br /&gt;&lt;img</summary>
      
    
    
    
    <category term="数据结构与算法" scheme="http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="http://example.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>算法：递归算法复杂度分析</title>
    <link href="http://example.com/2022/12/09/%E7%AE%97%E6%B3%95%EF%BC%9A%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/"/>
    <id>http://example.com/2022/12/09/%E7%AE%97%E6%B3%95%EF%BC%9A%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/</id>
    <published>2022-12-09T12:10:00.000Z</published>
    <updated>2025-10-24T21:20:54.871Z</updated>
    
    <content type="html"><![CDATA[<p><a name="C9SBI"></a></p><h4 id="求-x-的-n-次方"><a href="#求-x-的-n-次方" class="headerlink" title="求 x 的 n 次方"></a>求 x 的 n 次方</h4><p>最直观的方式是一个 for 循环求出结果，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function1</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">1</span>;  <span class="comment">// 注意 任何数的0次方等于1</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">        result = result * x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>时间复杂度为 O(n)，使用递归算法效率更好，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function2</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>; <span class="comment">// return 1 同样是因为0次方是等于1的</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> function2(x, n - <span class="number">1</span>) * x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>递归算法的时间复杂度：递归的次数 * 每次递归中的操作次数。<br />每次 n - 1，递归了 n 次，时间复杂度是 O(n)，每次进行了一个乘法操作，乘法操作的时间复杂度是常数 O(1)，所以代码的时间复杂度是 n × 1 &#x3D; O(n)。<br />时间复杂度没有达到预期，于是又写出了如下的递归算法的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function3</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">1</span>) <span class="keyword">return</span> x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (n % <span class="number">2</span> == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> function3(x, n / <span class="number">2</span>) * function3(x, n / <span class="number">2</span>)*x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> function3(x, n / <span class="number">2</span>) * function3(x, n / <span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>来分析一下，首先看递归了多少次，可以把递归抽象成一棵满二叉树。这个算法可以用一棵满二叉树来表示如图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685753223936-7b1751c7-bea2-4695-98ec-5f85156d5fd2.png#averageHue=%23f7f7f7&clientId=ub380f7f0-2b53-4&from=paste&height=376&id=u50db4d77&originHeight=602&originWidth=1066&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=101662&status=done&style=none&taskId=u06c685e5-d22c-443a-91e1-1fae0aac402&title=&width=666.2000122070312"><br />当前这棵二叉树就是求 x 的 n 次方，n 为 16 的情况，这棵树上每一个节点就代表着一次递归并进行了一次相乘操作，所以这棵树上有多少个节点就进行了多少次递归。<br />这棵满二叉树的节点数量是 23 + 22 + 21 + 20 &#x3D; 15，可以发现：这其实是等比数列的求和公式，这个结论在二叉树相关的面试题里经常出现。<br />总结点数：n - 1，时间复杂度忽略掉常数项 - 1 之后，递归算法的时间复杂度依然是 O(n)，仍然没有达到预期，这份代码其实有重复计算的部分，于是又写出如下递归算法的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">function4</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">1</span>) <span class="keyword">return</span> x;</span><br><span class="line">    <span class="type">int</span> <span class="variable">t</span> <span class="operator">=</span> function4(x, n / <span class="number">2</span>);<span class="comment">// 这里相对于function3，是把这个递归操作抽取出来</span></span><br><span class="line">    <span class="keyword">if</span> (n % <span class="number">2</span> == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> t * t * x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> t * t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这里仅仅有一个递归调用，且每次都是 n &#x2F; 2，所以这里一共调用了 log 以 2 为底 n 的对数次。每次递归做的都是一次乘法操作，这也是一个常数项的操作，所以这个递归算法的时间复杂度才是真正的 O(logn)。<br />注意不要一看到递归就想到 O(logn)，对于 function3 这样的递归实现，很容易让人感觉这是 O(logn) 的时间复杂度，但其实这是 O(n) 的算法。<br />这道题目非常简单，但是又很考究算法的功底，特别是对递归的理解。<br />大厂面试的时候最喜欢用“简单题”来考察候选人的算法功底，注意这里的“简单题”可并不一定真的简单。<br><a name="QgqcR"></a></p><h4 id="求斐波那契数列"><a href="#求斐波那契数列" class="headerlink" title="求斐波那契数列"></a>求斐波那契数列</h4><p>求斐波那契数的递归写法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">fibonacci</span><span class="params">(<span class="type">int</span> i)</span> &#123;</span><br><span class="line">   <span class="keyword">if</span>(i &lt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">   <span class="keyword">if</span>(i == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">   <span class="keyword">return</span> fibonacci(i-<span class="number">1</span>) + fibonacci(i-<span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于递归算法来说代码一般都比较简短，从算法逻辑上看所用的存储空间也非常少，但运行时需要内存可不见得会少。<br><a name="iLo5u"></a></p><h5 id="时间复杂度分析"><a href="#时间复杂度分析" class="headerlink" title="时间复杂度分析"></a>时间复杂度分析</h5><p>递归算法的时间复杂度要看: 递归的次数 * 每次递归的时间复杂度。<br />上面的代码每次递归都是 O(1) 的操作，抽象成一棵递归树，如图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685757293499-c3b9ac9c-b738-4877-b22f-94dad793c779.png#averageHue=%23f6f6f6&clientId=u26fe1e31-3882-4&from=paste&height=399&id=uae5755f0&originHeight=674&originWidth=937&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=115362&status=done&style=none&taskId=uc8b1b990-9297-460b-9d11-7c6bfb9fb95&title=&width=555.2000122070312"><br />从图中可以看出 f(5) 是由 f(4) 和 f(3) 相加而来，那么 f(4) 是由 f(3) 和 f(2) 相加而来，以此类推。<br />在这棵二叉树中每一个节点都是一次递归，一棵深度为 k 的二叉树最多可以有 2k - 1 个节点，所以该递归算法的时间复杂度为 O(2n)，这个复杂度是非常大的，随着n的增大耗时是指数上升的。<br />所以这种求斐波那契数的算法看似简洁，其实时间复杂度非常高，一般不推荐这样来实现斐波那契。<br />其实罪魁祸首就是这里的两次递归，导致了时间复杂度以指数上升。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> fibonacci(i-<span class="number">1</span>) + fibonacci(i-<span class="number">2</span>);</span><br></pre></td></tr></table></figure><p>优化思路主要是减少递归的调用次数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">fibonacci</span><span class="params">(<span class="type">int</span> first, <span class="type">int</span> second, <span class="type">int</span> n)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (n &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; <span class="number">3</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (n == <span class="number">3</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> first + second;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> fibonacci(second, first + second, n - <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里相当于用 first 和 second 来记录当前相加的两个数值，此时就不用两次递归了。<br />因为每次递归的时候 n 减 1，即只是递归了 n 次，所以时间复杂度是 O(n)。同理递归的深度依然是 n，每次递归所需的空间也是常数，所以空间复杂度依然是 O(n)。<br><a name="Elvjk"></a></p><h5 id="空间复杂度分析"><a href="#空间复杂度分析" class="headerlink" title="空间复杂度分析"></a>空间复杂度分析</h5><p>递归算法的空间复杂度 &#x3D; 每次递归的空间复杂度 * 递归深度。<br />因为每次递归所需的空间都被压到调用栈里（这是内存管理里面的数据结构，和算法里的栈原理是一样的），递归结束一次这个栈就会把本次递归的数据弹出去，所以这个栈最大的长度就是递归的深度。<br />从代码中可以看出每次递归所需要的空间大小都是一样的，所以每次递归中需要的空间是一个常量，并不会随着 n 的变化而变化，每次递归的空间复杂度就是 O(1)。<br />递归的深度如图所示：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685766648472-855b2ea2-2389-4f9c-ab6f-4ebbd5a4737d.png#averageHue=%23f6f6f6&clientId=u26fe1e31-3882-4&from=paste&height=389&id=uf8ae9a89&originHeight=486&originWidth=937&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=110481&status=done&style=none&taskId=ue34c58df-61ad-4557-ab45-1073e8072f2&title=&width=749.6"><br />递归第 n 个斐波那契数递归调用栈的深度就是 n，每次递归的空间复杂度是 O(1)， 调用栈深度为 n，所以递归代码的空间复杂度就是 O(n)。<br />求斐波那契数列方法的性能做分析，如题：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685766796628-d26ec911-d63e-4cb4-a0bd-e72df6a5bc0d.png#averageHue=%23d5d9dc&clientId=u26fe1e31-3882-4&from=paste&height=215&id=u4e02c419&originHeight=586&originWidth=1061&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=105827&status=done&style=none&taskId=uf7b1573c-6af2-4932-bf14-987d3689b07&title=&width=389.20001220703125"><br />可以看出求斐波那契数时使用递归算法并不一定在性能上是最优的，但递归确实简化了代码层面的复杂度。<br><a name="Q2O2J"></a></p><h4 id="二分法（递归实现）"><a href="#二分法（递归实现）" class="headerlink" title="二分法（递归实现）"></a>二分法（递归实现）</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">binary_search</span><span class="params">( <span class="type">int</span> arr[], <span class="type">int</span> l, <span class="type">int</span> r, <span class="type">int</span> x)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (r &gt;= l) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">mid</span> <span class="operator">=</span> l + (r - l) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (arr[mid] == x)</span><br><span class="line">            <span class="keyword">return</span> mid;</span><br><span class="line">        <span class="keyword">if</span> (arr[mid] &gt; x)</span><br><span class="line">            <span class="keyword">return</span> binary_search(arr, l, mid - <span class="number">1</span>, x);</span><br><span class="line">        <span class="keyword">return</span> binary_search(arr, mid + <span class="number">1</span>, r, x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>二分查找的时间复杂度是 O(logn)，二分查找的空间复杂度依然看每次递归的空间复杂度和递归的深度。<br />每次递归的空间复杂度可以看出主要就是参数里传入的这个 arr 数组，但需要注意的是函数传递数组参数，不是整个数组拷贝一份传入函数而是传入的数组地址。<br />也就是说每一层递归都是公用一块数组地址空间的，所以每次递归的空间复杂度是常数即：O(1)。再来看递归的深度，二分查找的递归深度是 logn ，递归深度就是调用栈的长度，那么这段代码的空间复杂度为 1 * logn &#x3D; O(logn)。<br />要注意语言在传递函数参数时是拷贝整个数值还是拷贝地址，如果是拷贝整个数值，那么该二分法的空间复杂度就是 O(nlogn)。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;C9SBI&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;求-x-的-n-次方&quot;&gt;&lt;a href=&quot;#求-x-的-n-次方&quot; class=&quot;headerlink&quot; title=&quot;求 x 的 n 次方&quot;&gt;&lt;/a&gt;求 x 的 n 次方&lt;/h4&gt;&lt;p&gt;最直观的方式是一个 </summary>
      
    
    
    
    <category term="数据结构与算法" scheme="http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="http://example.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>算法：复杂度分析</title>
    <link href="http://example.com/2022/12/09/%E7%AE%97%E6%B3%95%EF%BC%9A%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/"/>
    <id>http://example.com/2022/12/09/%E7%AE%97%E6%B3%95%EF%BC%9A%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/</id>
    <published>2022-12-09T12:00:00.000Z</published>
    <updated>2025-10-24T21:20:54.871Z</updated>
    
    <content type="html"><![CDATA[<p><a name="Q9TTG"></a></p><h4 id="时间复杂度分析"><a href="#时间复杂度分析" class="headerlink" title="时间复杂度分析"></a>时间复杂度分析</h4><p>假设算法的问题规模为 n，那么操作单元数量便用函数 f(n) 来表示，随着数据规模 n 的增大，算法执行时间的增长率和 f(n) 的增长率相同，这称作为算法的渐近时间复杂度，简称时间复杂度，记为 O(f(n)) 。<br><a name="ehHas"></a></p><h5 id="什么是大-O？"><a href="#什么是大-O？" class="headerlink" title="什么是大 O？"></a>什么是大 O？</h5><p>大 O 用来表示上界，当用它作为算法的最坏情况运行时间的上界，就是对任意数据输入的运行时间的上界。<br />以插入排序为例，插入排序的时间复杂度是 O(n²) 。输入数据的形式对程序运算时间是有很大影响的，在数据本来有序的情况下时间复杂度是 O(n)，但如果数据是逆序的，插入排序的时间复杂度就是 O(n²)，也就是对于所有输入情况来说，最坏是 O(n²) 的时间复杂度，所以称插入排序的时间复杂度为 O(n²)。<br />同理再看一下快速排序，都知道快速排序是 O(nlogn) 的，但是当数据已经有序的情况下快速排序的时间复杂度是O(n²) 的，所以严格从大O的定义来讲快速排序的时间复杂度应该是 O(n²)。但是依然说快速排序是 O(nlogn)的时间复杂度，这个就是业内的一个默认规定，这里说的 O 代表的就是一般情况，而不是严格的上界。<br />主要关心的还是一般情况下的数据形式，面试中说算法的时间复杂度是多少指的都是一般情况，但是如果面试官和我们深入探讨一个算法的实现以及性能的时候，就要时刻想着数据用例的不一样时间复杂度也是不同的，这一点是一定要注意的。<br><a name="pIiZK"></a></p><h5 id="不同数据规模的差异"><a href="#不同数据规模的差异" class="headerlink" title="不同数据规模的差异"></a>不同数据规模的差异</h5><p>如下图中可以看出不同算法的时间复杂度在不同数据输入规模下的差异。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685690040395-38d88111-f2c3-497d-bd73-3a87875f13ee.png#averageHue=%23f0efef&clientId=ufe484a7d-cb79-4&from=paste&height=353&id=uf8a393ab&originHeight=733&originWidth=1161&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=153592&status=done&style=none&taskId=u6565e1e6-507a-492b-8718-6ac0e40dc15&title=&width=559.2000122070312"><br />在决定使用哪些算法的时候不是时间复杂越低的越好（因为简化后的时间复杂度忽略了常数项等等），还要考虑数据规模，如果数据规模很小甚至 O(n²) 的算法要比 O(n) 的更合适（在有常数项的时候）。<br />就像上图中 O(5n²) 和 O(100n) 在 n 为20之前 很明显 O(5n²) 是更优的，所花费的时间也是最少的。<br />为什么在计算时间复杂度的时候要忽略常数项系数？<br />因为大 O 就是数据量级突破一个点且数据量级非常大的情况下所表现出的时间复杂度，这个数据量也就是常数项系数已经不起决定性作用的数据量。例如上图中 20 就是那个点，n 只要大于 20 常数项系数已经不起决定性作用了。<br />所以时间复杂度都是省略常数项系数的，因为一般情况下都是默认数据规模足够大，基于这样的事实，给出的算法时间复杂度的排行如下所示：<br />O(1) 常数阶 &lt; O(logn) 对数阶 &lt; O(n) 线性阶 &lt; O(nlogn) 线性对数阶 &lt; O(n²) 平方阶 &lt; O(n3) 立方阶 &lt; O(2n) 指数阶<br />但是也要注意大常数，如果这个常数非常大，那么常数就是不得不考虑的因素了。<br><a name="PYjPT"></a></p><h5 id="复杂表达式的化简"><a href="#复杂表达式的化简" class="headerlink" title="复杂表达式的化简"></a>复杂表达式的化简</h5><p>有时候计算时间复杂度不是简单的 O(n) 或者 O(n²)， 而是一个复杂的表达式，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">O(2*n² + 10*n + 1000)</span><br></pre></td></tr></table></figure><ul><li><p>去掉运行时间中的加法常数项 （因为常数项并不会因为 n 的增大而增加计算机的操作次数）；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">O(2*n² + 10*n)</span><br></pre></td></tr></table></figure></li><li><p>去掉常数系数（数据量级非常大的情况下常数项系数就不起决定性作用了）；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">O(n² + n)</span><br></pre></td></tr></table></figure></li><li><p>只保留最高项，去掉数量级小一级的 n（因为 n² 的数据规模远大于 n），最终简化为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">O(n²)</span><br></pre></td></tr></table></figure><p><a name="QHhvz"></a></p></li></ul><h5 id="O-logn-中的-log-是以什么为底？"><a href="#O-logn-中的-log-是以什么为底？" class="headerlink" title="O(logn) 中的 log 是以什么为底？"></a>O(logn) 中的 log 是以什么为底？</h5><p>O(logn) 是忽略底数的描述。假如有两个算法的时间复杂度，分别是 log 以 2 为底 n 的对数和 log 以 10 为底 n 的对数。高中数学中，以 2 为底 n 的对数 &#x3D; 以 2 为底 10 的对数 * 以 10 为底 n 的对数。而以 2 为底 10 的对数是一个常数，计算时间复杂度是忽略常数项系数的。<br />抽象一下就是在时间复杂度的计算过程中，log 以 i 为底 n 的对数等于 log 以 j 为底 n 的对数，所以忽略了 i，直接说是 logn。<br><a name="X40Ql"></a></p><h5 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h5><p>题目描述：找出 n 个字符串中相同的两个字符串（假设这里只有两个相同的字符串）。<br />如果是暴力枚举的话，这里有时会忽略字符串比较的时间消耗，字符串比较并不像 int 型数字做比较那么简单，除了 n² 次的遍历次数外，字符串比较依然要消耗 m 次操作（m 是字母串的长度），所以时间复杂度是 O(m × n × n)。<br />如果是其他的解题思路，先对 n 个字符串按字典序来排序，排序后 n 个字符串就是有序的，意味着两个相同的字符串就是挨在一起，然后再遍历一遍 n 个字符串，这样就找到两个相同的字符串了。<br />快速排序时间复杂度为 O(nlogn)，依然要考虑字符串的长度是 m，那么快速排序每次的比较都要有 m 次的字符比较的操作，就是 O(m × n × log n) 。<br />之后还要遍历一遍这 n 个字符串找出两个相同的字符串，别忘了遍历的时候依然要比较字符串，所以总共的时间复杂度是 O(m × n × logn + n × m)。<br />对 O(m × n × log n + n × m) 进行简化操作，把 m × n 提取出来变成 O(m × n × (logn + 1))，再省略常数项，最后的时间复杂度是 O(m × n × log n)。<br />很明显 O(m × n × logn) 要优于 O(m × n × n) 的。<br />所以先把字符串集合排序再遍历一遍找到两个相同字符串的方法要比直接暴力枚举的方式更快。<br />当然这不是这道题目的最优解，仅仅是用这道题目来讲解一下时间复杂度。<br><a name="ZWiv9"></a></p><h4 id="空间复杂度分析"><a href="#空间复杂度分析" class="headerlink" title="空间复杂度分析"></a>空间复杂度分析</h4><p>空间复杂度是对一个算法在运行过程中占用内存空间大小的量度，记做 S(n)&#x3D;O(f(n))。<br />空间复杂度记作 S(n) 依然使用大 O 来表示。利用程序的空间复杂度可以对程序运行中需要多少内存有个预估。<br />空间复杂度是考虑程序运行时占用内存的大小，而不是可执行文件的大小。<br />空间复杂度并不能精准的掌握程序的内存使用大小，很多因素会影响程序真正内存使用大小，例如编译器的内存对齐，编程语言容器的底层实现等等都会影响到程序内存的开销。<br />一般 OJ 对程序运行时的所消耗的内存都有限制，为了避免内存超出限制，这就需要对算法占用多大的内存有一个大体的预估。同样在工程实践中计算机的内存空间也不是无限的，需要工程师对软件运行时所使用的内存有一个大体评估，这都需要用到算法空间复杂度的分析。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    j++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>随着 n 的变化所需开辟的内存空间并不会随着 n 的变化而变化。即此算法空间复杂度为一个常量，所以表示为大 O(1)。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] a = <span class="keyword">new</span> <span class="title class_">int</span>[n];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    a[i] = i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当消耗空间和输入参数 n 保持线性增长，这样的空间复杂度为 O(n)。<br />定义一个数组，这个数组占用的大小为 n，虽然有一个 for 循环，但没有再分配新的空间，因此这段代码的空间复杂度主要看第一行即可，随着 n 的增大开辟的内存大小呈线性增长，即 O(n)。<br />空间复杂度是 logn 的情况有些特殊，在递归的时候会出现空间复杂度为 logn 的情况。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;Q9TTG&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;时间复杂度分析&quot;&gt;&lt;a href=&quot;#时间复杂度分析&quot; class=&quot;headerlink&quot; title=&quot;时间复杂度分析&quot;&gt;&lt;/a&gt;时间复杂度分析&lt;/h4&gt;&lt;p&gt;假设算法的问题规模为 n，那么操作单元数量便</summary>
      
    
    
    
    <category term="数据结构与算法" scheme="http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="http://example.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>创建型模式：单例模式</title>
    <link href="http://example.com/2022/12/08/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"/>
    <id>http://example.com/2022/12/08/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F%EF%BC%9A%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</id>
    <published>2022-12-08T10:00:00.000Z</published>
    <updated>2025-10-24T21:20:54.869Z</updated>
    
    <content type="html"><![CDATA[<p>保证一个类只有一个实例，并且提供一个可以全局访问的入口。<br><a name="qHenn"></a></p><h4 id="五种实现方式"><a href="#五种实现方式" class="headerlink" title="五种实现方式"></a>五种实现方式</h4><p><a name="OpM7w"></a></p><h5 id="饿汉式"><a href="#饿汉式" class="headerlink" title="饿汉式"></a>饿汉式</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EagerInitializedSingleton</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">EagerInitializedSingleton</span> <span class="variable">instance</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">EagerInitializedSingleton</span>();</span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">EagerInitializedSingleton</span><span class="params">()</span>&#123;&#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> EagerInitializedSingleton <span class="title function_">getInstance</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Singleton 类的实例是在类加载时创建的，这是创建单例类最简单的方法，但是它有一个缺点，即使客户端应用程序可能不使用它，也会创建实例。以空间换时间，不存在线程安全问题。<br><a name="GkzzH"></a></p><h5 id="懒汉式"><a href="#懒汉式" class="headerlink" title="懒汉式"></a>懒汉式</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LazyInitializedSingleton</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> LazyInitializedSingleton instance;</span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">LazyInitializedSingleton</span><span class="params">()</span>&#123;&#125;;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> LazyInitializedSingleton <span class="title function_">getInstance</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(instance == <span class="literal">null</span>)&#123;</span><br><span class="line">            instance = <span class="keyword">new</span> <span class="title class_">LazyInitializedSingleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>懒汉式实现在单线程环境中工作得很好，但是在多线程系统中，如果多个线程同时位于 if 条件中，就可能导致问题，它会破坏单例模式，两个线程都会得到单例类的不同实例。以时间换空间，存在线程安全问题。<br><a name="qes7k"></a></p><h5 id="双重校验锁"><a href="#双重校验锁" class="headerlink" title="双重校验锁"></a>双重校验锁</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DoubleCheckLockingSingleton</span> &#123;</span><br><span class="line">    <span class="comment">//禁止指令重排序</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> DoubleCheckLockingSingleton instance;</span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">DoubleCheckLockingSingleton</span><span class="params">()</span>&#123;&#125;;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> DoubleCheckLockingSingleton <span class="title function_">getInstance</span> <span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">//返回单例，避免多余的加锁操作</span></span><br><span class="line">        <span class="keyword">if</span>(instance == <span class="literal">null</span>)&#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (DoubleCheckLockingSingleton.class)&#123;</span><br><span class="line">                <span class="comment">//防止多线程创建多个实例</span></span><br><span class="line">                <span class="keyword">if</span>(instance == <span class="literal">null</span>)&#123;</span><br><span class="line">                    instance = <span class="keyword">new</span> <span class="title class_">DoubleCheckLockingSingleton</span>();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一次校验是否为null：如果单例已经创建了，直接调用synchronized加锁比较消耗性能。所以首先判断有没有创建，没创建再加锁。<br />第二次校验是否为null：防止多线程创建多个实例，例：在未创建实例的情况下，A线程和B线程都通过了第一次校验，这时如果通过竞争B线程拿到了锁就会执行一次new操作，生成一个实例，然后B执行完了A就会拿到资源的锁，如果没有第二次判断的话，这时A线程也会执行一次new操作，这里就出现了第二个类实例，违背了单例原则。<br />volatile<br />作用：禁止指令重排序，避免拿到没完成初始化的对象。<br />注意：singleton &#x3D; new Singleton() 并不是原子操作，至少做了以下 3 件事</p><ol><li>给 singleton 分配内存空间；</li><li>调用 Singleton 的构造函数等，来初始化 singleton；</li><li>将 singleton 对象指向分配的内存空间（执行完这步 singleton 就不是 null 了）。</li></ol><p>因为存在指令重排序的优化，第 2 步和第 3 步的顺序是不能保证的，最终的执行顺序，可能是 1-2-3，也有可能是 1-3-2。如果是 1-3-2，那么在第 3 步执行完以后，singleton 就不是 null 了，可是这时第 2 步并没有执行，singleton 对象未完成初始化。假设此时线程 2 进入 getInstance 方法，由于 singleton 已经不是 null 了，所以会通过第一重检查并直接返回，但其实这时的 singleton 并没有完成初始化，读取到的对象并不完整。<br><a name="xXil5"></a></p><h5 id="静态内部类"><a href="#静态内部类" class="headerlink" title="静态内部类"></a>静态内部类</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StaticInnerClassSingleton</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">StaticInnerClassSingleton</span><span class="params">()</span>&#123;&#125;;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SingletonHelper</span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">StaticInnerClassSingleton</span> <span class="variable">INSTANCE</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StaticInnerClassSingleton</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> StaticInnerClassSingleton <span class="title function_">getInstance</span> <span class="params">()</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> SingletonHelper.INSTANCE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>静态内部类的优点：外部类加载时并不需要立即加载内部类，内部类不被加载则不会去初始化 INSTANCE，故而不占内存。即当 StaticInnerClassSingleton 第一次被加载时并不需要去加载 SingletonHelper，只有当getInstance() 方法第一次被调用时才会去初始化 INSTANCE，第一次调用 getInstance() 方法会导致虚拟机加载 SingletonHelper 类，这种方法不仅能确保线程安全，也能保证单例的唯一性，同时也延迟了单例的实例化。<br><a name="XJPvP"></a></p><h5 id="枚举"><a href="#枚举" class="headerlink" title="枚举"></a>枚举</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">EnumSingleton</span> &#123;</span><br><span class="line">    INSTANCE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>枚举与普通类一样，都能拥有字段与方法，而且枚举实例创建是线程安全的，在任何情况下，它都是一个单例。可以直接以 EnumSingleton.INSTANCE 的方式调用。<br><a name="bRhc2"></a></p><h4 id="统一特征"><a href="#统一特征" class="headerlink" title="统一特征"></a>统一特征</h4><ul><li>私有的 Singleton 类型的 singleton 对象；</li><li>私有的构造方法，为了防止调用构造函数来生成实例；</li><li>public 的 getInstance 方法，可通过这个方法获取到单例。<br><a name="LIXD0"></a></li></ul><h4 id="典型用例"><a href="#典型用例" class="headerlink" title="典型用例"></a>典型用例</h4><ul><li>日志类</li><li>数据库连接类</li><li>文件系统类</li><li>缓存类</li><li>线程池类<br><a name="jRogd"></a></li></ul><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>保证一个类只有一个实例；</li><li>获得了一个指向该实例的全局访问节点；</li><li>仅在首次请求单例对象时对其进行初始化。<br><a name="qk5gO"></a></li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li>违反了单一职责原则(SRP)；</li><li>可能掩盖不良设计， 比如程序各组件之间相互了解过多等；</li><li>在多线程环境下需要进行特殊处理， 避免多个线程多次创建单例对象；</li><li>单例的客户端代码单元测试可能会比较困难。<br><a name="B6aoC"></a></li></ul><h4 id="ThreadLocal-线程单例"><a href="#ThreadLocal-线程单例" class="headerlink" title="ThreadLocal 线程单例"></a>ThreadLocal 线程单例</h4><p>并不能保证整个应用全局唯一，但是可以保证线程唯一（两个线程拿到的对象并不是同一个对象，但是同一线程能保证拿到的是同一个对象）。<br />ThreadLocal 是基于 ThreadLocalMap 来实现的，在调用 get 方法的时候，默认走的就是 ThreadLocalMap，不用指定 key，它维持了线程间的隔离。<br />ThreadLocal 隔离了多个线程对数据的访问冲突。对多线程资源共享的问题，假如使用的是同步锁，那么就是以时间换空间的方式；那假如使用 ThreadLocal，那就是用空间换时间的方式。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;保证一个类只有一个实例，并且提供一个可以全局访问的入口。&lt;br&gt;&lt;a name=&quot;qHenn&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;五种实现方式&quot;&gt;&lt;a href=&quot;#五种实现方式&quot; class=&quot;headerlink&quot; title=&quot;五种实现方式&quot;&gt;&lt;/a&gt;五种实现方式&lt;/</summary>
      
    
    
    
    <category term="Java设计模式" scheme="http://example.com/categories/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
    <category term="创建型模式" scheme="http://example.com/tags/%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>进程管理：进程间通信方式</title>
    <link href="http://example.com/2022/12/07/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%EF%BC%9A%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/"/>
    <id>http://example.com/2022/12/07/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%EF%BC%9A%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/</id>
    <published>2022-12-07T13:50:00.000Z</published>
    <updated>2025-10-24T21:20:54.873Z</updated>
    
    <content type="html"><![CDATA[<p>每个进程的用户地址空间都是独立的，一般是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686561987638-67f3419f-7443-4585-a7b4-fe28f6b8cefe.png#averageHue=%23b9bcb8&clientId=u5e5af460-cc70-4&from=paste&height=237&id=u37b60854&originHeight=506&originWidth=1113&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=140892&status=done&style=none&taskId=u03a8d8d6-25dd-4802-bead-059177cfe1c&title=&width=522"><br><a name="TgIIv"></a></p><h4 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h4><p>学过 Linux 命令肯定很熟悉「|」这个竖线。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ps auxf | grep mysql</span><br></pre></td></tr></table></figure><p>上面命令行里的「|」竖线就是一个管道，它的功能是将前一个命令（ps auxf）的输出作为后一个命令（grep mysql）的输入，从功能描述上可以看出管道传输数据是单向的，如果想相互通信需要创建两个管道才行。<br />上面这种管道是没有名字的，所以「|」表示的管道称为匿名管道，用完了就销毁。<br />管道还有另外一个类型是命名管道，也被叫做 FIFO，因为数据是先进先出的传输方式。<br />在使用命名管道前先需要通过 mkfifo 命令来创建并且指定管道名字：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">mkfifo</span> myPipe</span><br></pre></td></tr></table></figure><p>myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念管道也是以文件的方式存在，可以用 ls 看一下这个文件的类型是 p，也就是 pipe（管道） 的意思：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">ls</span> -l</span><br><span class="line">prw-r--r--. 1 root    root         0 Jul 17 02:45 myPipe</span><br></pre></td></tr></table></figure><p>接下来往 myPipe 这个管道写入数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> <span class="string">&quot;hello&quot;</span> &gt; myPipe  // 将数据写进管道</span><br><span class="line">                         // 停住了 ...</span><br></pre></td></tr></table></figure><p>操作后会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后命令才可以正常退出。<br />于是执行另外一个命令来读取这个管道里的数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cat</span> &lt; myPipe  // 读取管道里的数据</span><br><span class="line">hello</span><br></pre></td></tr></table></figure><p>可以看到管道里的内容被读取出来并打印在了终端上，另外一方面 echo 那个命令也正常退出了。<br />可以看出管道这种通信方式效率低，不适合进程间频繁地交换数据。它的好处是简单，同时也容易得知管道里的数据已经被另一个进程读取了。<br />匿名管道的创建需要通过下面这个系统调用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int pipe(int fd[2])</span><br></pre></td></tr></table></figure><p>这里表示创建一个匿名管道并返回两个描述符，一个是管道的读取端描述符 fd[0] 另一个是管道的写入端描述符 fd[1]。注意这个匿名管道是特殊的文件，只存在于内存不存于文件系统中。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686562773690-94544e2d-9103-4bb0-87d0-d54462bb6a96.png#averageHue=%23f8f2e1&clientId=u5e5af460-cc70-4&from=paste&height=279&id=u2cdffeea&originHeight=877&originWidth=906&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=165236&status=done&style=none&taskId=u4115438a-1ebc-4b73-8851-5d2835edbf2&title=&width=287.8000183105469"><br />所谓的管道就是内核里面的一串缓存。从管道的一段写入的数据实际上是缓存在内核中的，另一端读取也就是从内核中读取这段数据。另外管道传输的数据是无格式的流且大小受限。<br />可以使用 fork 创建子进程，创建的子进程会复制父进程的文件描述符，这样就做到了两个进程各有两个「 fd[0] 与 fd[1]」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686562946638-81525222-026b-42c1-8972-4003ca887f00.png#averageHue=%23f8f3e7&clientId=u5e5af460-cc70-4&from=paste&height=384&id=u6839d7cb&originHeight=790&originWidth=692&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=141912&status=done&style=none&taskId=u795cb158-7c6b-4b2b-b57d-c2324dd6319&title=&width=336.60003662109375"><br />管道只能一端写入另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入也都可以同时读出。为了避免这种情况通常的做法是：</p><ul><li>父进程关闭读取的 fd[0]，只保留写入的 fd[1]；</li><li>子进程关闭写入的 fd[1]，只保留读取的 fd[0]。</li></ul><p><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686563150459-49312d3b-fa05-44f5-8aa0-035899b4387d.png#averageHue=%23f9f4e9&clientId=u5e5af460-cc70-4&from=paste&height=367&id=u9c3c86c1&originHeight=806&originWidth=749&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=129778&status=done&style=none&taskId=ueb1b0b59-7ffd-4938-b7af-820aa2a6b56&title=&width=341.20001220703125"><br />所以如果需要双向通信就应该创建两个管道。<br />在 shell 里面执行 A | B 命令时 A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686563291009-43b7e45f-ca5c-43b9-a6b6-847f1219f3ae.png#averageHue=%23f9f4e9&clientId=u5e5af460-cc70-4&from=paste&height=392&id=uf6faa480&originHeight=804&originWidth=1243&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=198940&status=done&style=none&taskId=u1c1c07ff-4bd5-48b5-9d45-c68c04c47c4&title=&width=606"><br />所以在 shell 里通过「|」匿名管道将多个命令连接在一起实际上就是创建了多个子进程，那么在编写 shell 脚本时能使用一个管道搞定的事情就不要多用一个管道，这样可以减少创建子进程的系统开销。<br />匿名管道的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符来达到通信的目的。<br />命名管道在不相关的进程间也能相互通信。因为命令管道提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件可以相互通信。<br />不管是匿名管道还是命名管道进程写入的数据都是缓存在内核中，另一个进程读取数据时自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。<br><a name="KCa2u"></a></p><h4 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h4><p>管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。<br />对于这个问题消息队列的通信模式就可以解决。比如 A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理 B 进程要给 A 进程发送消息也是如此。<br />消息队列是保存在内核中的消息链表，在发送数据时会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。<br />消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统消息队列会一直存在，而前面提到的匿名管道的生命周期是随进程的创建而建立随进程的结束而销毁。<br />消息队列通信存在两点不足，一是通信不及时，二是消息有大小限制。<br />消息队列不适合传输比较大的数据，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位分别定义了一条消息的最大长度和一个队列的最大长度。<br />消息队列通信过程中存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时会发生从内核态拷贝数据到用户态的过程。<br><a name="sRP0a"></a></p><h4 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h4><p>消息队列的读取和写入的过程都会有发生用户态与内核态之间的消息拷贝过程。共享内存的方式就很好的解决了这一问题。<br />现代操作系统对于内存管理采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。<br />共享内存的机制就是拿出一块虚拟地址空间来映射到相同的物理内存中。这样这个进程写入的东西另外一个进程马上就能看到，不需要拷贝来拷贝去，大大提高了进程间通信的速度。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686565212938-6eb18d91-c32e-4d28-b2bc-d38c4c70615b.png#averageHue=%23f6eee5&clientId=u5e5af460-cc70-4&from=paste&height=350&id=u951d6f89&originHeight=870&originWidth=1008&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=148692&status=done&style=none&taskId=u9a94e646-396b-4c1f-a742-0f27c5def3f&title=&width=405"><br><a name="V8KCN"></a></p><h4 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h4><p>共享内存通信方式带来了新的问题，那就是如果多个进程同时修改同一个共享内存就很有可能冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。<br />为了防止多进程竞争共享资源而造成的数据错乱，所以需要保护机制，使得共享的资源在任意时刻只能被一个进程访问。信号量就实现了这一保护机制。<br />信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步而不是用于缓存进程间通信的数据。<br />信号量表示资源的数量，控制信号量的方式有两种原子操作：</p><ul><li>一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0 就表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;&#x3D; 0 就表明还有资源可使用，进程可正常继续执行；</li><li>另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 &lt;&#x3D; 0 就表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0 就表明当前没有阻塞中的进程。</li></ul><p>P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。<br />举个例子如果要使得两个进程互斥访问共享内存可以初始化信号量为 1。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686629041534-090b9e2f-0738-4dea-bb13-b9d0b5a3d013.png#averageHue=%23e4d2ca&clientId=ud1b4ab66-16af-4&from=paste&height=371&id=u50f62573&originHeight=832&originWidth=694&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=140061&status=done&style=none&taskId=u5c6132d7-74e0-4e19-98a9-0dc342fe929&title=&width=309.20001220703125"><br />具体的过程如下：</p><ul><li>进程 A 在访问共享内存前先执行了 P 操作，由于信号量的初始值为 1 故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存；</li><li>若此时进程 B 也想访问共享内存执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞；</li><li>直到进程 A 访问完共享内存才会执行 V 操作使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B 使得进程 B 可以访问共享内存，最后完成共享内存的访问后执行 V 操作使信号量恢复到初始值 1。</li></ul><p>信号初始化为 1 代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。<br />在多进程里每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候又希望多个进程能密切合作以实现一个共同的任务。<br />例如进程 A 是负责生产数据而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据进程 B 才能读取到数据，所以执行是有前后顺序的。<br />此时就可以用信号量来实现多进程同步的方式，可以初始化信号量为 0。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686629426598-1463996a-501c-46c3-b293-4b1eb7b5876f.png#averageHue=%23edefe8&clientId=ud1b4ab66-16af-4&from=paste&height=296&id=u904c15be&originHeight=533&originWidth=718&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=97987&status=done&style=none&taskId=u86231f33-7fd7-478e-a590-160f35f6d99&title=&width=399.3999938964844"><br />具体过程：</p><ul><li>如果进程 B 比进程 A 先执行了，那么执行到 P 操作时由于信号量初始值为 0 故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；</li><li>接着当进程 A 生产完数据后执行了 V 操作就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；</li><li>最后进程 B 被唤醒后意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。</li></ul><p>信号初始化为 0 代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。<br><a name="UWyNa"></a></p><h4 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h4><p>进程间通信都是常规状态下的工作模式。对于异常情况下的工作模式就需要用「信号」的方式来通知进程。<br />在 Linux 操作系统中为了响应各种各样的事件提供了几十种信号，分别代表不同的意义。<br />运行在 shell 终端的进程可以通过键盘输入某些组合键给进程发送信号。例如：</p><ul><li>Ctrl+C 产生 SIGINT 信号表示终止该进程；</li><li>Ctrl+Z 产生 SIGTSTP 信号表示停止该进程，但还未结束。</li></ul><p>如果进程在后台运行可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号例如：</p><ul><li>kill -9 1050 表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程。</li></ul><p>所以信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。<br />信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号就有下面这几种用户进程对信号的处理方式。</p><ul><li>执行默认操作。Linux 对每种信号都规定了默认操作，例如 SIGTERM 信号就是终止进程的意思；</li><li>捕捉信号。可以为信号定义一个信号处理函数。当信号发生时就执行相应的信号处理函数；</li><li>忽略信号。当不希望处理某些信号时就可以忽略该信号不做任何处理。有两个信号是应用进程无法捕捉和忽略的即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。<br><a name="d1T1z"></a></li></ul><h4 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h4><p>管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，要想跨网络与不同主机上的进程之间通信就需要 Socket 通信了。<br />实际上 Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。<br />创建 socket 的系统调用：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">socket</span><span class="params">(<span class="type">int</span> domain, <span class="type">int</span> type, <span class="type">int</span> protocal)</span></span><br></pre></td></tr></table></figure><p>三个参数分别代表：</p><ul><li>domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL&#x2F;AF_UNIX 用于本机；</li><li>type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流对应 TCP、SOCK_DGRAM 表示的是数据报对应 UDP、SOCK_RAW 表示的是原始套接字；</li><li>protocal 参数原本是用来指定通信协议的但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可。</li></ul><p>根据创建 socket 类型的不同通信的方式也就不同：</p><ul><li>实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；</li><li>实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；</li><li>实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外 AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket。<br><a name="HStmE"></a></li></ul><h5 id="TCP-协议通信的-socket-编程模型"><a href="#TCP-协议通信的-socket-编程模型" class="headerlink" title="TCP 协议通信的 socket 编程模型"></a>TCP 协议通信的 socket 编程模型</h5><p><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686630369712-688be719-f0a5-4daa-b7c4-9f8e9895bde3.png#averageHue=%23fcfbf2&clientId=ud1b4ab66-16af-4&from=paste&height=551&id=u6f14b51c&originHeight=938&originWidth=1169&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=271136&status=done&style=none&taskId=u40f292d7-1022-477d-9c45-6aed7f9e39b&title=&width=687"></p><ul><li>服务端和客户端初始化 socket 得到文件描述符；</li><li>服务端调用 bind 绑定 IP 地址和端口；</li><li>服务端调用 listen 进行监听；</li><li>服务端调用 accept 等待客户端连接；</li><li>客户端调用 connect 向服务器端的地址和端口发起连接请求；</li><li>服务端 accept 返回用于传输的 socket 的文件描述符；</li><li>客户端调用 write 写入数据；服务端调用 read 读取数据；</li><li>客户端断开连接时会调用 close，服务端 read 读取数据时就会读取到了 EOF，待处理完数据后服务端调用 close 表示连接关闭。</li></ul><p>需要注意的是服务端调用 accept 时连接成功会返回一个已完成连接的 socket，后续用来传输数据。<br />监听的 socket 和真正用来传送数据的 socket 是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。<br />成功连接建立之后双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。<br><a name="rQRyN"></a></p><h5 id="UDP-协议通信的-socket-编程模型"><a href="#UDP-协议通信的-socket-编程模型" class="headerlink" title="UDP 协议通信的 socket 编程模型"></a>UDP 协议通信的 socket 编程模型</h5><p><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686631324746-f9faa658-af93-4f2a-a695-318bdf7dec32.png#averageHue=%23faf7ee&clientId=ud1b4ab66-16af-4&from=paste&height=384&id=u43b16382&originHeight=920&originWidth=826&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=182623&status=done&style=none&taskId=u604193d7-c453-4e2e-b216-2777e11d30d&title=&width=344.79998779296875"><br />UDP 是没有连接的所以不需要三次握手，也就不需要像 TCP 那样调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。<br />对于 UDP 来说不需要维护连接，那么也就没有所谓的发送方和接收方甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。<br />每次通信时调用 sendto 和 recvfrom 都要传入目标主机的 IP 地址和端口。<br><a name="gdJPJ"></a></p><h5 id="本地进程间通信的-socket-编程模型"><a href="#本地进程间通信的-socket-编程模型" class="headerlink" title="本地进程间通信的 socket 编程模型"></a>本地进程间通信的 socket 编程模型</h5><p>本地 socket 被用于在同一台主机上进程间通信的场景：</p><ul><li>本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；</li><li>本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现。</li></ul><p>对于本地字节流 socket 其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。<br />对于本地数据报 socket 其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。<br />本地字节流 socket 和 本地数据报 socket 在 bind 时不像 TCP 和 UDP 要绑定 IP 地址和端口而是绑定一个本地文件，这也就是它们之间的最大区别。<br><a name="XjQcu"></a></p><h4 id="线程间通信方式"><a href="#线程间通信方式" class="headerlink" title="线程间通信方式"></a>线程间通信方式</h4><p>同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：</p><ul><li>互斥的方式可保证任意时刻只有一个线程访问共享资源；</li><li>同步的方式可保证线程 A 应在线程 B 之前执行。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;每个进程的用户地址空间都是独立的，一般是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。&lt;br /&gt;&lt;img src=&quot;https://cdn.nlark.com/yuque/0/2023/png/25368844/1686561987638-</summary>
      
    
    
    
    <category term="计算机操作系统" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="进程管理" scheme="http://example.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>进程管理：进程调度</title>
    <link href="http://example.com/2022/12/07/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%EF%BC%9A%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/"/>
    <id>http://example.com/2022/12/07/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%EF%BC%9A%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6/</id>
    <published>2022-12-07T13:40:00.000Z</published>
    <updated>2025-10-24T21:20:54.873Z</updated>
    
    <content type="html"><![CDATA[<p>一旦操作系统把进程切换到运行状态就意味着该进程占用着 CPU 在执行，但是当操作系统把进程切换到其他状态时就不能在 CPU 中执行了，于是操作系统会选择下一个要运行的进程。<br />选择一个进程运行这一功能是在操作系统中完成的，通常称为调度程序（scheduler）。<br><a name="Tuorr"></a></p><h4 id="调度时机"><a href="#调度时机" class="headerlink" title="调度时机"></a>调度时机</h4><p>在进程的生命周期中，当进程从一个运行状态到另外一个状态时就会触发一次调度。<br />比如以下状态的变化都会触发操作系统的调度：</p><ul><li>从就绪态 -&gt; 运行态：当进程被创建时会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；</li><li>从运行态 -&gt; 阻塞态：当进程发生 I&#x2F;O 事件而阻塞时操作系统必须选择另外一个进程运行；</li><li>从运行态 -&gt; 结束态：当进程退出结束后操作系统得从就绪队列选择另外一个进程运行。</li></ul><p>因为这些状态变化时操作系统需要考虑是否要让新的进程给 CPU 运行或者是否让当前进程从 CPU 上退出来而换另一个进程运行。<br />如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断把调度算法分为两类：</p><ul><li>非抢占式调度算法：挑选一个进程，让该进程运行直到被阻塞或者直到该进程退出才会调用另外一个进程，也就是说不会理时钟中断这个事情；</li><li>抢占式调度算法：挑选一个进程，让该进程只运行某段时间，如果在该时段结束时该进程仍然在运行就会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理需要在时间间隔的末端发生时钟中断以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。<br><a name="owbCC"></a></li></ul><h4 id="调度原则"><a href="#调度原则" class="headerlink" title="调度原则"></a>调度原则</h4><p>原则一：如果运行的程序发生了 I&#x2F;O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回，这样的过程势必会造成 CPU 突然的空闲。所以为了提高 CPU 利用率，在这种发送 I&#x2F;O 事件致使 CPU 空闲的情况下调度程序需要从就绪队列中选择一个进程来运行。<br />原则二：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用 CPU 就会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以为了提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。<br />原则三：从进程开始到结束的过程中实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，如果进程的等待时间很长而运行时间很短那周转时间就很长，调度程序应该避免这种情况发生。<br />原则四：处于就绪队列的进程也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以就绪队列中进程的等待时间也是调度程序所需要考虑的原则。<br />原则五：对于鼠标、键盘这种交互式比较强的应用响应时间越快越好，否则就会影响用户体验。所以对于交互式比较强的应用响应时间也是调度程序需要考虑的原则。<br />针对上面的五种调度原则总结成如下：</p><ul><li>CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li><li>系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源因此会降低吞吐量，相反短作业的进程会提升系统吞吐量；</li><li>周转时间：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li><li>等待时间：这个等待时间不是阻塞状态的时间而是进程处于就绪队列的时间，等待的时间越长用户越不满意；</li><li>响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中响应时间是衡量调度算法好坏的主要标准。<br><a name="NC0zD"></a></li></ul><h4 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h4><p>见上文。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;一旦操作系统把进程切换到运行状态就意味着该进程占用着 CPU 在执行，但是当操作系统把进程切换到其他状态时就不能在 CPU 中执行了，于是操作系统会选择下一个要运行的进程。&lt;br /&gt;选择一个进程运行这一功能是在操作系统中完成的，通常称为调度程序（scheduler）。&lt;b</summary>
      
    
    
    
    <category term="计算机操作系统" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="进程管理" scheme="http://example.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>进程管理：线程基础知识</title>
    <link href="http://example.com/2022/12/07/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%EF%BC%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>http://example.com/2022/12/07/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%EF%BC%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</id>
    <published>2022-12-07T13:30:00.000Z</published>
    <updated>2025-10-24T21:20:54.873Z</updated>
    
    <content type="html"><![CDATA[<p>在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面计算机科学家们又提出了更小的能独立运行的基本单位，也就是线程。<br><a name="e0XpG"></a></p><h4 id="为什么使用线程？"><a href="#为什么使用线程？" class="headerlink" title="为什么使用线程？"></a>为什么使用线程？</h4><p>举个例子假设要编写一个视频播放器软件，那么该软件功能的核心模块有三个：</p><ul><li>从视频文件当中读取数据；</li><li>对读取的数据进行解压缩；</li><li>把解压缩后的视频数据播放出来。</li></ul><p>单进程的实现方式会是以下这个方式：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686255878016-3c72c628-91ff-41f5-a9a6-e614c5295d56.png#averageHue=%23f7f5ef&clientId=uf8356ea5-2004-4&from=paste&height=277&id=u62aacf6c&originHeight=621&originWidth=723&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=192326&status=done&style=none&taskId=u35090d5f-54c7-4c13-a209-e408015bef5&title=&width=322.4000244140625"><br />单进程的方式存在以下问题：</p><ul><li>播放出来的画面和声音会不连贯，因为当 CPU 能力不够强时 Read 的时候可能进程就等在这了，这样就会导致等半天才进行数据解压和播放；</li><li>各个函数之间不是并发执行，影响资源的使用效率。</li></ul><p>改进成多进程的方式：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686256056326-8daba2b6-5252-4e84-887c-7ca7d4d7fc21.png#averageHue=%23f7f6f0&clientId=uf8356ea5-2004-4&from=paste&height=222&id=u8e5738f7&originHeight=277&originWidth=1145&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=129632&status=done&style=none&taskId=ub280bcf1-f348-42bc-9c4a-0c8e6fbd2ab&title=&width=916"><br />多进程的方式依然会存在问题：</p><ul><li>进程之间通信，共享数据；</li><li>维护进程的系统开销较大，如创建进程时分配资源、建立 PCB；终止进程时回收资源、撤销 PCB；进程切换时保存当前进程的状态信息。</li></ul><p>需要有一种新的实体满足以下特性：</p><ul><li>实体之间可以并发运行；</li><li>实体之间共享相同的地址空间。</li></ul><p>这个新的实体就是线程（Thread ），线程之间可以并发运行且共享相同的地址空间。<br><a name="OXEwn"></a></p><h4 id="什么是线程？"><a href="#什么是线程？" class="headerlink" title="什么是线程？"></a>什么是线程？</h4><p>线程是进程当中的一条执行流程。<br />同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。<br />线程的优点：</p><ul><li>一个进程中可以同时存在多个线程；</li><li>各个线程之间可以并发执行；</li><li>各个线程之间可以共享地址空间和文件等资源。</li></ul><p>线程的缺点：</p><ul><li>当进程中的一个线程崩溃时会导致其所属进程的所有线程崩溃（这里是针对 C&#x2F;C++ 语言，Java语言中的线程奔溃不会造成进程崩溃）。</li></ul><p>举个例子对于游戏的用户设计不应该使用多线程的方式，否则一个用户挂了会影响其他同个进程的线程。<br><a name="BNvIM"></a></p><h4 id="线程与进程的比较"><a href="#线程与进程的比较" class="headerlink" title="线程与进程的比较"></a>线程与进程的比较</h4><p>线程与进程的比较如下：</p><ul><li>进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；</li><li>进程拥有一个完整的资源平台，线程只独享必不可少的资源，如寄存器和栈；</li><li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li><li>线程能减少并发执行的时间和空间开销。</li></ul><p>线程相比进程能减少开销体现在：</p><ul><li>线程的创建时间比进程快，因为进程在创建的过程中还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中不会涉及这些资源管理信息而是共享它们；</li><li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li><li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，在切换的时候不需要切换页表。而对于进程之间的切换，在切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li><li>由于同一进程的各线程间共享内存和文件资源，在线程之间数据传递的时候就不需要经过内核了，这就使得线程之间的数据交互效率更高了。</li></ul><p>不管是时间效率还是空间效率线程比进程都要高。<br><a name="zheeU"></a></p><h4 id="线程的上下文切换"><a href="#线程的上下文切换" class="headerlink" title="线程的上下文切换"></a>线程的上下文切换</h4><p>线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。<br />操作系统的任务调度实际上的调度对象是线程，进程只是给线程提供了虚拟内存、全局变量等资源。<br />可以这么理解线程和进程：</p><ul><li>当进程只有一个线程时可以认为进程就等于线程；</li><li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；</li><li>线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。</li></ul><p>线程上下文切换还得看线程是不是属于同一个进程：</p><ul><li>当两个线程不是属于同一个进程，切换的过程就跟进程上下文切换一样；</li><li>当两个线程属于同一个进程，因为虚拟内存是共享的，所以在切换时虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；</li></ul><p>所以线程的上下文切换相比进程开销要小很多。<br><a name="WESg7"></a></p><h4 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h4><p>主要有三种线程的实现方式：</p><ul><li>用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；</li><li>内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程；</li><li>轻量级进程（LightWeight Process）：在内核中来支持用户线程。</li></ul><p>用户线程和内核线程的对应关系：</p><ul><li>第一种关系是多对一的关系，也就是多个用户线程对应同一个内核线程；</li><li>第二种是一对一的关系，也就是一个用户线程对应一个内核线程；</li><li>第三种是多对多的关系，也就是多个用户线程对应到多个内核线程。<br><a name="TPBlq"></a></li></ul><h5 id="用户线程"><a href="#用户线程" class="headerlink" title="用户线程"></a>用户线程</h5><p>用户线程是基于用户态的线程管理库来实现的，线程控制块（Thread Control Block, TCB）也是在库里面实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。<br />所以用户线程的整个线程管理和调度操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。<br />用户级线程的模型类似前面提到的多对一的关系，即多个用户线程对应同一个内核线程。<br />用户线程的优点：</p><ul><li>每个进程都需要有它私有的线程控制块（TCB）列表用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；</li><li>用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快。</li></ul><p>用户线程的缺点：</p><ul><li>由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了；</li><li>当一个线程开始运行后除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的；</li><li>由于时间片分配给进程，故与其他进程比，在多线程执行时每个线程得到的时间片较少，执行会比较慢。<br><a name="oe5lt"></a></li></ul><h5 id="内核线程"><a href="#内核线程" class="headerlink" title="内核线程"></a>内核线程</h5><p>内核线程是由操作系统管理的，线程对应的 TCB 是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。<br />内核线程的模型类似前面提到的一对一的关系，即一个用户线程对应一个内核线程。<br />内核线程的优点：</p><ul><li>在一个进程中如果某个内核线程发起系统调用而被阻塞并不会影响其他内核线程的运行；</li><li>分配给线程，多线程的进程获得更多的 CPU 运行时间。</li></ul><p>内核线程的缺点：</p><ul><li>在支持内核线程的操作系统中由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；</li><li>线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说开销比较大。<br><a name="jAMnW"></a></li></ul><h5 id="轻量级进程"><a href="#轻量级进程" class="headerlink" title="轻量级进程"></a>轻量级进程</h5><p>轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持而且 LWP 是由内核管理并像普通进程一样被调度。<br />在大多数系统中 LWP 与普通进程的区别在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说一个进程代表程序的一个实例而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。<br />在 LWP 之上是可以使用用户线程的，LWP 与用户线程的对应关系有三种：</p><ul><li>1 : 1，即一个 LWP 对应 一个用户线程；</li><li>N : 1，即一个 LWP 对应多个用户线程；</li><li>M : N，即多个 LWP 对应多个用户线程。</li></ul><p>针对上面这三种对应关系说明它们优缺点，先看下图的 LWP 模型：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686259304646-34183d2c-ab8d-4034-8959-8b155909b966.png#averageHue=%23f3f0ec&clientId=u61f553e4-b04f-4&from=paste&height=431&id=u804cac6a&originHeight=686&originWidth=1130&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=253205&status=done&style=none&taskId=u3feb8063-7ffd-46aa-af11-808f2412323&title=&width=709.2000122070312"><br><a name="EbgAD"></a></p><h6 id="1-1-模式"><a href="#1-1-模式" class="headerlink" title="1 : 1 模式"></a>1 : 1 模式</h6><p>一个线程对应到一个 LWP 再对应到一个内核线程，上图的进程 4 属于此模型。</p><ul><li>优点：实现并行，一个 LWP 阻塞不会影响其他 LWP；</li><li>缺点：每一个用户线程就产生一个内核线程，创建线程的开销较大。<br><a name="KgPPC"></a></li></ul><h6 id="N-1-模式"><a href="#N-1-模式" class="headerlink" title="N : 1 模式"></a>N : 1 模式</h6><p>多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。</p><ul><li>优点：用户线程要开几个都没问题且上下文切换发生在用户空间，切换的效率较高；</li><li>缺点：一个用户线程如果阻塞了则整个进程都将会阻塞，在多核 CPU 中没办法充分利用 CPU。<br><a name="ibSJU"></a></li></ul><h6 id="M-N-模式"><a href="#M-N-模式" class="headerlink" title="M : N 模式"></a>M : N 模式</h6><p>根据前面的两个模型混搭一起就形成 M : N 模型，该模型提供了两级控制，首先多个用户线程对应多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。</p><ul><li>优点：综合了前两种优点，大部分的线程上下文切换发生在用户空间且多个线程又可以充分利用多核 CPU 的资源。<br><a name="uikCf"></a></li></ul><h6 id="组合模式"><a href="#组合模式" class="headerlink" title="组合模式"></a>组合模式</h6><p>如上图的进程 5，此进程结合 1 : 1 模型和 M : N 模型。开发人员可以针对不同的应用特点调节内核线程的数目来达到物理并行性和逻辑并行性的最佳方案。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面计算机科学家们又提出了更小的能独立运行的基本单位，也就是线程。&lt;br&gt;&lt;a name=&quot;e0XpG&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;为什么使用线程？&quot;&gt;&lt;a href=&quot;#为什么使用线程？&quot; class=&quot;he</summary>
      
    
    
    
    <category term="计算机操作系统" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="进程管理" scheme="http://example.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>进程管理：进程基础知识</title>
    <link href="http://example.com/2022/12/07/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%EF%BC%9A%E8%BF%9B%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>http://example.com/2022/12/07/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%EF%BC%9A%E8%BF%9B%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</id>
    <published>2022-12-07T13:20:00.000Z</published>
    <updated>2025-10-24T21:20:54.873Z</updated>
    
    <content type="html"><![CDATA[<p>编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当运行这个可执行文件后它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，运行中的程序被称为「进程」（Process）。<br />有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，在这个时候如果 CPU 傻傻的等硬盘返回数据的话 CPU 的利用率是非常低的。<br />所以当进程要从硬盘读取数据时 CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时 CPU 会收到个中断，于是 CPU 再继续运行这个进程。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686216193216-027ed512-505d-497f-bb00-f47989ab6823.png#averageHue=%23f6f1f0&clientId=u3b0a58ef-73e9-4&from=paste&height=202&id=u7571aa56&originHeight=423&originWidth=1104&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=216913&status=done&style=none&taskId=u2ae028a8-d126-42f2-9f01-d7717ce533c&title=&width=527.2000122070312"><br />这种多个程序交替执行的思想就有 CPU 管理多个进程的初步想法。<br />对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒。<br />虽然单核的 CPU 在某一个瞬间只能运行一个进程，但在 1 秒钟期间它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。<br />并发和并行区别：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686216350450-55a378a6-8deb-4cef-9814-140e1aa9f3a1.png#averageHue=%23faf5f0&clientId=u3b0a58ef-73e9-4&from=paste&height=292&id=u9bc34179&originHeight=814&originWidth=998&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=193285&status=done&style=none&taskId=u7c4d8b31-2c05-4274-a5e4-9d8efbbf3e5&title=&width=358.20001220703125"><br />CPU 可以从一个进程切换到另外一个进程，在切换前必须要记录当前进程中运行的状态信息以备下次切换回来的时候可以恢复执行。<br />进程有着「运行 - 暂停 - 运行」的活动规律。<br><a name="CbdvN"></a></p><h4 id="进程的状态"><a href="#进程的状态" class="headerlink" title="进程的状态"></a>进程的状态</h4><p>一般说来一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。<br />它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后它又进入准备运行状态。<br />所以在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686216595573-ac0b5491-7c9c-4211-979c-f22e74c74916.png#averageHue=%23f4f1ef&clientId=u3b0a58ef-73e9-4&from=paste&height=394&id=ufb3a7240&originHeight=492&originWidth=1113&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=184104&status=done&style=none&taskId=u0d1be2cf-5464-4875-abaa-01d8dc9f236&title=&width=890.4"><br />上图中各个状态的意义：</p><ul><li>运行状态（Running）：该时刻进程占用 CPU；</li><li>就绪状态（Ready）：可运行，但由于其他进程处于运行状态而暂时停止运行；</li><li>阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入&#x2F;输出操作的完成）而暂时停止运行，这时即使给它CPU控制权也无法运行。</li></ul><p>进程还有另外两个基本状态：</p><ul><li>创建状态（new）：进程正在被创建时的状态；</li><li>结束状态（Exit）：进程正在从系统中消失时的状态。</li></ul><p>一个完整的进程状态的变迁如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686216811059-73d3f211-b4f4-445c-8331-0e1f93c5d87f.png#averageHue=%23f9f5ec&clientId=u3b0a58ef-73e9-4&from=paste&height=302&id=ub62ab511&originHeight=378&originWidth=1107&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=156527&status=done&style=none&taskId=u88826fcc-9af6-46a7-a951-fe25b863028&title=&width=885.6"><br />进程的状态变迁：</p><ul><li>NULL -&gt; 创建状态：一个新进程被创建时的第一个状态；</li><li>创建状态 -&gt; 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时变为就绪状态，这个过程是很快的；</li><li>就绪态 -&gt; 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后就分配给 CPU 正式运行该进程；</li><li>运行状态 -&gt; 结束状态：当进程已经运行完成或出错时会被操作系统作结束状态处理；</li><li>运行状态 -&gt; 就绪状态：处于运行状态的进程在运行过程中由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态中选中另外一个进程运行；</li><li>运行状态 -&gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I&#x2F;O 事件；</li><li>阻塞状态 -&gt; 就绪状态：当进程要等待的事件完成时从阻塞状态变到就绪状态。</li></ul><p>如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，物理内存空间是有限的，被阻塞状态的进程占用着物理内存就是一种浪费物理内存的行为。<br />所以在虚拟内存管理的操作系统中通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候再从硬盘换入到物理内存。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686217220158-d46a0c29-8803-4dd3-aab6-6745757ba21d.png#averageHue=%23f7f3ec&clientId=u3b0a58ef-73e9-4&from=paste&height=318&id=u9702c675&originHeight=692&originWidth=1122&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=128713&status=done&style=none&taskId=uf64b4888-653c-431b-931c-72973f5f8dc&title=&width=516.2000122070312"><br />那么就需要一个新的状态来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态不一样，阻塞状态是等待某个事件的返回。<br />挂起状态可以分为两种：</p><ul><li>阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；</li><li>就绪挂起状态：进程在外存（硬盘），但只要进入内存就立刻运行。</li></ul><p>这两种挂起状态加上前面的五种状态就变成了七种状态变迁，见如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686217379626-8aa47cf5-43f7-4b27-916d-a7bb0b7ea92a.png#averageHue=%23faf8f5&clientId=u3b0a58ef-73e9-4&from=paste&height=389&id=uef8559b8&originHeight=690&originWidth=1137&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=201491&status=done&style=none&taskId=ub5692b5b-7606-42ec-8047-51065a35979&title=&width=641.2000122070312"><br />导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：</p><ul><li>通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。</li><li>用户希望挂起一个程序的执行，比如在 Linux 中用 Ctrl+Z 挂起进程。<br><a name="V0uuR"></a></li></ul><h4 id="进程的控制结构"><a href="#进程的控制结构" class="headerlink" title="进程的控制结构"></a>进程的控制结构</h4><p>在操作系统中是用进程控制块（process control block，PCB）数据结构来描述进程的。<br />PCB 是进程存在的唯一标识，这意味着一个进程的存在必然会有一个 PCB，如果进程消失了 PCB 也会随之消失。<br />PCB 包含信息：</p><ul><li>进程描述信息：<ul><li>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</li><li>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务。</li></ul></li><li>进程控制和管理信息：<ul><li>进程当前状态，如 new、ready、running、waiting 或 blocked 等；</li><li>进程优先级：进程抢占 CPU 时的优先级。</li></ul></li><li>资源分配清单：<ul><li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。</li></ul></li><li>CPU 相关信息：<ul><li>CPU 中各个寄存器的值，当进程被切换时 CPU 的状态信息都会被保存在相应的 PCB 中以便进程重新执行时能从断点处继续执行。</li></ul></li></ul><p>PCB 通常是通过链表的方式进行组织，把具有相同状态的进程链在一起组成各种队列。比如：</p><ul><li>将所有处于就绪状态的进程链在一起称为就绪队列；</li><li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列；</li><li>对于运行队列在单核 CPU 系统中只有一个运行指针，因为单核 CPU 在某个时间只能运行一个程序。</li></ul><p>就绪队列和阻塞队列链表的组织形式如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686218081227-52ead3d9-c6fe-4ff8-90e6-a92c279f0560.png#averageHue=%23f9f8f8&clientId=u3b0a58ef-73e9-4&from=paste&height=310&id=ud54f9f95&originHeight=630&originWidth=1150&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=84145&status=done&style=none&taskId=u7664f3a0-62cd-4e2d-b9e2-f539bbb07d6&title=&width=565.2000122070312"><br />除了链接的组织方式还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。<br />一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。<br><a name="kIYAH"></a></p><h4 id="进程的控制"><a href="#进程的控制" class="headerlink" title="进程的控制"></a>进程的控制</h4><p>进程的创建、终止、阻塞、唤醒的过程就是进程的控制。<br><a name="MbqXa"></a></p><h5 id="创建进程"><a href="#创建进程" class="headerlink" title="创建进程"></a>创建进程</h5><p>操作系统允许一个进程创建另一个进程而且允许子进程继承父进程所拥有的资源。<br />创建进程的过程如下：</p><ul><li>申请一个空白的 PCB 并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；</li><li>为该进程分配运行时所必需的资源，比如内存资源；</li><li>将 PCB 插入到就绪队列，等待被调度运行。<br><a name="gBR8o"></a></li></ul><h5 id="终止进程"><a href="#终止进程" class="headerlink" title="终止进程"></a>终止进程</h5><p>进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。<br />当子进程被终止时其在父进程处继承的资源应当还给父进程。而当父进程被终止时该父进程的子进程就变为孤儿进程，会被 1 号进程收养并由 1 号进程对它们完成状态收集工作。<br />终止进程的过程如下：</p><ul><li>查找需要终止的进程的 PCB；</li><li>如果处于执行状态就立即终止该进程的执行，然后将 CPU 资源分配给其他进程；</li><li>如果其还有子进程就将该进程的子进程交给 1 号进程接管；</li><li>将该进程所拥有的全部资源都归还给操作系统；</li><li>将其从 PCB 所在队列中删除。<br><a name="IAyXP"></a></li></ul><h5 id="阻塞进程"><a href="#阻塞进程" class="headerlink" title="阻塞进程"></a>阻塞进程</h5><p>当进程需要等待某一事件完成时可以调用阻塞语句把自己阻塞等待。一旦被阻塞等待只能由另一个进程唤醒。<br />阻塞进程的过程如下：</p><ul><li>找到将要被阻塞进程标识号对应的 PCB；</li><li>如果该进程为运行状态则保护其现场，将其状态转为阻塞状态并停止运行；</li><li>将该 PCB 插入到阻塞队列中去。<br><a name="i53XR"></a></li></ul><h5 id="唤醒进程"><a href="#唤醒进程" class="headerlink" title="唤醒进程"></a>唤醒进程</h5><p>进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。<br />如果某进程正在等待 I&#x2F;O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时才由发现者进程用唤醒语句叫醒它。<br />唤醒进程的过程如下：</p><ul><li>在该事件的阻塞队列中找到相应进程的 PCB；</li><li>将其从阻塞队列中移出并置其状态为就绪状态；</li><li>把该 PCB 插入到就绪队列中，等待调度程序调度。</li></ul><p>进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句则必有一个与之对应的唤醒语句。<br><a name="YsH5h"></a></p><h4 id="进程的上下文切换"><a href="#进程的上下文切换" class="headerlink" title="进程的上下文切换"></a>进程的上下文切换</h4><p>各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换来让不同的进程可以在 CPU 执行，这样一个进程切换到另一个进程运行称为进程的上下文切换。<br><a name="GMHAi"></a></p><h5 id="CPU-上下文切换"><a href="#CPU-上下文切换" class="headerlink" title="CPU 上下文切换"></a>CPU 上下文切换</h5><p>大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上这些任务并不是同时运行的，只是因为系统在很短的时间内让各个任务分别在 CPU 运行造成了同时运行的错觉。<br />任务是交给 CPU 运行的，在每个任务运行前 CPU 需要知道任务从哪里加载，又从哪里开始运行。<br />所以操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。<br />CPU 寄存器是 CPU 内部一个容量小但是速度极快的内存（缓存）。<br />程序计数器是用来存储 CPU 正在执行的指令位置、即将执行的下一条指令位置。<br />CPU 寄存器和程序计数器是 CPU 在运行任何任务前所必须依赖的环境，这些环境就叫做 CPU 上下文。<br />CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置运行新任务。<br />系统内核会存储保存下来的上下文信息，当此任务再次被分配给 CPU 运行时 CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。<br />上面说到所谓的「任务」主要包含进程、线程和中断。所以可以根据任务的不同把 CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换。<br><a name="Yr2Yi"></a></p><h5 id="进程上下文切换"><a href="#进程上下文切换" class="headerlink" title="进程上下文切换"></a>进程上下文切换</h5><p>进程是由内核管理和调度的，所以进程的切换只能发生在内核态。<br />所以进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。<br />通常会把交换的信息保存在进程的 PCB 里，当要运行另外一个进程时需要从这个进程的 PCB 里取出上下文，然后恢复到 CPU 中以使得这个进程可以继续执行，如下图所示：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686240114688-306e594f-6ad9-459f-8ea9-be63af965cd8.png#averageHue=%23f4efe8&clientId=uafa8d369-79c5-4&from=paste&height=209&id=u556fd57b&originHeight=261&originWidth=1087&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=98426&status=done&style=none&taskId=u28af2b25-4a24-4636-a399-272d43ed248&title=&width=869.6"><br />进程的上下文开销是很关键的，希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上而不是耗费在上下文切换。<br />发生进程上下文切换的场景：</p><ul><li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；</li><li>进程在系统资源不足（比如内存不足）时要等到资源满足后才可以运行，这个时候进程也会被挂起并由系统调度其他进程运行；</li><li>当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时也会重新调度；</li><li>当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程运行；</li><li>发生硬件中断时 CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当运行这个可执行文件后它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，运行中的程序被称为「进程」（Process）。&lt;br /&gt;有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文</summary>
      
    
    
    
    <category term="计算机操作系统" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="进程管理" scheme="http://example.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>网络系统：高性能网络模式</title>
    <link href="http://example.com/2022/12/07/%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F/"/>
    <id>http://example.com/2022/12/07/%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F/</id>
    <published>2022-12-07T13:10:00.000Z</published>
    <updated>2025-10-24T21:20:54.873Z</updated>
    
    <content type="html"><![CDATA[<p><a name="OcMWZ"></a></p><h4 id="演进"><a href="#演进" class="headerlink" title="演进"></a>演进</h4><p>如果要让服务器服务多个客户端，最直接的方式就是为每一条连接创建线程。创建进程也是可以的，原理是一样的，进程和线程的区别在于线程比较轻量级，线程的创建和线程间切换的成本要小些。<br />处理完业务逻辑后随着连接关闭线程也同样要销毁了，但是这样不停地创建和销毁线程不仅会带来性能开销，也会造成浪费资源，而且如果要连接几万条连接，创建几万个线程去应对也是不现实的。<br />可以使用「资源复用」的方式解决这个问题，也就是不用再为每个连接创建线程而是创建一个「线程池」，将连接分配给线程然后一个线程可以处理多个连接的业务。<br />线程怎样才能高效地处理多个连接的业务？<br />当一个连接对应一个线程时线程一般采用「read -&gt; 业务处理 -&gt; send」的处理流程，如果当前连接没有数据可读，那么线程会阻塞在 read 操作上（ socket 默认情况是阻塞 I&#x2F;O），不过这种阻塞方式并不影响其他线程。<br />但是引入了线程池，一个线程要处理多个连接的业务，线程在处理某个连接的 read 操作时如果遇到没有数据可读就会发生阻塞，那么线程就没办法继续处理其他连接的业务。<br />解决这个问题最简单的方式就是将 socket 改成非阻塞，然后线程不断地轮询调用 read 操作来判断是否有数据，这种方式虽然能够解决阻塞的问题，但是解决的方式比较粗暴，因为轮询是要消耗 CPU 的而且随着一个线程处理的连接越多轮询的效率就会越低。<br />上面的问题在于线程并不知道当前连接是否有数据可读从而需要每次通过 read 去试探。<br />I&#x2F;O 多路复用技术实现了在只有当连接上有数据时线程才去发起读请求。I&#x2F;O 多路复用技术会用一个系统调用函数来监听所有关心的连接，也就是说可以在一个监控线程里面监控很多的连接。<br />select&#x2F;poll&#x2F;epoll 就是内核提供给用户态的多路复用系统调用，线程可以通过一个系统调用函数从内核中获取多个事件。<br />select&#x2F;poll&#x2F;epoll 是如何获取网络事件的？<br />在获取事件时先把关心的连接传给内核，再由内核检测：</p><ul><li>如果没有事件发生，线程只需阻塞在这个系统调用而无需像线程池方案那样轮训调用 read 操作来判断是否有数据；</li><li>如果有事件发生，内核会返回产生了事件的连接，线程就会从阻塞状态返回然后在用户态中再处理这些连接对应的业务即可。</li></ul><p>用 I&#x2F;O 多路复用接口写网络程序是面向过程的，大佬们基于面向对象的思想对 I&#x2F;O 多路复用作了一层封装，让使用者不用考虑底层网络 API 的细节，只需要关注应用代码的编写。这种模式就是 Reactor 模式。<br />Reactor 翻译过来的意思是「反应堆」，这里的反应指的是「对事件反应」，也就是来了一个事件 Reactor 就有相对应的反应&#x2F;响应。<br />Reactor 模式也叫 Dispatcher 模式，这个名字更贴合该模式的含义，即 I&#x2F;O 多路复用监听事件，收到事件后根据事件类型分配（Dispatch）给某个进程 &#x2F; 线程。<br />Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：</p><ul><li>Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；</li><li>处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send。</li></ul><p>Reactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：</p><ul><li>Reactor 的数量可以只有一个也可以有多个；</li><li>处理资源池可以是单个进程&#x2F;线程，也可以是多个进程&#x2F;线程。</li></ul><p>将上面的两个因素排列组设一下，理论上就可以有 4 种方案选择：</p><ul><li>单 Reactor 单进程&#x2F;线程；</li><li>单 Reactor 多进程&#x2F;线程；</li><li>多 Reactor 单进程&#x2F;线程；</li><li>多 Reactor 多进程&#x2F;线程。</li></ul><p>其中「多 Reactor 单进程&#x2F;线程」实现方案相比「单 Reactor 单进程&#x2F;线程」方案不仅复杂而且也没有性能优势，因此实际中并没有应用。<br />剩下的 3 个方案都是比较经典的且都有应用在实际的项目中。<br />方案具体使用进程还是线程要看使用的编程语言以及平台有关：</p><ul><li>Java 语言一般使用线程，比如 Netty；</li><li>C 语言使用进程和线程都可以，例如 Nginx 使用的是进程，Memcache 使用的是线程。<br><a name="fmisN"></a></li></ul><h4 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h4><p><a name="oX8jS"></a></p><h5 id="单-Reactor-单进程-x2F-线程"><a href="#单-Reactor-单进程-x2F-线程" class="headerlink" title="单 Reactor 单进程&#x2F;线程"></a>单 Reactor 单进程&#x2F;线程</h5><p>C 语言实现的是「单 Reactor 单进程」的方案，因为 C 语言编写完的程序运行后就是一个独立的进程，不需要在进程中再创建线程。<br />而 Java 语言实现的是「单 Reactor 单线程」的方案，因为 Java 程序是跑在 Java 虚拟机这个进程上面的，虚拟机中有很多线程，Java 程序只是其中的一个线程而已。<br />「单 Reactor 单进程」的方案示意图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686168756976-55dff1d7-f08d-4e98-a58c-4f607e8507fe.png#averageHue=%23f7efe1&clientId=u6a95cdbc-3be4-4&from=paste&height=413&id=u7b67172e&originHeight=656&originWidth=1139&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=206684&status=done&style=none&taskId=uade61bf8-b80f-483a-ad3b-2081178fda4&title=&width=717.2000122070312"><br />进程里有 Reactor、Acceptor、Handler 三个对象：</p><ul><li>Reactor 对象的作用是监听和分发事件；</li><li>Acceptor 对象的作用是获取连接；</li><li>Handler 对象的作用是处理业务。</li></ul><p>对象里的 select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。<br />「单 Reactor 单进程」这个方案：</p><ul><li>Reactor 对象通过 select（IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象要看收到的事件类型；</li><li>如果是连接建立的事件就交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法获取连接并创建一个 Handler 对象来处理后续的响应事件；</li><li>如果不是连接建立事件就交由当前连接对应的 Handler 对象来进行响应；</li><li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li></ul><p>单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信也不用担心多进程竞争。<br />但是这种方案存在 2 个缺点：</p><ul><li>第一个缺点，因为只有一个进程，所以无法充分利用多核 CPU 的性能；</li><li>第二个缺点，Handler 对象在业务处理时整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长就会造成响应的延迟。</li></ul><p>所以单 Reactor 单进程的方案不适用计算密集型的场景，只适用于业务处理非常快速的场景。<br />Redis 是由 C 语言实现的，采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。<br><a name="QxqQX"></a></p><h5 id="单-Reactor-多线程-x2F-进程"><a href="#单-Reactor-多线程-x2F-进程" class="headerlink" title="单 Reactor 多线程&#x2F;进程"></a>单 Reactor 多线程&#x2F;进程</h5><p>如果要克服「单 Reactor 单线程 &#x2F; 进程」方案的缺点就需要引入多线程&#x2F;多进程，这样就产生了单 Reactor 多线程&#x2F;多进程的方案。<br />「单 Reactor 多线程」方案的示意图如下：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686169551043-c6ca80ce-d84a-4d8b-a547-a8122f058a1b.png#averageHue=%23f8eeda&clientId=u6a95cdbc-3be4-4&from=paste&height=552&id=uef09f463&originHeight=902&originWidth=1186&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=344609&status=done&style=none&taskId=uc77920fe-bcfa-4ad4-aaa0-1bdb6673c23&title=&width=725.2000122070312"><br />方案如下：</p><ul><li>Reactor 对象通过 select（IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象要看收到的事件类型；</li><li>如果是连接建立的事件就交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法获取连接并创建一个 Handler 对象来处理后续的响应事件；</li><li>如果不是连接建立事件就交由当前连接对应的 Handler 对象来进行响应；</li></ul><p>上面的三个步骤和单 Reactor 单线程方案是一样的，接下来的步骤就开始不一样了：</p><ul><li>Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后会将数据发给子线程里的 Processor 对象进行业务处理；</li><li>子线程里的 Processor 对象处理完业务后将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client。</li></ul><p>单 Reactor 多线程的方案优势在于能够充分利用多核 CPU 的能力，既然引入多线程自然就带来了多线程竞争资源的问题。<br />例如子线程完成业务处理后要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。<br />要避免多线程由于竞争共享资源而导致数据错乱的问题就需要在操作共享资源前加上互斥锁以保证任意时间里只有一个线程在操作共享资源，待该线程操作完释放互斥锁后其他线程才有机会操作共享数据。<br />单 Reactor 多进程相比单 Reactor 多线程实现起来更麻烦，主要因为要考虑子进程 &lt;-&gt; 父进程的双向通信并且父进程还得知道子进程要将数据发送给哪个客户端。<br />而多线程间可以共享数据，虽然要额外考虑并发问题，但是这远比进程间通信的复杂度低得多，因此实际应用中也看不到单 Reactor 多进程的模式。<br />「单 Reactor」的模式有个问题，因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时容易成为性能的瓶颈。<br><a name="BKbPd"></a></p><h5 id="多-Reactor-多进程-x2F-线程"><a href="#多-Reactor-多进程-x2F-线程" class="headerlink" title="多 Reactor 多进程&#x2F;线程"></a>多 Reactor 多进程&#x2F;线程</h5><p>解决「单 Reactor」的问题就要将「单 Reactor」实现成「多 Reactor」，这样就产生了多 Reactor 多进程&#x2F;线程的方案。<br />多 Reactor 多进程&#x2F;线程方案的示意图如下（以线程为例）：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686170409279-21cadb9b-d580-4222-ac14-11959a199356.png#averageHue=%23f7eedf&clientId=u6a95cdbc-3be4-4&from=paste&height=724&id=uec899e23&originHeight=905&originWidth=1352&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=391728&status=done&style=none&taskId=u28733856-b829-4a1a-85a4-547a667d0c1&title=&width=1081.6"><br />方案如下：</p><ul><li>主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；</li><li>子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听并创建一个 Handler 用于处理连接的响应事件；</li><li>当有新的事件发生时 SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应；</li><li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li></ul><p>多 Reactor 多线程的方案虽然看起来很复杂，但是实现比单 Reactor 多线程的方案要简单的多，原因如下：</p><ul><li>主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理；</li><li>主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据直接就可以在子线程将处理结果发送给客户端。</li></ul><p>Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案。<br />Nginx 采用了「多 Reactor 多进程」方案，不过方案与标准的多 Reactor 多进程有些差异。<br />具体差异表现在主进程中仅仅用来初始化 socket 并没有创建 mainReactor 来 accept 连接，而是由子进程的 Reactor 来 accept 连接，通过锁来控制一次只有一个子进程进行 accept（防止出现惊群现象），子进程 accept 新连接后就放到自己的 Reactor 进行处理，不会再分配给其他子进程。<br><a name="PfkR0"></a></p><h4 id="Proactor"><a href="#Proactor" class="headerlink" title="Proactor"></a>Proactor</h4><p>Reactor 是非阻塞同步网络模式，而 Proactor 是异步网络模式。<br />阻塞、非阻塞、同步、异步 I&#x2F;O 的概念：<br />阻塞 I&#x2F;O，当用户程序执行 read，线程会被阻塞直到内核数据准备好并把数据从内核缓冲区拷贝到应用程序的缓冲区中，拷贝过程完成 read 才会返回。<br />注意阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。过程如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686171866109-0bbf00ae-d092-409b-9c6f-74b802bd95e4.png#averageHue=%23f7f7f7&clientId=u4ff9c40c-e026-4&from=paste&height=323&id=u4c8b89db&originHeight=777&originWidth=1027&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=98427&status=done&style=none&taskId=u5c6552cb-0703-4144-9d9a-383d01a7e32&title=&width=427.20001220703125"><br />非阻塞 I&#x2F;O，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。过程如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686172053148-f7c8eace-a8a5-40d9-8588-44c28b3f259d.png#averageHue=%23f0f0f0&clientId=u4ff9c40c-e026-4&from=paste&height=385&id=u488b30a5&originHeight=907&originWidth=990&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=226376&status=done&style=none&taskId=uc089dd5d-57e3-431e-8329-8295beebd75&title=&width=420.20001220703125"><br />注意这里最后一次 read 调用，获取数据的过程是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。<br />举个例子如果 socket 设置了 O_NONBLOCK 标志就表示使用的是非阻塞 I&#x2F;O 的方式访问，而不做任何设置的话默认是阻塞 I&#x2F;O。<br />因此无论 read 和 send 是阻塞 I&#x2F;O还是非阻塞 I&#x2F;O 都是同步调用。因为在 read 调用时内核将数据从内核空间拷贝到用户空间的过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。<br />而真正的异步 I&#x2F;O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。<br />当发起 aio_read（异步 I&#x2F;O） 之后就立即返回，内核自动将数据从内核空间拷贝到用户空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。过程如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686172639786-8d36a98c-87fd-43a2-a0e5-1a5d6cedc5c1.png#averageHue=%23f7f7f7&clientId=u4ff9c40c-e026-4&from=paste&height=354&id=uf5059685&originHeight=901&originWidth=1015&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=118072&status=done&style=none&taskId=u173a8ada-ef46-4047-91d0-b668c76cf69&title=&width=399.20001220703125"><br />异步 I&#x2F;O 比同步 I&#x2F;O 性能更好，因为异步 I&#x2F;O 在「内核数据准备好」和「数据从内核空间拷贝到用户空间」这两个过程都不用等待。<br />Proactor 正是采用了异步 I&#x2F;O 技术，所以被称为异步网络模型。<br />Reactor 和 Proactor 的区别：</p><ul><li>Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件。在每次感知到有事件发生（比如可读就绪事件）后就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据；</li><li>Proactor 是异步网络模式， 感知的是已完成的读写事件。在发起异步读写请求时需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read&#x2F;write 来读写数据，操作系统完成读写工作后就会通知应用进程直接处理数据。</li></ul><p>Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」，而 Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」。这里的「事件」就是有新连接、有数据可读、有数据可写的 I&#x2F;O 事件，这里的「处理」包含从驱动读取到内核以及从内核读取到用户空间。<br />无论是 Reactor 还是 Proactor 都是一种基于「事件分发」的网络编程模式，区别在于 Reactor 模式是基于「待完成」的 I&#x2F;O 事件，而 Proactor 模式则是基于「已完成」的 I&#x2F;O 事件。<br />Proactor 模式的示意图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686173466090-e982a124-5f76-400d-a2f6-1f1d3e291aaa.png#averageHue=%23f6f2e7&clientId=u4ff9c40c-e026-4&from=paste&height=411&id=ua9ddd6dc&originHeight=514&originWidth=1153&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=147485&status=done&style=none&taskId=u6e354f87-04b2-4b94-bfdb-0c89f9d959a&title=&width=922.4"><br />Proactor 模式的工作流程：</p><ul><li>Proactor Initiator 负责创建 Proactor 和 Handler 对象并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核；</li><li>Asynchronous Operation Processor 负责处理注册请求并处理 I&#x2F;O 操作；</li><li>Asynchronous Operation Processor 完成 I&#x2F;O 操作后通知 Proactor；</li><li>Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理；</li><li>Handler 完成业务处理。</li></ul><p>在 Linux 下的异步 I&#x2F;O 是不完善的， 这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案。<br />而 Windows 里实现了一套完整的支持 socket 的异步编程接口，因此在 Windows 里实现高性能网络程序可以使用效率更高的 Proactor 方案。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;OcMWZ&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;演进&quot;&gt;&lt;a href=&quot;#演进&quot; class=&quot;headerlink&quot; title=&quot;演进&quot;&gt;&lt;/a&gt;演进&lt;/h4&gt;&lt;p&gt;如果要让服务器服务多个客户端，最直接的方式就是为每一条连接创建线程。创建进程也是可以</summary>
      
    
    
    
    <category term="计算机操作系统" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="网络系统" scheme="http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>网络系统：I/O 多路复用</title>
    <link href="http://example.com/2022/12/07/%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%EF%BC%9AIO%20%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/"/>
    <id>http://example.com/2022/12/07/%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%EF%BC%9AIO%20%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</id>
    <published>2022-12-07T13:00:00.000Z</published>
    <updated>2025-10-24T21:20:54.872Z</updated>
    
    <content type="html"><![CDATA[<p><a name="oryUX"></a></p><h4 id="基本-Socket-模型"><a href="#基本-Socket-模型" class="headerlink" title="基本 Socket 模型"></a>基本 Socket 模型</h4><p>要想客户端和服务器能在网络中通信必须得使用 Socket 编程，它是进程间通信里比较特别的方式，特别之处在于它是可以跨主机间通信。<br />Socket 的中文名叫作插口，双方要进行网络通信前各自得创建一个 Socket，这相当于客户端和服务器都开了一个“口子”，双方读取和发送数据的时候都通过这个“口子”。就像弄了一根网线，一头插在客户端，一头插在服务端，然后进行通信。<br />创建 Socket 时可以指定网络层使用的是 IPv4 还是 IPv6，传输层使用的是 TCP 还是 UDP。<br />UDP 的 Socket 编程相对简单些，这里只介绍基于 TCP 的 Socket 编程。<br />服务器的程序要先跑起来，然后等待客户端的连接和数据，服务端的 Socket 编程过程：<br />服务端首先调用 socket() 函数，创建网络协议为 IPv4 以及传输协议为 TCP 的 Socket ，接着调用 bind() 函数给这个 Socket 绑定一个 IP 地址和端口，绑定这两个的目的：</p><ul><li>绑定端口的目的：当内核收到 TCP 报文后通过 TCP 头里面的端口号来找到应用程序，然后把数据传递给应用程序；</li><li>绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，在绑定一个网卡后内核在收到该网卡上的包时才会发给机器。</li></ul><p>绑定完 IP 地址和端口后就可以调用 listen() 函数进行监听，此时对应 TCP 状态图中的 listen，如果要判定服务器中一个网络程序有没有启动，可以通过 netstat 命令查看对应的端口号是否有被监听。<br />服务端进入了监听状态后通过调用 accept() 函数来从内核获取客户端的连接，如果没有客户端连接则会阻塞等待客户端连接的到来。<br />客户端发起连接：客户端在创建好 Socket 后调用 connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后 TCP 三次握手就开始了。<br />在 TCP 连接的过程中服务器的内核实际上为每个 Socket 维护了两个队列：</p><ul><li>一个是「还没完全建立」连接的队列，称为 TCP 半连接队列，这个队列都是没有完成三次握手的连接，此时服务端处于 syn_rcvd 的状态；</li><li>一个是「已经建立」连接的队列，称为 TCP 全连接队列，这个队列都是完成了三次握手的连接，此时服务端处于 established 状态。</li></ul><p>当 TCP 全连接队列不为空时，服务端的 accept() 函数就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。<br />注意监听的 Socket 和真正用来传数据的 Socket 是两个：</p><ul><li>一个叫作监听 Socket；</li><li>一个叫作已连接 Socket。</li></ul><p>连接建立后客户端和服务端就开始相互传输数据了，双方都可以通过 read() 和 write() 函数来读写数据。<br />至此 TCP 协议的 Socket 程序的调用过程就结束了，整个过程如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686042057820-46f4a759-b3a7-42db-93ff-027393c9d2de.png#averageHue=%23f9f7ef&clientId=uf30cc27d-c3ef-4&from=paste&height=510&id=u3af33b4e&originHeight=937&originWidth=684&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=172293&status=done&style=none&taskId=u7f3dd680-147b-4437-a9f7-295d196fd33&title=&width=372.20001220703125"><br />读写 Socket 的方式好像读写文件一样，基于 Linux 一切皆文件的理念，在内核中 Socket 也是以「文件」的形式存在的，也是有对应的文件描述符。<br><a name="KAC7z"></a></p><h4 id="如何服务更多的用户？"><a href="#如何服务更多的用户？" class="headerlink" title="如何服务更多的用户？"></a>如何服务更多的用户？</h4><p>前面的 TCP Socket 调用流程是最简单、最基本的，它基本只能一对一通信，因为使用的是同步阻塞的方式，当服务端在还没处理完一个客户端的网络 I&#x2F;O 时或者读写操作发生阻塞时，其他客户端是无法与服务端连接的。<br />如果服务器只能服务一个客户就太浪费资源了，于是要改进这个网络 I&#x2F;O 模型以支持更多的客户端。<br />服务器单机理论最大能连接多少个客户端？<br />TCP 连接是由四元组唯一确认的，这个四元组就是：本机IP，本机端口，对端IP，对端端口。<br />服务器作为服务方通常会在本地固定监听一个端口，等待客户端的连接。因此服务器的本地 IP 和端口是固定的，于是对于服务端 TCP 连接的四元组只有对端 IP 和端口是会变化的，所以最大 TCP 连接数 &#x3D; 客户端 IP 数×客户端端口数。<br />对于 IPv4 客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数约为 2 的 48 次方。<br />这个理论值相当“丰满”，但是服务器肯定承载不了那么大的连接数，主要会受两个方面的限制：</p><ul><li>文件描述符，Socket 实际上是一个文件，也就会对应一个文件描述符。在 Linux 下单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024，不过可以通过 ulimit 增大文件描述符的数目；</li><li>系统内存，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的。<br><a name="X1hTV"></a></li></ul><h4 id="多进程模型"><a href="#多进程模型" class="headerlink" title="多进程模型"></a>多进程模型</h4><p>基于最原始的阻塞网络 I&#x2F;O， 如果服务器要支持多个客户端，其中比较传统的方式就是使用多进程模型，也就是为每个客户端分配一个进程来处理请求。<br />服务器的主进程负责监听客户端的连接，一旦与客户端连接完成 accept() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。<br />这两个进程刚复制完的时候几乎一模一样。不过会根据返回值来区分是父进程还是子进程，如果返回值是 0 则是子进程；如果返回值是其他的整数就是父进程。<br />因为子进程会复制父进程的文件描述符，于是就可以直接使用「已连接 Socket 」和客户端通信了，<br />可以发现子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户端交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」。<br />下面这张图描述了从连接请求到连接建立，父进程创建生子进程为客户服务。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686043780444-a132c056-7542-47cc-a11d-e2b0eadf28e3.png#averageHue=%23f3f2e5&clientId=uf30cc27d-c3ef-4&from=paste&height=374&id=u323d7de4&originHeight=468&originWidth=1133&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=194217&status=done&style=none&taskId=ub3f29b70-570d-405a-ba84-f6a019af24a&title=&width=906.4"><br />当「子进程」退出时内核里还会保留该进程的一些信息，也是会占用内存的，如果不做好“回收”工作就会变成僵尸进程，随着僵尸进程增多会慢慢耗尽系统资源。<br />因此父进程要“善后”好自己的孩子，有两种方式可以在子进程退出后回收资源，分别是调用 wait() 和 waitpid() 函数。<br />这种用多个进程来应付多个客户端的方式在应对 100 个客户端时还是可行的，但是当客户端数量高达一万时肯定时是扛不住的，因为每产生一个进程必会占据一定的系统资源，而且进程间上下文切换的“包袱”是很重的，性能会大打折扣。<br />进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。<br><a name="pobaE"></a></p><h4 id="多线程模型"><a href="#多线程模型" class="headerlink" title="多线程模型"></a>多线程模型</h4><p>既然进程间上下文切换的“包袱”很重，那就搞个比较轻量级的模型来应对多用户的请求 —— 多线程模型。<br />线程是运行在进程中的一个“逻辑流”，单进程中可以运行多个线程，同进程里的线程可以共享进程的部分资源，比如文件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享资源在上下文切换时不需要切换，而只需要切换线程的私有数据、寄存器等不共享的数据，因此同一个进程下的线程上下文切换的开销要比进程小得多。<br />当服务器与客户端 TCP 完成连接后通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信从而达到并发处理的目的。<br />如果每来一个连接就创建一个线程，线程运行完后操作系统还得销毁线程，虽说线程切换的上下文开销不大，但是如果频繁创建和销毁线程系统开销也是不小的。<br />可以使用线程池的方式来避免线程的频繁创建和销毁，所谓的线程池就是提前创建若干个线程，这样当新连接建立时将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686044215739-e1141743-cdfe-4475-8076-28f2a96b6a90.png#averageHue=%23f4f3e7&clientId=uf30cc27d-c3ef-4&from=paste&height=295&id=ub9743197&originHeight=369&originWidth=1126&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=153820&status=done&style=none&taskId=ucc09a04e-a4df-4471-82a4-9d4c2680a7e&title=&width=900.8"><br />需要注意的是这个队列是全局的，每个线程都会操作，为了避免多线程竞争线程在操作这个队列前要加锁。<br />基于进程或者线程模型还是有问题的。新到来一个 TCP 连接就需要分配一个进程或者线程，那么如果要达到 C10K 意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程&#x2F;线程，操作系统就算死扛也是扛不住的。<br />经典的 C10K 问题：C 是 Client 单词首字母缩写，C10K 就是单机同时处理 1 万个请求的问题。<br><a name="E9Xph"></a></p><h4 id="I-x2F-O-多路复用"><a href="#I-x2F-O-多路复用" class="headerlink" title="I&#x2F;O 多路复用"></a>I&#x2F;O 多路复用</h4><p>既然为每个请求分配一个进程&#x2F;线程的方式不合适，那就只使用一个进程来维护多个 Socket，这就是 I&#x2F;O 多路复用技术。<br />一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。<br />select&#x2F;poll&#x2F;epoll 内核提供用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。<br />select&#x2F;poll&#x2F;epoll 获取网络事件：在获取事件时先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。<br><a name="QmEny"></a></p><h4 id="select-x2F-poll"><a href="#select-x2F-poll" class="headerlink" title="select&#x2F;poll"></a>select&#x2F;poll</h4><p>select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。<br />所以 select 这种方式需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后再传出到用户空间中。<br />select 使用固定长度的 BitsMap 表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。<br />poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。<br />但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来性能的损耗会呈指数级增长。<br><a name="iIu62"></a></p><h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h4><p>epoll 的用法，如下的代码中先用 epoll_create 创建一个 epoll 对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> s = socket(AF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line">bind(s, ...);</span><br><span class="line">listen(s, ...)</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> epfd = epoll_create(...);</span><br><span class="line">epoll_ctl(epfd, ...); <span class="comment">// 将所有需要监听的socket添加到epfd中</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="type">int</span> n = epoll_wait(...);</span><br><span class="line">    <span class="keyword">for</span>(接收到数据的socket)&#123;</span><br><span class="line">        <span class="comment">// 处理</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>epoll 通过两个方面很好解决了 select&#x2F;poll 的问题。<br />第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。<br />第二点，epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时通过回调函数内核会将其加入到就绪事件列表中，当用户调用 epoll_wait() 函数时只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。<br />从下图可以看到 epoll 相关的接口作用：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1686048774498-54dec2af-e67c-4b45-a436-fb091f74e577.png#averageHue=%23eaedd1&clientId=ucd8c7945-085c-4&from=paste&height=417&id=ud5a669f7&originHeight=521&originWidth=1134&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=172064&status=done&style=none&taskId=u73b035c4-3647-4a6d-a549-a889998a709&title=&width=907.2"><br />epoll 的方式即使监听的 Socket 数量很多的时候效率也不会大幅度降低，能够同时监听的 Socket 的数目也非常多，上限就是系统定义的进程打开的最大文件描述符个数。因而 epoll 被称为解决 C10K 问题的利器。<br><a name="oitOB"></a></p><h5 id="边缘触发和水平触发"><a href="#边缘触发和水平触发" class="headerlink" title="边缘触发和水平触发"></a>边缘触发和水平触发</h5><p>epoll 支持两种事件触发模式，分别是边缘触发和水平触发。<br />区别：</p><ul><li>使用边缘触发模式，当被监控的 Socket 描述符上有可读事件发生时服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据也依然只苏醒一次，因此程序要保证一次性将内核缓冲区的数据读取完；</li><li>使用水平触发模式，当被监控的 Socket 上有可读事件发生时服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是通知有数据需要读取。</li></ul><p>这就是两者的区别，水平触发的意思是只要满足事件的条件，比如内核中有数据需要读就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。<br />如果使用水平触发模式，当内核通知文件描述符可读写时还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后没必要一次执行尽可能多的读写操作。<br />如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次而且不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据以免错失读写的机会。因此会循环从文件描述符读写数据，如果文件描述符是阻塞的，没有数据可读写时进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用，程序会一直执行 I&#x2F;O 操作直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。<br />一般来说边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。<br />select&#x2F;poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。<br />使用 I&#x2F;O 多路复用时最好搭配非阻塞 I&#x2F;O 一起使用。因为多路复用 API 返回的事件并不一定是可读写的，如果使用阻塞 I&#x2F;O，那么在调用 read&#x2F;write 时就会发生程序阻塞，因此最好搭配非阻塞 I&#x2F;O 以便应对极少数的特殊情况。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a name=&quot;oryUX&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;基本-Socket-模型&quot;&gt;&lt;a href=&quot;#基本-Socket-模型&quot; class=&quot;headerlink&quot; title=&quot;基本 Socket 模型&quot;&gt;&lt;/a&gt;基本 Socket 模型&lt;/h4&gt;&lt;p&gt;要想</summary>
      
    
    
    
    <category term="计算机操作系统" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="网络系统" scheme="http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>网络系统：零拷贝</title>
    <link href="http://example.com/2022/12/07/%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E9%9B%B6%E6%8B%B7%E8%B4%9D/"/>
    <id>http://example.com/2022/12/07/%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F%EF%BC%9A%E9%9B%B6%E6%8B%B7%E8%B4%9D/</id>
    <published>2022-12-07T12:50:00.000Z</published>
    <updated>2025-10-24T21:20:54.872Z</updated>
    
    <content type="html"><![CDATA[<p>磁盘是计算机系统最慢的硬件之一，读写速度相差内存 10 倍以上，所以针对磁盘优化的技术非常的多，比如零拷贝、直接 I&#x2F;O、异步 I&#x2F;O 等等，这些优化的目的就是提高系统的吞吐量，另外操作系统内核中的磁盘高速缓存区可以有效的减少磁盘的访问次数。<br><a name="iBkF9"></a></p><h4 id="DMA-技术"><a href="#DMA-技术" class="headerlink" title="DMA 技术"></a>DMA 技术</h4><p>在没有 DMA 技术时 I&#x2F;O 的过程是这样的：</p><ul><li>CPU 发出对应的指令给磁盘控制器，然后返回；</li><li>磁盘控制器收到指令后就开始准备数据，会把数据放入磁盘控制器的内部缓冲区中，然后产生一个中断；</li><li>CPU 收到中断信号后停下手头的工作，接着把磁盘控制器的缓冲区中的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输期间 CPU 是无法执行其他任务的。</li></ul><p>如图所示：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685979494678-96d1001a-301a-43a8-b565-88f448046c34.png#averageHue=%23f9f9f8&clientId=ubef3b676-df4e-4&from=paste&height=531&id=uba45d8c7&originHeight=664&originWidth=1112&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=186374&status=done&style=none&taskId=u620a8ac6-1057-4799-a7c2-22fb7113b6b&title=&width=889.6"><br />整个数据的传输过程都要需要 CPU 亲自参与搬运数据的过程，而且这个过程中 CPU 是不能做其他事情的。<br />如果用千兆网卡或者硬盘传输大量数据，都用 CPU 搬运是忙不过来的，于是就发明了 DMA 技术，也就是直接内存访问（Direct Memory Access） 技术。<br />DMA 技术简单理解就是，在进行 I&#x2F;O 设备和内存的数据传输时数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。<br />使用 DMA 控制器进行数据传输的过程：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685979865731-bf90d4fa-b0a4-4b03-b709-0ed7211f6ebd.png#averageHue=%23fbfafa&clientId=ubef3b676-df4e-4&from=paste&height=435&id=u1fe8ce29&originHeight=544&originWidth=1122&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=134557&status=done&style=none&taskId=u505ee37b-cada-4963-85bc-c9e1218611d&title=&width=897.6"><br />具体过程：</p><ul><li>用户进程调用 read 方法向操作系统发出 I&#x2F;O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；</li><li>操作系统收到请求后进一步将 I&#x2F;O 请求发送到 DMA，然后让 CPU 执行其他任务；</li><li>DMA 进一步将 I&#x2F;O 请求发送给磁盘；</li><li>磁盘收到 DMA 的 I&#x2F;O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后向 DMA 发起中断信号，告知自己缓冲区已满；</li><li>DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务；</li><li>当 DMA 读取了足够多的数据就会发送中断信号给 CPU；</li><li>CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回。</li></ul><p>可以看到 CPU 不再参与「将数据从磁盘控制器缓冲区搬运到内核空间」的工作，这部分工作全程由 DMA 完成。但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器。<br><a name="XxXHl"></a></p><h4 id="糟糕的传统文件传输"><a href="#糟糕的传统文件传输" class="headerlink" title="糟糕的传统文件传输"></a>糟糕的传统文件传输</h4><p>如果服务端要提供文件传输的功能，最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。<br />传统 I&#x2F;O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I&#x2F;O 接口从磁盘读取或写入。<br />代码通常如下，一般会需要两个系统调用：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">read(file, tmp_buf, len);</span><br><span class="line">write(socket, tmp_buf, len);</span><br></pre></td></tr></table></figure><p>两行代码发生了不少事情。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685980483377-b44d75ba-05d9-4e14-9bcb-3953f399ac07.png#averageHue=%23f4f0e4&clientId=ubef3b676-df4e-4&from=paste&height=434&id=ua296c49b&originHeight=700&originWidth=1161&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=254729&status=done&style=none&taskId=ue11bcc87-13dc-4840-8f90-13868d4f540&title=&width=720.2000122070312"><br />首先期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后再从内核态切换回用户态。<br />上下文切换的成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下这类时间容易被累积和放大，从而影响系统的性能。<br />其次还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，过程如下：</p><ul><li>第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的；</li><li>第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的；</li><li>第三次拷贝，把刚才拷贝到用户的缓冲区里的数据再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的；</li><li>第四次拷贝，把内核的 socket 缓冲区里的数据拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。</li></ul><p>回顾文件传输的过程，只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。<br />这种简单的文件传输方式存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。所以要想提高文件传输的性能就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。<br><a name="gOGHE"></a></p><h4 id="优化文件传输性能"><a href="#优化文件传输性能" class="headerlink" title="优化文件传输性能"></a>优化文件传输性能</h4><ul><li>减少「用户态与内核态的上下文切换」的次数</li></ul><p>读取磁盘数据时之所以要发生上下文切换，是因为用户空间没有权限操作磁盘或网卡，内核的权限最高，这些操作设备的过程都需要交由操作系统内核来完成，所以一般要通过内核去完成某些任务的时候就需要使用操作系统提供的系统调用函数。<br />而一次系统调用必然会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后再切换回用户态交由进程代码执行。<br />所以要想减少上下文切换到次数就要减少系统调用的次数。</p><ul><li>减少「数据拷贝」的次数</li></ul><p>传统的文件传输方式会历经 4 次数据拷贝，这里面「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」这个过程是没有必要的。<br />因为在文件传输的应用场景中，在用户空间并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此用户的缓冲区是没有必要存在的。<br><a name="TyjP9"></a></p><h4 id="零拷贝实现"><a href="#零拷贝实现" class="headerlink" title="零拷贝实现"></a>零拷贝实现</h4><p>零拷贝技术实现的方式通常有 2 种：</p><ul><li>mmap + write</li><li>sendfile<br><a name="HtRIJ"></a></li></ul><h5 id="mmap-write"><a href="#mmap-write" class="headerlink" title="mmap + write"></a>mmap + write</h5><p>read() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，为了减少这一步开销可以用 mmap() 替换 read() 系统调用函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">buf = mmap(file, len);</span><br><span class="line">write(sockfd, buf, len);</span><br></pre></td></tr></table></figure><p>mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685981859422-9a1d911c-9359-4064-a3df-4493841b8218.png#averageHue=%23f2efe2&clientId=ubef3b676-df4e-4&from=paste&height=428&id=u517f081d&originHeight=686&originWidth=1137&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=262117&status=done&style=none&taskId=u8f9e508a-6ba2-43be-91e0-38602f7a651&title=&width=709.2000122070312"><br />具体过程如下：</p><ul><li>应用进程调用了 mmap() 后 DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着应用进程跟操作系统内核「共享」这个缓冲区；</li><li>应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li><li>最后把内核的 socket 缓冲区里的数据拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。</li></ul><p>通过使用 mmap() 来代替 read() 可以减少一次数据拷贝的过程。但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。<br><a name="MAX9G"></a></p><h5 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h5><p>在 Linux 内核中提供了一个专门发送文件的系统调用函数 sendfile()，函数形式如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">sendfile</span><span class="params">(<span class="type">int</span> out_fd, <span class="type">int</span> in_fd, <span class="type">off_t</span> *offset, <span class="type">size_t</span> count)</span>;</span><br></pre></td></tr></table></figure><p>前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。<br />首先它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。<br />其次该系统调用可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换和 3 次数据拷贝。如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685983374446-bd5f923d-7fd5-42a9-bffd-987569f630ab.png#averageHue=%23f2eee4&clientId=ubef3b676-df4e-4&from=paste&height=409&id=ua09361c1&originHeight=700&originWidth=1150&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=254877&status=done&style=none&taskId=u83b5a8ac-0f78-4cc6-a20f-192c3586620&title=&width=672.2000122070312"><br />但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA 技术（和普通的 DMA 有所不同），可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。<br />可以在 Linux 系统通过下面这个命令查看网卡是否支持 scatter-gather 特性：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ethtool -k eth0 | grep scatter-gather</span></span><br><span class="line">scatter-gather: on</span><br></pre></td></tr></table></figure><p>对于网卡支持 SG-DMA 技术的情况下 sendfile() 系统调用的过程发生了点变化，具体过程如下：</p><ul><li>第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；</li><li>第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝。</li></ul><p>所以这个过程之中只进行了 2 次数据拷贝，如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685983738066-b139feb0-2ea3-49b3-afa6-a0e8a682f4f0.png#averageHue=%23efede0&clientId=ubef3b676-df4e-4&from=paste&height=411&id=u216760a7&originHeight=662&originWidth=1135&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=250120&status=done&style=none&taskId=u1e532441-4542-4a50-881b-9db1b6b3461&title=&width=704.2000122070312"><br />这就是所谓的零拷贝（Zero-copy）技术，因为没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。<br />零拷贝技术的文件传输方式相比传统文件传输的方式减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数就可以完成文件的传输，而且这 2 次数据拷贝过程都不需要通过 CPU，2 次都是由 DMA 来搬运。<br />总体来看零拷贝技术可以把文件传输的性能提高至少一倍以上。<br />需要注意的是零拷贝技术是不允许进程对文件内容作进一步的加工的，比如压缩数据再发送。<br><a name="GSMqT"></a></p><h5 id="使用零拷贝技术的项目"><a href="#使用零拷贝技术的项目" class="headerlink" title="使用零拷贝技术的项目"></a>使用零拷贝技术的项目</h5><p>开源项目 Kafka 就使用了「零拷贝」技术，从而大幅提升了 I&#x2F;O 的吞吐率，这也是 Kafka 在处理海量数据为什么这么快的原因之一。<br />追溯 Kafka 文件传输的代码，会发现最终它调用了 Java NIO 库里的 transferTo 方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Overridepublic</span> </span><br><span class="line"><span class="type">long</span> <span class="title function_">transferFrom</span><span class="params">(FileChannel fileChannel, <span class="type">long</span> position, <span class="type">long</span> count)</span> <span class="keyword">throws</span> IOException &#123; </span><br><span class="line">    <span class="keyword">return</span> fileChannel.transferTo(position, count, socketChannel);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果 Linux 系统支持 sendfile() 系统调用，那么 transferTo() 实际上最后就会使用到 sendfile() 系统调用函数。<br />Nginx 也支持零拷贝技术，一般默认是开启零拷贝技术，这样有利于提高文件传输的效率，是否开启零拷贝技术的配置如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    sendfile on</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>sendfile 配置的具体意思：</p><ul><li>设置为 on 表示使用零拷贝技术来传输文件：sendfile ，这样只需要 2 次上下文切换和 2 次数据拷贝；</li><li>设置为 off 表示使用传统的文件传输技术：read + write，这时就需要 4 次上下文切换和 4 次数据拷贝。<br><a name="V3Seu"></a></li></ul><h4 id="PageCache-作用"><a href="#PageCache-作用" class="headerlink" title="PageCache 作用"></a>PageCache 作用</h4><p>文件传输过程中第一步都是先需要把磁盘文件数据拷贝到「内核缓冲区」里，这个「内核缓冲区」实际上是磁盘高速缓存（PageCache）。<br />零拷贝使用了 PageCache 技术，可以使得零拷贝进一步提升了性能。<br />读写磁盘相比读写内存的速度慢太多了，所以应该想办法把「读写磁盘」替换成「读写内存」。于是通过 DMA 把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。但是内存空间远比磁盘要小，内存注定只能拷贝磁盘里的一小部分数据。<br />程序运行时具有「局部性」，所以通常刚被访问的数据在短时间内再次被访问的概率很高，于是可以用 PageCache 来缓存最近被访问的数据，当空间不足时淘汰最久未被访问的缓存。<br />所以读磁盘数据时优先在 PageCache 中找，如果数据存在则可以直接返回；如果没有则从磁盘中读取，然后缓存 PageCache 中。<br />读取磁盘数据时需要找到数据所在的位置，但是对于机械磁盘来说就是通过磁头旋转到数据所在的扇区再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响 PageCache 使用了「预读功能」。<br />比如 read 方法每次只会读 32 KB 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后面的 32～64 KB 也读取到 PageCache 中，这样后面读取 32～64 KB 的成本就很低，如果在 32～64 KB 淘汰出 PageCache 前进程读取到它了收益就非常大。<br />PageCache 的优点主要是两个：</p><ul><li>缓存最近被访问的数据；</li><li>预读功能（顺序读比随机读性能好的原因）。</li></ul><p>这两个做法将大大提高读写磁盘的性能。但是在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能。<br />这是因为如果有很多 GB 级别文件需要传输，每当用户访问这些大文件时内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满。<br />另外由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来 2 个问题：</p><ul><li>PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；</li><li>PageCache 中的大文件数据没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次。</li></ul><p>所以针对大文件的传输不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下会带来严重的性能问题。<br><a name="bJlZa"></a></p><h4 id="大文件传输实现"><a href="#大文件传输实现" class="headerlink" title="大文件传输实现"></a>大文件传输实现</h4><p>当调用 read 方法读取文件时进程实际上会阻塞在 read 方法调用，因为要等待磁盘数据的返回，如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685986096622-cab03e22-1c24-4252-bea4-bb399c321a5d.png#averageHue=%23f9f8f7&clientId=ubef3b676-df4e-4&from=paste&height=459&id=uc23d111e&originHeight=742&originWidth=1128&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=213882&status=done&style=none&taskId=u2f64124c-87bb-4787-a0c5-556a21ff183&title=&width=698.2000122070312"><br />具体过程：</p><ul><li>当调用 read 方法时会阻塞着，此时内核会向磁盘发起 I&#x2F;O 请求，磁盘收到请求后便会寻址，当磁盘数据准备好后就会向内核发起 I&#x2F;O 中断，告知内核磁盘数据已经准备好；</li><li>内核收到 I&#x2F;O 中断后就将数据从磁盘控制器缓冲区拷贝到 PageCache 里；</li><li>最后内核再把 PageCache 中的数据拷贝到用户缓冲区，于是 read 调用就正常返回了。</li></ul><p>阻塞的问题可以用异步 I&#x2F;O 来解决，它工作方式如下图：<br /><img src="https://cdn.nlark.com/yuque/0/2023/png/25368844/1685986222579-3b6c6cc8-0461-4032-9f01-ea28fbb70a79.png#averageHue=%23fafafa&clientId=ubef3b676-df4e-4&from=paste&height=414&id=u921ebf67&originHeight=661&originWidth=1117&originalType=binary&ratio=1.25&rotation=0&showTitle=false&size=153785&status=done&style=none&taskId=u17b96d3a-8aa2-4e61-b2e1-14b911472de&title=&width=699.2000122070312"><br />它把读操作分为两部分：</p><ul><li>前半部分：内核向磁盘发起读请求，但是可以不等待数据就位就可以返回，于是进程此时可以处理其他任务；</li><li>后半部分：当内核将磁盘中的数据拷贝到进程缓冲区后进程将接收到内核的通知，再去处理数据；</li></ul><p>可以发现异步 I&#x2F;O 并没有涉及到 PageCache，所以使用异步 I&#x2F;O 就意味着要绕开 PageCache。<br />绕开 PageCache 的 I&#x2F;O 叫直接 I&#x2F;O，使用 PageCache 的 I&#x2F;O 则叫缓存 I&#x2F;O。通常对于磁盘，异步 I&#x2F;O 只支持直接 I&#x2F;O。<br />大文件的传输不应该使用 PageCache，因为可能由于 PageCache 被大文件占据而导致「热点」小文件无法利用到 PageCache。在高并发的场景下，针对大文件传输的方式，应该使用「异步 I&#x2F;O + 直接 I&#x2F;O」来替代零拷贝技术。<br />直接 I&#x2F;O 应用场景常见的两种：</p><ul><li>应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中可以通过参数设置开启直接 I&#x2F;O，默认是不开启；</li><li>传输大文件时由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此这时应该使用直接 I&#x2F;O。</li></ul><p>另外由于直接 I&#x2F;O 绕过了 PageCache，就无法享受内核的这两点的优化：</p><ul><li>内核的 I&#x2F;O 调度算法会缓存尽可能多的 I&#x2F;O 请求在 PageCache 中，最后「合并」成一个更大的 I&#x2F;O 请求再发给磁盘，这样做是为了减少磁盘的寻址操作；</li><li>内核也会「预读」后续的 I&#x2F;O 请求放在 PageCache 中，一样是为了减少对磁盘的操作。</li></ul><p>传输大文件时使用「异步 I&#x2F;O + 直接 I&#x2F;O」就可以无阻塞地读取文件了。<br />所以传输文件时要根据文件的大小来使用不同的方式：</p><ul><li>传输大文件时使用「异步 I&#x2F;O + 直接 I&#x2F;O」；</li><li>传输小文件时使用「零拷贝技术」；</li></ul><p>在 nginx 中可以用如下配置来根据文件的大小来使用不同的方式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">location /video/ &#123; </span><br><span class="line">    sendfile on; </span><br><span class="line">    aio on; </span><br><span class="line">    directio 1024m; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当文件大小大于 directio 值后使用「异步 I&#x2F;O + 直接 I&#x2F;O」，否则使用「零拷贝技术」。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;磁盘是计算机系统最慢的硬件之一，读写速度相差内存 10 倍以上，所以针对磁盘优化的技术非常的多，比如零拷贝、直接 I&amp;#x2F;O、异步 I&amp;#x2F;O 等等，这些优化的目的就是提高系统的吞吐量，另外操作系统内核中的磁盘高速缓存区可以有效的减少磁盘的访问次数。&lt;br&gt;&lt;a</summary>
      
    
    
    
    <category term="计算机操作系统" scheme="http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
    
    <category term="网络系统" scheme="http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
</feed>
